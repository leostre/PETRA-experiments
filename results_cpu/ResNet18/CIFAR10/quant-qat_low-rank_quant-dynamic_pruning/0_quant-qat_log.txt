
>>> PEFT step 1: quant-qat
Creating Dask Server
Generations:   0%|                                                                                                                                               | 0/10000 [00:00<?, ?gen/s][QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A58584C0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A58584C0>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585AA70>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585AA70>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585A710>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585A710>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5858E50>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5858E50>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585B010>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585B010>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585A560>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585A560>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585A050>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585A050>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A58595A0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A58595A0>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585A440>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585A440>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585B2E0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585B2E0>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A58596C0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A58596C0>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DCAB90>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DC85E0>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DC97E0>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DC8DC0>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DC8430>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DCA050>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DC9900>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5859000>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585BAC0>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585BD00>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585A290>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[HOOK] Performing Dynamic PTQ hook operations.
[HOOK] Dynamic PTQ setup completed.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DCA050>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DCA050>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DC8DC0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DC8DC0>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585B2E0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585B2E0>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A58597E0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A58597E0>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5859EA0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5859EA0>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A58592D0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A58592D0>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585B010>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585B010>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5858D30>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5858D30>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5859000>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5859000>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5858E50>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5858E50>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585AC20>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585AC20>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585B2E0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585B2E0>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585ACB0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585ACB0>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585AC20>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585AC20>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5858820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5858820>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5858CA0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5858CA0>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585ADD0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585ADD0>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5859000>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5859000>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5858E50>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5858E50>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A58597E0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A58597E0>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585A0E0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585A0E0>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585A710>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585A710>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[HOOK] Performing QAT training hook.
[HOOK] QAT epoch 1/5 started.
[HOOK][Epoch: 1] Batch 1 Loss: 0.1966
[HOOK][Epoch: 1] Batch 51 Loss: 0.1919
[HOOK][Epoch: 1] Batch 101 Loss: 0.1693
[HOOK][Epoch: 1] Batch 151 Loss: 0.1557
[HOOK][Epoch: 1] Batch 201 Loss: 0.2617
[HOOK][Epoch: 1] Batch 251 Loss: 0.4407
[HOOK][Epoch: 1] Batch 301 Loss: 0.2311
[HOOK][Epoch: 1] Batch 351 Loss: 0.1144
[HOOK][Epoch: 1] Batch 401 Loss: 0.4693
[HOOK][Epoch: 1] Batch 451 Loss: 0.0614
[HOOK][Epoch: 1] Batch 501 Loss: 0.1920
[HOOK][Epoch: 1] Batch 551 Loss: 0.0974
[HOOK][Epoch: 1] Batch 601 Loss: 0.3291
[HOOK] QAT epoch 2/5 started.
[HOOK][Epoch: 2] Batch 1 Loss: 0.0498
[HOOK][Epoch: 2] Batch 51 Loss: 0.1284
[HOOK][Epoch: 2] Batch 101 Loss: 0.0110
[HOOK][Epoch: 2] Batch 151 Loss: 0.0747
[HOOK][Epoch: 2] Batch 201 Loss: 0.0807
[HOOK][Epoch: 2] Batch 251 Loss: 0.1146
[HOOK][Epoch: 2] Batch 301 Loss: 0.1666
[HOOK][Epoch: 2] Batch 351 Loss: 0.1691
[HOOK][Epoch: 2] Batch 401 Loss: 0.0342
[HOOK][Epoch: 2] Batch 451 Loss: 0.1974
[HOOK][Epoch: 2] Batch 501 Loss: 0.0304
[HOOK][Epoch: 2] Batch 551 Loss: 0.0261
[HOOK][Epoch: 2] Batch 601 Loss: 0.1875
[HOOK] QAT epoch 3/5 started.
[HOOK][Epoch: 3] Batch 1 Loss: 0.0141
[HOOK][Epoch: 3] Batch 51 Loss: 0.0138
[HOOK][Epoch: 3] Batch 101 Loss: 0.0077
[HOOK][Epoch: 3] Batch 151 Loss: 0.0123
[HOOK][Epoch: 3] Batch 201 Loss: 0.0129
[HOOK][Epoch: 3] Batch 251 Loss: 0.0228
[HOOK][Epoch: 3] Batch 301 Loss: 0.0092
[HOOK][Epoch: 3] Batch 351 Loss: 0.0057
[HOOK][Epoch: 3] Batch 401 Loss: 0.0271
[HOOK][Epoch: 3] Batch 451 Loss: 0.0108
[HOOK][Epoch: 3] Batch 501 Loss: 0.0076
[HOOK][Epoch: 3] Batch 551 Loss: 0.0172
[HOOK][Epoch: 3] Batch 601 Loss: 0.0904
[HOOK] QAT epoch 4/5 started.
[HOOK][Epoch: 4] Batch 1 Loss: 0.0105
[HOOK][Epoch: 4] Batch 51 Loss: 0.0124
[HOOK][Epoch: 4] Batch 101 Loss: 0.0192
[HOOK][Epoch: 4] Batch 151 Loss: 0.0169
[HOOK][Epoch: 4] Batch 201 Loss: 0.0261
[HOOK][Epoch: 4] Batch 251 Loss: 0.0060
[HOOK][Epoch: 4] Batch 301 Loss: 0.0020
[HOOK][Epoch: 4] Batch 351 Loss: 0.0875
[HOOK][Epoch: 4] Batch 401 Loss: 0.0195
[HOOK][Epoch: 4] Batch 451 Loss: 0.0020
[HOOK][Epoch: 4] Batch 501 Loss: 0.0226
[HOOK][Epoch: 4] Batch 551 Loss: 0.0367
[HOOK][Epoch: 4] Batch 601 Loss: 0.0085
[HOOK] QAT epoch 5/5 started.
[HOOK][Epoch: 5] Batch 1 Loss: 0.0528
[HOOK][Epoch: 5] Batch 51 Loss: 0.0116
[HOOK][Epoch: 5] Batch 101 Loss: 0.0060
[HOOK][Epoch: 5] Batch 151 Loss: 0.1656
[HOOK][Epoch: 5] Batch 201 Loss: 0.0257
[HOOK][Epoch: 5] Batch 251 Loss: 0.0155
[HOOK][Epoch: 5] Batch 301 Loss: 0.0115
[HOOK][Epoch: 5] Batch 351 Loss: 0.0827
[HOOK][Epoch: 5] Batch 401 Loss: 0.0188
[HOOK][Epoch: 5] Batch 451 Loss: 0.0030
[HOOK][Epoch: 5] Batch 501 Loss: 0.0941
[HOOK][Epoch: 5] Batch 551 Loss: 0.0406
[HOOK][Epoch: 5] Batch 601 Loss: 0.0128
[HOOK] QAT training completed.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5858820>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A5858820>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585B250>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585B250>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585AC20>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585AC20>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585ACB0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A585ACB0>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4B520>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4B520>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4AC20>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4AC20>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E80D0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E80D0>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E84C0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E84C0>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9000>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9000>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E8CA0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E8CA0>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E8F70>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E8F70>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E84C0>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E95A0>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9360>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E92D0>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9510>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E80D0>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E93F0>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9480>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E8EE0>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9AB0>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9C60>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[HOOK] Performing Dynamic PTQ hook operations.
[HOOK] Dynamic PTQ setup completed.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9510>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9510>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9FC0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9FC0>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E80D0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E80D0>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9F30>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9F30>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E92D0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E92D0>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9360>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9360>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E95A0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E95A0>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9CF0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9CF0>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9EA0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9EA0>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9D80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9D80>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E84C0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E84C0>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87EA680>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87EA680>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9F30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E9F30>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E80D0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87E80D0>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87EA290>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87EA290>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87EAB00>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87EAB00>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87EAB90>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87EAB90>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87EAC20>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87EAC20>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87EACB0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87EACB0>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87EAD40>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87EAD40>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87EAE60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87EAE60>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87EADD0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1A87EADD0>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[HOOK] Performing QAT training hook.
[HOOK] QAT epoch 1/5 started.
[HOOK][Epoch: 1] Batch 1 Loss: 0.0021
[HOOK][Epoch: 1] Batch 51 Loss: 1.0708
[HOOK][Epoch: 1] Batch 101 Loss: 0.2582
[HOOK][Epoch: 1] Batch 151 Loss: 0.1608
[HOOK][Epoch: 1] Batch 201 Loss: 0.3179
[HOOK][Epoch: 1] Batch 251 Loss: 0.0905
[HOOK][Epoch: 1] Batch 301 Loss: 0.2815
[HOOK][Epoch: 1] Batch 351 Loss: 0.0629
[HOOK][Epoch: 1] Batch 401 Loss: 0.0880
[HOOK][Epoch: 1] Batch 451 Loss: 0.2670
[HOOK][Epoch: 1] Batch 501 Loss: 0.1889
[HOOK][Epoch: 1] Batch 551 Loss: 0.0653
[HOOK][Epoch: 1] Batch 601 Loss: 0.1580
[HOOK] QAT epoch 2/5 started.
[HOOK][Epoch: 2] Batch 1 Loss: 0.0177
[HOOK][Epoch: 2] Batch 51 Loss: 0.0856
[HOOK][Epoch: 2] Batch 101 Loss: 0.0651
[HOOK][Epoch: 2] Batch 151 Loss: 0.0515
[HOOK][Epoch: 2] Batch 201 Loss: 0.2616
[HOOK][Epoch: 2] Batch 251 Loss: 0.0202
[HOOK][Epoch: 2] Batch 301 Loss: 0.0757
[HOOK][Epoch: 2] Batch 351 Loss: 0.0629
[HOOK][Epoch: 2] Batch 401 Loss: 0.1288
[HOOK][Epoch: 2] Batch 451 Loss: 0.1130
[HOOK][Epoch: 2] Batch 501 Loss: 0.0594
[HOOK][Epoch: 2] Batch 551 Loss: 0.2257
[HOOK][Epoch: 2] Batch 601 Loss: 0.2128
[HOOK] QAT epoch 3/5 started.
[HOOK][Epoch: 3] Batch 1 Loss: 0.0088
[HOOK][Epoch: 3] Batch 51 Loss: 0.0328
[HOOK][Epoch: 3] Batch 101 Loss: 0.0273
[HOOK][Epoch: 3] Batch 151 Loss: 0.0065
[HOOK][Epoch: 3] Batch 201 Loss: 0.1135
[HOOK][Epoch: 3] Batch 251 Loss: 0.0090
[HOOK][Epoch: 3] Batch 301 Loss: 0.0639
[HOOK][Epoch: 3] Batch 351 Loss: 0.0151
[HOOK][Epoch: 3] Batch 401 Loss: 0.0188
[HOOK][Epoch: 3] Batch 451 Loss: 0.0043
[HOOK][Epoch: 3] Batch 501 Loss: 0.0222
[HOOK][Epoch: 3] Batch 551 Loss: 0.0454
[HOOK][Epoch: 3] Batch 601 Loss: 0.0163
[HOOK] QAT epoch 4/5 started.
[HOOK][Epoch: 4] Batch 1 Loss: 0.0070
[HOOK][Epoch: 4] Batch 51 Loss: 0.0031
[HOOK][Epoch: 4] Batch 101 Loss: 0.0049
[HOOK][Epoch: 4] Batch 151 Loss: 0.0009
[HOOK][Epoch: 4] Batch 201 Loss: 0.0012
[HOOK][Epoch: 4] Batch 251 Loss: 0.0148
[HOOK][Epoch: 4] Batch 301 Loss: 0.0187
[HOOK][Epoch: 4] Batch 351 Loss: 0.0146
[HOOK][Epoch: 4] Batch 401 Loss: 0.0021
[HOOK][Epoch: 4] Batch 451 Loss: 0.0037
[HOOK][Epoch: 4] Batch 501 Loss: 0.0044
[HOOK][Epoch: 4] Batch 551 Loss: 0.0021
[HOOK][Epoch: 4] Batch 601 Loss: 0.0112
[HOOK] QAT epoch 5/5 started.
[HOOK][Epoch: 5] Batch 1 Loss: 0.0007
[HOOK][Epoch: 5] Batch 51 Loss: 0.0004
[HOOK][Epoch: 5] Batch 101 Loss: 0.0934
[HOOK][Epoch: 5] Batch 151 Loss: 0.0002
[HOOK][Epoch: 5] Batch 201 Loss: 0.1029
[HOOK][Epoch: 5] Batch 251 Loss: 0.0075
[HOOK][Epoch: 5] Batch 301 Loss: 0.0164
[HOOK][Epoch: 5] Batch 351 Loss: 0.0017
[HOOK][Epoch: 5] Batch 401 Loss: 0.0075
[HOOK][Epoch: 5] Batch 451 Loss: 0.0017
[HOOK][Epoch: 5] Batch 501 Loss: 0.0418
[HOOK][Epoch: 5] Batch 551 Loss: 0.0007
[HOOK][Epoch: 5] Batch 601 Loss: 0.0158
[HOOK] QAT training completed.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49120>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49120>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4A7A0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4A7A0>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4B5B0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4B5B0>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E491B0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E491B0>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4BD00>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4BD00>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49F30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49F30>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49FC0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49FC0>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49B40>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49B40>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4AE60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4AE60>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4AEF0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4AEF0>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4B490>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4B490>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[HOOK] Performing QAT training hook.
[HOOK] QAT epoch 1/5 started.
[HOOK][Epoch: 1] Batch 1 Loss: 0.9730
[HOOK][Epoch: 1] Batch 51 Loss: 0.2363
[HOOK][Epoch: 1] Batch 101 Loss: 0.3385
[HOOK][Epoch: 1] Batch 151 Loss: 0.1965
[HOOK][Epoch: 1] Batch 201 Loss: 0.2984
[HOOK][Epoch: 1] Batch 251 Loss: 0.1691
[HOOK][Epoch: 1] Batch 301 Loss: 0.5277
[HOOK][Epoch: 1] Batch 351 Loss: 0.0828
[HOOK][Epoch: 1] Batch 401 Loss: 0.0348
[HOOK][Epoch: 1] Batch 451 Loss: 0.1092
[HOOK][Epoch: 1] Batch 501 Loss: 0.1350
[HOOK][Epoch: 1] Batch 551 Loss: 0.7103
[HOOK][Epoch: 1] Batch 601 Loss: 0.2422
[HOOK] QAT epoch 2/5 started.
[HOOK][Epoch: 2] Batch 1 Loss: 0.0423
[HOOK][Epoch: 2] Batch 51 Loss: 0.0854
[HOOK][Epoch: 2] Batch 101 Loss: 0.0046
[HOOK][Epoch: 2] Batch 151 Loss: 0.0883
[HOOK][Epoch: 2] Batch 201 Loss: 0.1421
[HOOK][Epoch: 2] Batch 251 Loss: 0.1448
[HOOK][Epoch: 2] Batch 301 Loss: 0.1885
[HOOK][Epoch: 2] Batch 351 Loss: 0.0280
[HOOK][Epoch: 2] Batch 401 Loss: 0.0207
[HOOK][Epoch: 2] Batch 451 Loss: 0.1405
[HOOK][Epoch: 2] Batch 501 Loss: 0.0183
[HOOK][Epoch: 2] Batch 551 Loss: 0.1189
[HOOK][Epoch: 2] Batch 601 Loss: 0.0730
[HOOK] QAT epoch 3/5 started.
[HOOK][Epoch: 3] Batch 1 Loss: 0.0256
[HOOK][Epoch: 3] Batch 51 Loss: 0.0264
[HOOK][Epoch: 3] Batch 101 Loss: 0.0306
[HOOK][Epoch: 3] Batch 151 Loss: 0.0077
[HOOK][Epoch: 3] Batch 201 Loss: 0.0013
[HOOK][Epoch: 3] Batch 251 Loss: 0.1678
[HOOK][Epoch: 3] Batch 301 Loss: 0.0073
[HOOK][Epoch: 3] Batch 351 Loss: 0.0664
[HOOK][Epoch: 3] Batch 401 Loss: 0.0070
[HOOK][Epoch: 3] Batch 451 Loss: 0.0260
[HOOK][Epoch: 3] Batch 501 Loss: 0.0410
[HOOK][Epoch: 3] Batch 551 Loss: 0.0146
[HOOK][Epoch: 3] Batch 601 Loss: 0.0617
[HOOK] QAT epoch 4/5 started.
[HOOK][Epoch: 4] Batch 1 Loss: 0.0024
[HOOK][Epoch: 4] Batch 51 Loss: 0.0044
[HOOK][Epoch: 4] Batch 101 Loss: 0.0588
[HOOK][Epoch: 4] Batch 151 Loss: 0.0215
[HOOK][Epoch: 4] Batch 201 Loss: 0.0165
[HOOK][Epoch: 4] Batch 251 Loss: 0.0024
[HOOK][Epoch: 4] Batch 301 Loss: 0.0005
[HOOK][Epoch: 4] Batch 351 Loss: 0.0028
[HOOK][Epoch: 4] Batch 401 Loss: 0.0111
[HOOK][Epoch: 4] Batch 451 Loss: 0.0277
[HOOK][Epoch: 4] Batch 501 Loss: 0.0278
[HOOK][Epoch: 4] Batch 551 Loss: 0.0313
[HOOK][Epoch: 4] Batch 601 Loss: 0.0021
[HOOK] QAT epoch 5/5 started.
[HOOK][Epoch: 5] Batch 1 Loss: 0.0045
[HOOK][Epoch: 5] Batch 51 Loss: 0.0041
[HOOK][Epoch: 5] Batch 101 Loss: 0.0415
[HOOK][Epoch: 5] Batch 151 Loss: 0.0033
[HOOK][Epoch: 5] Batch 201 Loss: 0.0047
[HOOK][Epoch: 5] Batch 251 Loss: 0.0034
[HOOK][Epoch: 5] Batch 301 Loss: 0.0133
[HOOK][Epoch: 5] Batch 351 Loss: 0.0115
[HOOK][Epoch: 5] Batch 401 Loss: 0.1749
[HOOK][Epoch: 5] Batch 451 Loss: 0.0901
[HOOK][Epoch: 5] Batch 501 Loss: 0.0031
[HOOK][Epoch: 5] Batch 551 Loss: 0.0031
[HOOK][Epoch: 5] Batch 601 Loss: 0.0040
[HOOK] QAT training completed.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E48040>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4B5B0>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4A7A0>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4BC70>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E231C0>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E211B0>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E21C60>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E216C0>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E227A0>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E23520>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E20EE0>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[HOOK] Performing Dynamic PTQ hook operations.
[HOOK] Dynamic PTQ setup completed.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E20D30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E20D30>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E224D0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E224D0>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E216C0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E216C0>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E21C60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E21C60>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E231C0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E231C0>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E23370>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E23370>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E211B0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E211B0>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E21D80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E21D80>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E22710>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E22710>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E213F0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E213F0>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E20C10>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E20C10>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[HOOK] Performing QAT training hook.
[HOOK] QAT epoch 1/5 started.
[HOOK][Epoch: 1] Batch 1 Loss: 0.4981
[HOOK][Epoch: 1] Batch 51 Loss: 0.1168
[HOOK][Epoch: 1] Batch 101 Loss: 0.0077
[HOOK][Epoch: 1] Batch 151 Loss: 0.2232
[HOOK][Epoch: 1] Batch 201 Loss: 0.3931
[HOOK][Epoch: 1] Batch 251 Loss: 0.3443
[HOOK][Epoch: 1] Batch 301 Loss: 0.1447
[HOOK][Epoch: 1] Batch 351 Loss: 0.1863
[HOOK][Epoch: 1] Batch 401 Loss: 0.1587
[HOOK][Epoch: 1] Batch 451 Loss: 0.2354
[HOOK][Epoch: 1] Batch 501 Loss: 0.5827
[HOOK][Epoch: 1] Batch 551 Loss: 0.1349
[HOOK][Epoch: 1] Batch 601 Loss: 0.1341
[HOOK] QAT epoch 2/5 started.
[HOOK][Epoch: 2] Batch 1 Loss: 0.0819
[HOOK][Epoch: 2] Batch 51 Loss: 0.0431
[HOOK][Epoch: 2] Batch 101 Loss: 0.0080
[HOOK][Epoch: 2] Batch 151 Loss: 0.0681
[HOOK][Epoch: 2] Batch 201 Loss: 0.1306
[HOOK][Epoch: 2] Batch 251 Loss: 0.0173
[HOOK][Epoch: 2] Batch 301 Loss: 0.0911
[HOOK][Epoch: 2] Batch 351 Loss: 0.3497
[HOOK][Epoch: 2] Batch 401 Loss: 0.1810
[HOOK][Epoch: 2] Batch 451 Loss: 0.1409
[HOOK][Epoch: 2] Batch 501 Loss: 0.0344
[HOOK][Epoch: 2] Batch 551 Loss: 0.0950
[HOOK][Epoch: 2] Batch 601 Loss: 0.0748
[HOOK] QAT epoch 3/5 started.
[HOOK][Epoch: 3] Batch 1 Loss: 0.0335
[HOOK][Epoch: 3] Batch 51 Loss: 0.0816
[HOOK][Epoch: 3] Batch 101 Loss: 0.0045
[HOOK][Epoch: 3] Batch 151 Loss: 0.0167
[HOOK][Epoch: 3] Batch 201 Loss: 0.0032
[HOOK][Epoch: 3] Batch 251 Loss: 0.0185
[HOOK][Epoch: 3] Batch 301 Loss: 0.0787
[HOOK][Epoch: 3] Batch 351 Loss: 0.0079
[HOOK][Epoch: 3] Batch 401 Loss: 0.0278
[HOOK][Epoch: 3] Batch 451 Loss: 0.0444
[HOOK][Epoch: 3] Batch 501 Loss: 0.0007
[HOOK][Epoch: 3] Batch 551 Loss: 0.0373
[HOOK][Epoch: 3] Batch 601 Loss: 0.0034
[HOOK] QAT epoch 4/5 started.
[HOOK][Epoch: 4] Batch 1 Loss: 0.0115
[HOOK][Epoch: 4] Batch 51 Loss: 0.0374
[HOOK][Epoch: 4] Batch 101 Loss: 0.0074
[HOOK][Epoch: 4] Batch 151 Loss: 0.0052
[HOOK][Epoch: 4] Batch 201 Loss: 0.0785
[HOOK][Epoch: 4] Batch 251 Loss: 0.0482
[HOOK][Epoch: 4] Batch 301 Loss: 0.0040
[HOOK][Epoch: 4] Batch 351 Loss: 0.0018
[HOOK][Epoch: 4] Batch 401 Loss: 0.0114
[HOOK][Epoch: 4] Batch 451 Loss: 0.0116
[HOOK][Epoch: 4] Batch 501 Loss: 0.0591
[HOOK][Epoch: 4] Batch 551 Loss: 0.0137
[HOOK][Epoch: 4] Batch 601 Loss: 0.0394
[HOOK] QAT epoch 5/5 started.
[HOOK][Epoch: 5] Batch 1 Loss: 0.0239
[HOOK][Epoch: 5] Batch 51 Loss: 0.0031
[HOOK][Epoch: 5] Batch 101 Loss: 0.0413
[HOOK][Epoch: 5] Batch 151 Loss: 0.0354
[HOOK][Epoch: 5] Batch 201 Loss: 0.0152
[HOOK][Epoch: 5] Batch 251 Loss: 0.0087
[HOOK][Epoch: 5] Batch 301 Loss: 0.0156
[HOOK][Epoch: 5] Batch 351 Loss: 0.0445
[HOOK][Epoch: 5] Batch 401 Loss: 0.0246
[HOOK][Epoch: 5] Batch 451 Loss: 0.0048
[HOOK][Epoch: 5] Batch 501 Loss: 0.0076
[HOOK][Epoch: 5] Batch 551 Loss: 0.0134
[HOOK][Epoch: 5] Batch 601 Loss: 0.0129
[HOOK] QAT training completed.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E216C0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E216C0>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E224D0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E224D0>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E20C10>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E20C10>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3B250>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3B250>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D383A0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D383A0>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D388B0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D388B0>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3A4D0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3A4D0>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3B370>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3B370>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3AD40>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3AD40>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3BE20>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3BE20>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3AC20>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3AC20>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D39090>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D39090>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D38F70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D38F70>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3B250>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3B250>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D39F30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D39F30>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19AEDE8C0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19AEDE8C0>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19AEDC790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19AEDC790>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19AEDFEB0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19AEDFEB0>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19AEDCA60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19AEDCA60>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19AEDCCA0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19AEDCCA0>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19AEDF0A0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19AEDF0A0>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19AEDC670>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19AEDC670>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[HOOK] Performing QAT training hook.
[HOOK] QAT epoch 1/5 started.
[HOOK][Epoch: 1] Batch 1 Loss: 0.7891
[HOOK][Epoch: 1] Batch 51 Loss: 0.0447
[HOOK][Epoch: 1] Batch 101 Loss: 0.3842
[HOOK][Epoch: 1] Batch 151 Loss: 0.2421
[HOOK][Epoch: 1] Batch 201 Loss: 0.5678
[HOOK][Epoch: 1] Batch 251 Loss: 0.2502
[HOOK][Epoch: 1] Batch 301 Loss: 0.3740
[HOOK][Epoch: 1] Batch 351 Loss: 0.1429
[HOOK][Epoch: 1] Batch 401 Loss: 0.0626
[HOOK][Epoch: 1] Batch 451 Loss: 0.0565
[HOOK][Epoch: 1] Batch 501 Loss: 0.0949
[HOOK][Epoch: 1] Batch 551 Loss: 0.1525
[HOOK][Epoch: 1] Batch 601 Loss: 0.2209
[HOOK] QAT epoch 2/5 started.
[HOOK][Epoch: 2] Batch 1 Loss: 0.1394
[HOOK][Epoch: 2] Batch 51 Loss: 0.0982
[HOOK][Epoch: 2] Batch 101 Loss: 0.1073
[HOOK][Epoch: 2] Batch 151 Loss: 0.2540
[HOOK][Epoch: 2] Batch 201 Loss: 0.0421
[HOOK][Epoch: 2] Batch 251 Loss: 0.0887
[HOOK][Epoch: 2] Batch 301 Loss: 0.0574
[HOOK][Epoch: 2] Batch 351 Loss: 0.0060
[HOOK][Epoch: 2] Batch 401 Loss: 0.2204
[HOOK][Epoch: 2] Batch 451 Loss: 0.1347
[HOOK][Epoch: 2] Batch 501 Loss: 0.0448
[HOOK][Epoch: 2] Batch 551 Loss: 0.1470
[HOOK][Epoch: 2] Batch 601 Loss: 0.0516
[HOOK] QAT epoch 3/5 started.
[HOOK][Epoch: 3] Batch 1 Loss: 0.0131
[HOOK][Epoch: 3] Batch 51 Loss: 0.0178
[HOOK][Epoch: 3] Batch 101 Loss: 0.0085
[HOOK][Epoch: 3] Batch 151 Loss: 0.0747
[HOOK][Epoch: 3] Batch 201 Loss: 0.0373
[HOOK][Epoch: 3] Batch 251 Loss: 0.0549
[HOOK][Epoch: 3] Batch 301 Loss: 0.0040
[HOOK][Epoch: 3] Batch 351 Loss: 0.0679
[HOOK][Epoch: 3] Batch 401 Loss: 0.0032
[HOOK][Epoch: 3] Batch 451 Loss: 0.0585
[HOOK][Epoch: 3] Batch 501 Loss: 0.0075
[HOOK][Epoch: 3] Batch 551 Loss: 0.0042
[HOOK][Epoch: 3] Batch 601 Loss: 0.0230
[HOOK] QAT epoch 4/5 started.
[HOOK][Epoch: 4] Batch 1 Loss: 0.0063
[HOOK][Epoch: 4] Batch 51 Loss: 0.0136
[HOOK][Epoch: 4] Batch 101 Loss: 0.0385
[HOOK][Epoch: 4] Batch 151 Loss: 0.0287
[HOOK][Epoch: 4] Batch 201 Loss: 0.0115
[HOOK][Epoch: 4] Batch 251 Loss: 0.0035
[HOOK][Epoch: 4] Batch 301 Loss: 0.0207
[HOOK][Epoch: 4] Batch 351 Loss: 0.0215
[HOOK][Epoch: 4] Batch 401 Loss: 0.0526
[HOOK][Epoch: 4] Batch 451 Loss: 0.0034
[HOOK][Epoch: 4] Batch 501 Loss: 0.0033
[HOOK][Epoch: 4] Batch 551 Loss: 0.0019
[HOOK][Epoch: 4] Batch 601 Loss: 0.0798
[HOOK] QAT epoch 5/5 started.
[HOOK][Epoch: 5] Batch 1 Loss: 0.0003
[HOOK][Epoch: 5] Batch 51 Loss: 0.0026
[HOOK][Epoch: 5] Batch 101 Loss: 0.0470
[HOOK][Epoch: 5] Batch 151 Loss: 0.0134
[HOOK][Epoch: 5] Batch 201 Loss: 0.0056
[HOOK][Epoch: 5] Batch 251 Loss: 0.0114
[HOOK][Epoch: 5] Batch 301 Loss: 0.0006
[HOOK][Epoch: 5] Batch 351 Loss: 0.0053
[HOOK][Epoch: 5] Batch 401 Loss: 0.0133
[HOOK][Epoch: 5] Batch 451 Loss: 0.0019
[HOOK][Epoch: 5] Batch 501 Loss: 0.0127
[HOOK][Epoch: 5] Batch 551 Loss: 0.0156
[HOOK][Epoch: 5] Batch 601 Loss: 0.0329
[HOOK] QAT training completed.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:08, 17.38it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:09, 16.86it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:09, 16.76it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 16.72it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:08, 16.74it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:08, 16.62it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:08, 16.54it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:08, 16.49it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:01<00:08, 16.37it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:08, 16.29it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:08, 16.24it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:08, 16.16it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:08, 16.18it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:07, 16.32it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:07, 16.38it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:07, 16.42it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:02<00:07, 16.41it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:02<00:07, 16.48it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:07, 16.57it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:06, 16.76it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:06, 16.77it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:06, 16.82it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:06, 16.81it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:06, 16.72it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:03<00:06, 16.62it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:03<00:06, 16.67it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:06, 16.66it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:06, 16.54it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 16.57it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 16.51it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 16.51it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 16.64it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:05, 16.68it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:04<00:05, 16.67it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:04<00:05, 16.67it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:05, 16.54it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:05, 16.53it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 16.48it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 16.66it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 16.61it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 16.75it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:05<00:04, 16.72it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:05<00:04, 16.78it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:04, 16.66it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:04, 16.66it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 16.78it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 16.83it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 16.82it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 16.77it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:06<00:03, 16.69it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:06<00:03, 16.64it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:06<00:03, 16.52it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:03, 16.72it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 16.70it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 16.73it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 16.71it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 16.52it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 16.60it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:07<00:02, 16.54it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:07<00:02, 16.57it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:07<00:02, 16.59it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 16.74it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 16.67it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 16.66it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 16.66it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 16.70it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:08<00:01, 16.56it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:08<00:01, 16.67it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:08<00:01, 16.66it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:08<00:01, 16.62it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 16.63it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 16.72it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 16.70it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 16.48it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:09<00:00, 16.53it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:09<00:00, 16.53it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:09<00:00, 16.44it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:09<00:00, 16.46it/s][A100%|#####################################################################################################################################################| 157/157 [00:09<00:00, 16.64it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:09, 15.73it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:09, 16.11it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:09, 16.41it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 16.67it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:08, 16.66it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:08, 16.52it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:08, 16.65it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:08, 16.65it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:01<00:08, 16.70it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:08, 16.99it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:08, 16.75it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:07, 16.77it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 16.69it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:07, 16.68it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:07, 16.63it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:07, 16.76it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:02<00:07, 16.73it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:02<00:07, 16.75it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:07, 16.80it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:06, 16.76it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:06, 16.85it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:06, 16.96it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:06, 16.78it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:06, 16.66it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:02<00:06, 16.78it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:03<00:06, 16.66it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:06, 16.91it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:06, 16.79it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 16.79it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 16.88it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 16.68it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 16.80it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:05, 16.92it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:04<00:05, 17.10it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:04<00:05, 17.14it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:04, 17.12it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:04, 16.93it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 16.85it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 16.83it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 16.78it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 16.78it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:05<00:04, 16.78it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:05<00:04, 16.79it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:04, 16.75it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:04, 16.68it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 16.63it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 16.59it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 16.65it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 16.78it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 16.91it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:06<00:03, 16.96it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:06<00:03, 17.08it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:03, 16.87it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 16.84it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 16.91it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 16.96it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 16.83it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 16.90it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:07<00:02, 16.91it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:07<00:02, 17.00it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:07<00:02, 16.94it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 16.94it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 16.68it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 16.76it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 16.73it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 16.74it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 16.80it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:08<00:01, 16.80it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:08<00:01, 16.88it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:08<00:01, 16.90it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 16.82it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 16.77it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 16.73it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 16.75it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 16.81it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:09<00:00, 16.72it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:09<00:00, 16.66it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:09<00:00, 16.70it/s][A100%|#####################################################################################################################################################| 157/157 [00:09<00:00, 16.82it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:09, 16.51it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 17.10it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 17.22it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 17.11it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:08, 17.15it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:08, 17.28it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:08, 17.46it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:08, 17.38it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:01<00:07, 17.38it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 17.29it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 17.31it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:07, 17.38it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 17.47it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:07, 17.58it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:07, 17.80it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:07, 17.48it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:07, 17.45it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:02<00:12, 10.05it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:10, 11.51it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:09, 12.91it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:08, 13.93it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:07, 14.74it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:07, 15.27it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:03<00:06, 15.73it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:03<00:06, 16.11it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:03<00:06, 16.35it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:06, 16.44it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:06, 16.67it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 16.92it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 16.97it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 17.04it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 16.97it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:04<00:05, 16.87it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:04<00:05, 16.93it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:04<00:05, 17.02it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:05, 16.91it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:04, 16.70it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 16.77it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 16.86it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 16.71it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:05<00:04, 16.82it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:05<00:04, 16.90it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:05<00:04, 17.00it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:04, 16.93it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:03, 16.98it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 16.92it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 16.84it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 17.00it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:06<00:03, 16.93it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:06<00:03, 17.02it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:06<00:03, 16.95it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:06<00:03, 17.03it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:03, 16.92it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 16.92it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 16.97it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 16.87it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 16.64it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:07<00:02, 16.94it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:07<00:02, 16.94it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:07<00:02, 16.89it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:07<00:02, 16.95it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 17.03it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 17.09it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 17.35it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 17.18it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:08<00:01, 16.97it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:08<00:01, 16.96it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:08<00:01, 17.13it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:08<00:01, 17.16it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:08<00:00, 17.05it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 17.01it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 16.99it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 16.93it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 16.93it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:09<00:00, 17.02it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:09<00:00, 16.95it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:09<00:00, 16.99it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:09<00:00, 16.93it/s][A100%|#####################################################################################################################################################| 157/157 [00:09<00:00, 16.61it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:09, 16.25it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 17.06it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 17.27it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 17.49it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:08, 17.34it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:08, 17.67it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:07, 17.93it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:07, 17.85it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:01<00:07, 17.75it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 17.88it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 18.01it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:08, 16.39it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 16.68it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:07, 16.97it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:07, 17.31it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:07, 17.42it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:07, 17.55it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:02<00:06, 17.73it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:06, 17.81it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:06, 17.82it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:06, 17.78it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:06, 17.75it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:06, 17.78it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:06, 17.94it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:02<00:05, 17.91it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:02<00:05, 17.99it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:05, 17.85it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:05, 17.80it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 17.86it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 17.85it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 17.71it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 17.94it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:05, 17.91it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:03<00:04, 17.89it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:03<00:04, 17.83it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:04, 17.83it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:05, 14.13it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:05, 15.17it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 15.81it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 16.21it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 16.54it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:04<00:04, 16.83it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:04<00:04, 16.94it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:04, 17.03it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:03, 17.13it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 17.16it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 17.45it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 17.47it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 17.22it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 17.31it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:05<00:03, 17.15it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:06<00:03, 17.09it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:02, 17.08it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 17.04it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 17.05it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 17.02it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 17.03it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 17.14it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:06<00:02, 17.03it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:06<00:02, 17.13it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:07<00:02, 17.20it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 17.12it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 17.15it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 17.09it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 17.13it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 17.07it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 16.99it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:07<00:01, 17.06it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:08<00:01, 17.02it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:08<00:00, 17.08it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 17.04it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 17.14it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 17.16it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 17.09it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 17.13it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:08<00:00, 16.99it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:08<00:00, 17.10it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:09<00:00, 17.18it/s][A100%|#####################################################################################################################################################| 157/157 [00:09<00:00, 17.26it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:08, 17.53it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 17.90it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 18.09it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 17.87it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:08, 17.91it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:08, 17.89it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:07, 17.93it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:07, 18.05it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:00<00:07, 18.19it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 18.23it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 18.11it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:07, 18.13it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 17.94it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:07, 18.01it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:07, 18.11it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:06, 18.17it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:06, 18.17it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:01<00:06, 18.22it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:10, 10.84it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:09, 12.31it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:08, 13.41it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:07, 14.43it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:07, 15.13it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:06, 15.74it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:03<00:06, 16.16it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:03<00:06, 16.47it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:06, 16.65it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:06, 16.69it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 16.72it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 16.78it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 16.87it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 16.89it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:05, 16.95it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:04<00:05, 16.94it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:04<00:05, 16.90it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:05, 16.91it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:04, 17.00it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 17.07it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 17.03it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 17.17it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 17.10it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:05<00:04, 17.27it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:05<00:04, 17.30it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:04, 17.15it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:03, 17.13it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 17.02it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 17.04it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 17.05it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 16.84it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 17.00it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:06<00:03, 16.81it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:06<00:03, 16.76it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:03, 16.69it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 16.76it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 16.60it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 16.66it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 16.82it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 16.94it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:07<00:02, 16.98it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:07<00:02, 16.97it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:07<00:02, 16.87it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 17.06it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 17.11it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 17.23it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 17.23it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 17.19it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 17.20it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:08<00:01, 17.30it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:08<00:01, 17.14it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:08<00:00, 17.17it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 17.14it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 17.08it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 16.95it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 16.90it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 16.91it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:09<00:00, 16.96it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:09<00:00, 17.08it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:09<00:00, 17.13it/s][A100%|#####################################################################################################################################################| 157/157 [00:09<00:00, 16.87it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:08, 17.84it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 17.94it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 18.11it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 18.07it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:08, 18.16it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:08, 18.05it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:07, 18.20it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:07, 18.03it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:00<00:07, 18.17it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 18.27it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 18.40it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:07, 16.91it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 17.36it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:07, 17.46it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:07, 17.86it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:06, 18.19it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:06, 18.19it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:02<00:06, 18.23it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:06, 18.26it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:06, 18.18it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:06, 18.28it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:06, 18.34it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:06, 18.44it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:05, 18.36it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:02<00:05, 18.45it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:02<00:05, 18.47it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:02<00:05, 18.22it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:05, 18.41it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 18.23it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 18.21it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 18.25it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 18.32it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:04, 18.28it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:03<00:04, 18.29it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:03<00:04, 18.35it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:03<00:04, 18.20it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:04, 18.24it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 18.12it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:05, 13.75it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:05, 14.93it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 15.85it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:04<00:04, 16.52it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:04<00:04, 16.98it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:04<00:03, 17.32it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:03, 17.61it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 17.82it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 17.92it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 18.00it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 17.76it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 17.78it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:05<00:03, 17.66it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:05<00:03, 17.67it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:05<00:02, 17.58it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 17.66it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 17.39it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 17.38it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 17.47it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 17.54it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:06<00:02, 17.40it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:06<00:02, 17.44it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:06<00:01, 17.55it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:06<00:01, 17.64it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 17.51it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 17.52it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 17.47it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 17.58it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 17.47it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:07<00:01, 17.40it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:07<00:01, 17.35it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:07<00:00, 17.45it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 17.38it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 17.24it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 17.02it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 17.04it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 16.88it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:08<00:00, 15.81it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:08<00:00, 15.39it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:08<00:00, 15.07it/s][A100%|#####################################################################################################################################################| 157/157 [00:08<00:00, 17.48it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:10, 14.27it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:11, 13.86it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:10, 13.87it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:10, 13.95it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:10, 13.85it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:10, 13.67it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:01<00:10, 13.55it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:01<00:10, 13.57it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:01<00:09, 14.24it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:09, 14.84it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:08, 15.31it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:08, 15.59it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:08, 15.67it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:08, 16.03it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:02<00:13,  9.47it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:02<00:11, 10.81it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:02<00:10, 12.04it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:02<00:09, 13.14it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:08, 13.88it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:08, 14.55it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:03<00:07, 14.95it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:03<00:07, 15.14it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:03<00:07, 15.11it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:03<00:07, 15.32it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:03<00:06, 15.48it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:03<00:06, 15.56it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:06, 15.68it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:06, 15.88it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:04<00:06, 15.99it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:04<00:06, 16.07it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:04<00:05, 15.97it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:04<00:05, 15.97it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:04<00:05, 16.05it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:04<00:05, 16.19it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:04<00:05, 16.13it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:05, 16.12it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:05<00:05, 16.24it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:05<00:04, 16.24it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:05<00:04, 16.12it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:05<00:04, 16.08it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:05<00:04, 16.05it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:05<00:04, 16.03it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:05<00:04, 15.98it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:04, 15.83it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:06<00:04, 15.84it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:06<00:04, 15.96it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:06<00:03, 15.89it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:06<00:03, 16.00it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:06<00:03, 15.99it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:06<00:03, 15.95it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:06<00:03, 15.96it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:06<00:03, 16.01it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:07<00:03, 16.00it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:07<00:03, 15.96it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:07<00:02, 15.97it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:07<00:02, 16.05it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:07<00:02, 16.07it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:07<00:02, 15.89it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:07<00:02, 15.81it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:07<00:02, 15.90it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:08<00:02, 16.00it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:08<00:02, 16.15it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:08<00:01, 15.80it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:08<00:01, 15.89it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:08<00:01, 15.92it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:08<00:01, 15.90it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:08<00:01, 15.89it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:08<00:01, 15.92it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:09<00:01, 15.90it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:09<00:01, 15.85it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:09<00:00, 15.81it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:09<00:00, 15.87it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:09<00:00, 15.90it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:09<00:00, 15.93it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:09<00:00, 15.79it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:09<00:00, 15.66it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:10<00:00, 15.68it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:10<00:00, 15.85it/s][A100%|#####################################################################################################################################################| 157/157 [00:10<00:00, 15.32it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:09, 15.61it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:09, 15.76it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:09, 16.03it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:09, 15.91it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:09, 15.99it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:09, 16.03it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:08, 16.14it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:08, 16.09it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:01<00:08, 16.10it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:09, 14.99it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:08, 15.46it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:08, 15.84it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:08, 15.96it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:08, 16.09it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:07, 16.25it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:02<00:07, 16.33it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:02<00:07, 16.22it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:02<00:07, 16.27it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:07, 16.42it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:07, 16.29it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:07, 16.20it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:06, 16.29it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:06, 16.28it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:06, 16.31it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:03<00:06, 16.37it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:03<00:06, 16.49it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:06, 16.54it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:06, 16.57it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 16.56it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 16.67it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 16.66it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 16.58it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:04<00:05, 16.52it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:04<00:06, 12.73it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:04<00:06, 13.56it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:05, 14.33it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:05, 14.92it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:05, 15.36it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:05, 15.69it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:05<00:04, 15.89it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:05<00:04, 16.19it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:05<00:04, 16.25it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:05<00:04, 16.29it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:04, 16.39it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:04, 16.43it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 16.41it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 16.28it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:06<00:03, 16.23it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:06<00:03, 16.24it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:06<00:03, 16.20it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:06<00:03, 16.29it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:06<00:03, 16.20it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:03, 16.41it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 16.36it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 16.21it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:07<00:02, 16.22it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:07<00:02, 16.23it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:07<00:02, 16.15it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:07<00:02, 16.10it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:07<00:02, 16.07it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:07<00:02, 16.56it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 16.97it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 17.18it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 17.28it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:08<00:01, 17.40it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:08<00:01, 17.39it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:08<00:01, 17.39it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:08<00:01, 17.12it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:08<00:01, 17.02it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:08<00:00, 17.21it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 17.17it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 17.06it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 17.15it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:09<00:00, 17.17it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:09<00:00, 17.28it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:09<00:00, 17.26it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:09<00:00, 17.21it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:09<00:00, 17.08it/s][A100%|#####################################################################################################################################################| 157/157 [00:09<00:00, 16.33it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:09, 17.08it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 17.08it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 17.21it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 17.22it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:08, 17.33it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:08, 17.45it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:08, 17.47it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:08, 17.35it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:01<00:07, 17.55it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 17.73it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 17.91it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:07, 18.04it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 18.13it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:07, 18.24it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:06, 18.22it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:06, 18.20it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:07, 15.85it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:02<00:11, 10.77it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:09, 12.29it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:08, 13.59it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:07, 14.73it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:07, 15.54it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:06, 16.13it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:06, 16.52it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:03<00:06, 16.81it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:03<00:06, 17.07it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:06, 17.11it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:05, 17.19it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 17.07it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 17.20it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 17.08it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 17.21it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:05, 17.40it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:04<00:05, 17.43it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:04<00:04, 17.42it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:04, 17.40it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:04, 17.44it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 17.51it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 17.52it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 17.57it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 17.70it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:05<00:04, 17.69it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:05<00:04, 17.64it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:03, 17.61it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:03, 17.68it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 17.87it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 17.81it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 17.63it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 17.69it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 17.64it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:06<00:03, 17.38it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:06<00:03, 17.42it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:02, 17.45it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 17.43it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 17.28it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 17.54it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 17.72it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 17.66it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:06<00:02, 17.72it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:07<00:02, 17.80it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:07<00:01, 17.86it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 17.81it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 17.82it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 17.78it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 17.70it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 17.60it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 17.49it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:07<00:01, 17.55it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:08<00:01, 17.54it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:08<00:00, 17.72it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 17.62it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 17.64it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 17.60it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 17.77it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 17.74it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:08<00:00, 17.77it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:08<00:00, 17.75it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:09<00:00, 17.73it/s][A100%|#####################################################################################################################################################| 157/157 [00:09<00:00, 17.20it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:08, 17.38it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 18.41it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 18.38it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 18.56it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:07, 18.42it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:07, 18.33it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:07, 18.28it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:07, 18.24it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:00<00:07, 18.37it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 18.41it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 17.13it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:07, 17.43it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 17.79it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:07, 18.00it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:06, 18.25it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:06, 18.32it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:06, 18.43it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:01<00:06, 18.40it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:06, 18.43it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:06, 18.71it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:06, 18.49it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:06, 18.34it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:06, 18.39it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:05, 18.53it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:02<00:05, 18.42it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:02<00:05, 18.49it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:02<00:05, 18.65it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:05, 18.61it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 18.52it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 18.57it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 18.50it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 18.45it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:04, 18.41it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:03<00:04, 18.39it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:03<00:04, 18.47it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:03<00:04, 18.48it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:04, 18.44it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 18.46it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:05, 14.37it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:05, 15.40it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 16.21it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:04<00:04, 16.80it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:04<00:04, 17.32it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:04<00:03, 17.61it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:03, 17.77it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 17.75it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 18.02it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 18.21it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 18.05it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 17.94it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:05<00:03, 17.81it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:05<00:02, 17.77it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:05<00:02, 17.65it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 17.85it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 17.85it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 17.89it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 18.07it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 17.95it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:06<00:02, 16.58it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:06<00:02, 16.90it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:06<00:02, 17.21it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:06<00:01, 17.44it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 17.42it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 17.50it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 17.60it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 17.63it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 17.60it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:07<00:01, 17.76it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:07<00:01, 17.79it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:07<00:00, 17.95it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:07<00:00, 17.91it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 17.80it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 17.95it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 17.97it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 17.88it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:08<00:00, 17.92it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:08<00:00, 17.94it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:08<00:00, 17.77it/s][A100%|#####################################################################################################################################################| 157/157 [00:08<00:00, 17.92it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:08, 17.68it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 18.35it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 18.34it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 18.47it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:07, 18.48it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:07, 18.55it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:07, 18.31it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:07, 18.42it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:00<00:07, 18.56it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 18.59it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 18.62it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:07, 18.79it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 18.71it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:06, 18.80it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:06, 18.92it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:06, 18.85it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:06, 19.18it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:01<00:07, 16.73it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:10, 11.23it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:09, 12.78it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:08, 14.18it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:07, 15.18it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:06, 15.93it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:06, 16.46it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:02<00:06, 16.85it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:03<00:06, 17.14it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:05, 17.25it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:05, 17.33it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 17.44it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 17.42it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 17.45it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 17.47it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:05, 17.63it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:03<00:05, 17.65it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:04<00:04, 17.75it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:04, 17.87it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:04, 17.82it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 18.02it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 18.01it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 17.96it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 17.83it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:04<00:04, 17.88it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:04<00:03, 17.77it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:03, 17.84it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:03, 17.79it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 17.81it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 17.77it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 17.79it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 17.76it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 17.74it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:05<00:03, 17.86it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:05<00:02, 17.76it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:02, 17.88it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 17.87it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 17.96it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 17.83it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 17.78it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 17.85it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:06<00:02, 17.75it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:06<00:02, 17.83it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:06<00:01, 17.93it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 17.85it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 17.95it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 18.01it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 17.96it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 17.88it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 17.82it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:07<00:01, 17.73it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:07<00:01, 17.62it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:08<00:00, 17.73it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 17.81it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 17.87it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 17.72it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 17.71it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 17.89it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:08<00:00, 17.83it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:08<00:00, 17.78it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:08<00:00, 17.80it/s][A100%|#####################################################################################################################################################| 157/157 [00:08<00:00, 17.58it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:08, 18.33it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 18.63it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 18.81it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:07, 18.83it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:07, 19.03it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:07, 19.15it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:07, 18.82it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:07, 19.00it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:00<00:07, 19.07it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 19.06it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 17.66it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:07, 17.95it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 18.42it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:06, 18.65it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:06, 18.71it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:06, 18.86it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:06, 18.80it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:01<00:06, 18.82it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:06, 18.88it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:06, 18.98it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:06, 18.94it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:05, 18.91it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:05, 18.95it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:05, 19.03it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:02<00:05, 19.19it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:02<00:05, 19.09it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:02<00:05, 19.07it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:02<00:05, 19.17it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 19.13it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 19.15it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:04, 19.12it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:04, 19.26it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:04, 19.24it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:03<00:04, 19.18it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:03<00:04, 19.30it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:03<00:04, 19.11it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:03<00:04, 19.19it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 19.31it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 19.34it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:05, 14.73it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 15.77it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:04<00:04, 16.62it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:04<00:04, 17.37it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:04<00:03, 17.83it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:04<00:03, 18.13it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:04<00:03, 18.54it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 18.63it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 18.75it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 18.62it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 18.48it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:05<00:02, 18.39it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:05<00:02, 18.22it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:05<00:02, 18.20it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:05<00:02, 18.34it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:05<00:02, 18.34it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 18.29it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 18.45it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 18.42it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:06<00:02, 18.19it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:06<00:02, 18.08it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:06<00:01, 18.01it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:06<00:01, 18.01it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:06<00:01, 17.86it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:06<00:01, 17.95it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 18.01it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 18.06it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 17.90it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:07<00:01, 17.98it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:07<00:01, 17.89it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:07<00:00, 17.87it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:07<00:00, 17.91it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:07<00:00, 17.89it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:07<00:00, 17.92it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 17.95it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 17.68it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:08<00:00, 17.82it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:08<00:00, 17.83it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:08<00:00, 17.83it/s][A100%|#####################################################################################################################################################| 157/157 [00:08<00:00, 18.41it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:08, 18.16it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 18.56it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:07, 19.02it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:07, 19.17it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:07, 19.05it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:07, 18.98it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:07, 19.24it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:07, 19.35it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:00<00:07, 19.36it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 19.43it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:06, 19.60it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:06, 19.36it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:06, 19.26it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:06, 19.25it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:06, 19.29it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:06, 19.21it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:06, 19.27it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:01<00:07, 17.25it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:07, 15.52it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:10, 11.55it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:08, 13.15it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:07, 14.27it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:07, 15.22it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:06, 15.88it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:02<00:06, 16.42it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:03<00:06, 16.95it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:05, 17.21it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:05, 17.44it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 17.51it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 17.66it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 17.66it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 17.76it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:05, 17.74it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:03<00:04, 17.82it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:04<00:04, 17.78it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:04, 17.75it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:04, 17.78it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 17.99it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 18.09it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 18.01it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 18.01it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:04<00:04, 18.11it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:04<00:03, 18.12it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:03, 18.24it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:03, 18.02it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 18.06it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 17.95it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 17.96it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 18.12it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 18.09it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:05<00:03, 17.96it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:05<00:02, 18.02it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:02, 18.21it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 18.15it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 18.20it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 18.14it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 18.15it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 18.10it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:06<00:02, 18.07it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:06<00:02, 18.10it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:06<00:01, 18.12it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 18.08it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 18.01it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 17.96it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 17.97it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 18.18it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 18.17it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:07<00:01, 18.17it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:07<00:01, 18.22it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:07<00:00, 18.10it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:07<00:00, 18.07it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 18.05it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 18.13it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 18.14it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 18.10it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:08<00:00, 18.12it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:08<00:00, 17.99it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:08<00:00, 17.94it/s][A100%|#####################################################################################################################################################| 157/157 [00:08<00:00, 17.83it/s]

  0%|                                                                                                                                                               | 0/313 [00:00<?, ?it/s][A
  0%|4                                                                                                                                                      | 1/313 [00:00<01:03,  4.92it/s][A
  1%|9                                                                                                                                                      | 2/313 [00:00<01:00,  5.10it/s][A
  1%|#4                                                                                                                                                     | 3/313 [00:00<01:00,  5.11it/s][A
  1%|#9                                                                                                                                                     | 4/313 [00:00<01:00,  5.08it/s][A
  2%|##4                                                                                                                                                    | 5/313 [00:00<01:00,  5.07it/s][A
  2%|##8                                                                                                                                                    | 6/313 [00:01<01:00,  5.09it/s][A
  2%|###3                                                                                                                                                   | 7/313 [00:01<01:41,  3.01it/s][A
  3%|###8                                                                                                                                                   | 8/313 [00:01<01:28,  3.45it/s][A
  3%|####3                                                                                                                                                  | 9/313 [00:02<01:19,  3.83it/s][A
  3%|####7                                                                                                                                                 | 10/313 [00:02<01:13,  4.13it/s][A
  4%|#####2                                                                                                                                                | 11/313 [00:02<01:08,  4.38it/s][A
  4%|#####7                                                                                                                                                | 12/313 [00:02<01:05,  4.57it/s][A
  4%|######2                                                                                                                                               | 13/313 [00:02<01:03,  4.73it/s][A
  4%|######7                                                                                                                                               | 14/313 [00:03<01:01,  4.83it/s][A
  5%|#######1                                                                                                                                              | 15/313 [00:03<01:00,  4.91it/s][A
  5%|#######6                                                                                                                                              | 16/313 [00:03<00:59,  4.97it/s][A
  5%|########1                                                                                                                                             | 17/313 [00:03<00:58,  5.06it/s][A
  6%|########6                                                                                                                                             | 18/313 [00:03<00:57,  5.14it/s][A
  6%|#########1                                                                                                                                            | 19/313 [00:04<00:57,  5.13it/s][A
  6%|#########5                                                                                                                                            | 20/313 [00:04<00:56,  5.14it/s][A
  7%|##########                                                                                                                                            | 21/313 [00:04<00:56,  5.18it/s][A
  7%|##########5                                                                                                                                           | 22/313 [00:04<00:56,  5.19it/s][A
  7%|###########                                                                                                                                           | 23/313 [00:04<00:55,  5.20it/s][A
  8%|###########5                                                                                                                                          | 24/313 [00:05<00:55,  5.22it/s][A
  8%|###########9                                                                                                                                          | 25/313 [00:05<00:55,  5.19it/s][A
  8%|############4                                                                                                                                         | 26/313 [00:05<00:55,  5.18it/s][A
  9%|############9                                                                                                                                         | 27/313 [00:05<00:55,  5.18it/s][A
  9%|#############4                                                                                                                                        | 28/313 [00:05<00:54,  5.21it/s][A
  9%|#############8                                                                                                                                        | 29/313 [00:06<00:54,  5.20it/s][A
 10%|##############3                                                                                                                                       | 30/313 [00:06<00:54,  5.20it/s][A
 10%|##############8                                                                                                                                       | 31/313 [00:06<00:53,  5.23it/s][A
 10%|###############3                                                                                                                                      | 32/313 [00:06<00:54,  5.18it/s][A 10%|###############3                                                                                                                                      | 32/313 [00:06<00:58,  4.81it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:08, 17.38it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 17.29it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 17.33it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 17.23it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:08, 17.44it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:08, 17.58it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:08, 17.71it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:08, 17.60it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:01<00:08, 17.30it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:08, 17.09it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 17.04it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:07, 16.92it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 16.97it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:07, 16.96it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:07, 16.82it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:07, 16.81it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:07, 16.81it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:02<00:07, 16.84it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:07, 16.74it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:06, 16.72it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:06, 16.74it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:06, 16.63it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:06, 16.72it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:06, 16.78it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:02<00:06, 16.74it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:03<00:06, 16.84it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:06, 16.70it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:06, 16.73it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 16.62it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 16.59it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 16.61it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 16.58it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:05, 16.48it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:04<00:05, 16.41it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:04<00:05, 16.40it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:05, 16.31it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:05, 16.33it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 16.35it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 16.36it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 16.48it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 16.45it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:05<00:04, 16.51it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:05<00:04, 16.51it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:04, 16.76it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:04, 16.60it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 16.54it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 16.74it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 16.80it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 16.84it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 16.74it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:06<00:03, 16.75it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:06<00:03, 16.68it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:03, 16.63it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 16.64it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 16.60it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 16.62it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 16.75it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 16.72it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:07<00:02, 16.74it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:07<00:02, 16.51it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:07<00:02, 16.51it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 16.68it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 16.67it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 16.71it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 16.65it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 16.65it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:08<00:01, 16.57it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:08<00:01, 16.63it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:08<00:01, 16.60it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:08<00:01, 16.61it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 16.46it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 16.60it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 16.49it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 16.62it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 16.63it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:09<00:00, 16.55it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:09<00:00, 16.62it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:09<00:00, 16.43it/s][A100%|#####################################################################################################################################################| 157/157 [00:09<00:00, 16.75it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:09, 15.86it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:09, 16.32it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:09, 16.47it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 16.70it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:08, 16.54it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:08, 16.48it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:08, 16.58it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:08, 16.65it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:01<00:08, 16.78it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:08, 16.70it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 17.03it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:07, 17.00it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 16.98it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:07, 16.88it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:07, 16.77it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:07, 16.48it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:02<00:07, 16.53it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:02<00:07, 16.74it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:07, 16.67it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:06, 16.79it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:06, 16.79it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:06, 16.83it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:06, 16.99it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:06, 16.93it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:02<00:06, 16.93it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:03<00:06, 16.89it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:06, 16.73it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:06, 16.63it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 16.63it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 16.81it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 16.93it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 16.89it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:05, 16.82it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:04<00:05, 16.94it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:04<00:05, 16.77it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:05, 16.61it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:04, 16.66it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 16.74it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 16.63it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 16.81it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 16.80it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:05<00:04, 16.76it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:05<00:04, 16.98it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:04, 17.14it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:03, 17.08it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 17.03it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 16.92it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 16.97it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 16.87it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 16.85it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:06<00:03, 16.87it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:06<00:03, 16.93it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:03, 16.81it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 16.76it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 16.90it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 16.86it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 16.80it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 16.93it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:07<00:02, 16.72it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:07<00:02, 16.70it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:07<00:02, 16.81it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 16.76it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 16.77it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 16.78it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 16.66it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 16.74it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 16.75it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:08<00:01, 16.89it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:08<00:01, 16.82it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:08<00:01, 16.94it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 16.89it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 16.82it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 16.69it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 16.76it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 16.85it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:09<00:00, 16.79it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:09<00:00, 16.79it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:09<00:00, 16.71it/s][A100%|#####################################################################################################################################################| 157/157 [00:09<00:00, 16.83it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:09, 16.38it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 17.04it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 17.39it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 17.45it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:08, 17.42it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:08, 17.46it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:08, 17.58it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:08, 17.47it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:01<00:07, 17.53it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 17.68it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 17.73it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:07, 17.48it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 17.54it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:07, 17.58it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:07, 17.71it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:07, 17.70it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:06, 17.65it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:02<00:11, 10.70it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:09, 12.16it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:08, 13.28it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:08, 14.17it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:07, 14.94it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:07, 15.52it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:06, 15.88it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:03<00:06, 16.18it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:03<00:06, 16.36it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:06, 16.61it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:06, 16.66it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 16.66it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 16.78it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 17.00it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 17.02it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:04<00:05, 17.00it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:04<00:05, 16.89it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:04<00:05, 16.90it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:05, 16.87it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:04, 16.76it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 16.69it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 16.68it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 16.79it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:05<00:04, 16.75it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:05<00:04, 16.68it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:05<00:04, 16.80it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:04, 16.63it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:04, 16.68it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 16.71it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 16.65it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 16.78it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 16.74it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:06<00:03, 16.84it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:06<00:03, 16.74it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:06<00:03, 16.63it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:03, 16.64it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 16.85it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 16.79it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 16.88it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 16.85it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:07<00:02, 16.96it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:07<00:02, 16.87it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:07<00:02, 16.84it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:07<00:02, 16.79it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 16.83it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 16.86it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 16.88it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 16.81it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 16.76it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:08<00:01, 16.81it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:08<00:01, 16.85it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:08<00:01, 16.96it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:08<00:01, 16.95it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 16.78it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 16.87it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 16.93it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 17.10it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:09<00:00, 16.88it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:09<00:00, 16.94it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:09<00:00, 16.85it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:09<00:00, 16.79it/s][A100%|#####################################################################################################################################################| 157/157 [00:09<00:00, 16.61it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:09, 16.51it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 17.63it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 17.44it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 17.78it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:08, 17.98it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:08, 17.77it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:08, 17.64it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:08, 17.60it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:01<00:07, 17.82it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 17.83it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 17.74it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:08, 16.23it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 16.77it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:07, 17.08it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:07, 17.26it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:07, 17.29it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:07, 17.36it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:02<00:06, 17.41it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:06, 17.49it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:06, 17.69it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:06, 17.83it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:06, 17.74it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:06, 17.86it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:06, 17.62it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:02<00:06, 17.69it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:02<00:05, 17.69it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:05, 17.59it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:05, 17.57it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 17.56it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 17.50it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 17.56it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 17.59it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:05, 17.86it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:03<00:05, 17.66it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:03<00:04, 17.76it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:04, 17.83it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:05, 14.04it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:05, 15.07it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:05, 15.69it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 16.36it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 16.86it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:04<00:04, 17.19it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:04<00:04, 17.38it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:03, 17.42it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:03, 17.59it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 17.62it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 17.73it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 17.67it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 17.40it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 17.26it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:05<00:03, 17.25it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:06<00:03, 17.11it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:03, 16.97it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 16.96it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 17.08it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 16.91it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 16.87it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 16.93it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:06<00:02, 17.15it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:06<00:02, 17.00it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:07<00:02, 16.89it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 16.91it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 16.91it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 16.92it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 16.84it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 16.87it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 16.80it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:07<00:01, 16.97it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:08<00:01, 17.09it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:08<00:00, 17.09it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 17.08it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 17.00it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 16.98it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 17.05it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 16.97it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:08<00:00, 17.09it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:08<00:00, 16.96it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:09<00:00, 17.04it/s][A100%|#####################################################################################################################################################| 157/157 [00:09<00:00, 17.22it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:08, 17.84it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 17.94it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 17.89it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 17.81it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:08, 17.99it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:08, 18.05it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:07, 17.93it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:07, 17.90it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:01<00:07, 17.78it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 18.05it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 18.13it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:07, 18.09it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 18.12it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:07, 18.13it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:06, 18.19it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:06, 18.18it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:06, 18.18it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:01<00:06, 18.22it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:10, 10.83it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:09, 12.35it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:08, 13.44it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:07, 14.36it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:07, 15.08it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:07, 15.55it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:03<00:06, 16.02it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:03<00:06, 16.32it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:06, 16.50it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:06, 16.67it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 16.79it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 16.92it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 16.97it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 17.09it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:05, 17.13it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:04<00:05, 17.34it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:04<00:05, 17.35it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:04, 17.27it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:04, 17.30it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 17.23it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 17.46it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 17.30it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 17.14it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:05<00:04, 17.08it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:05<00:04, 17.30it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:03, 17.28it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:03, 17.04it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 17.05it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 17.10it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 17.14it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 17.03it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 17.09it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:06<00:03, 16.96it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:06<00:03, 17.08it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:03, 16.99it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 17.19it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 17.20it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 17.12it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 17.15it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 17.09it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:07<00:02, 17.13it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:07<00:02, 17.07it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:07<00:02, 17.07it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 17.03it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 17.13it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 17.07it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 16.90it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 16.78it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 16.96it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:08<00:01, 16.99it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:08<00:01, 17.02it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:08<00:01, 16.99it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 16.98it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 16.96it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 16.87it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 16.76it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 16.90it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:09<00:00, 16.87it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:09<00:00, 16.93it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:09<00:00, 17.02it/s][A100%|#####################################################################################################################################################| 157/157 [00:09<00:00, 16.90it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:08, 17.68it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 17.87it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 18.08it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 17.92it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:08, 18.01it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:08, 18.12it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:07, 18.30it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:07, 18.25it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:00<00:07, 18.07it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 18.05it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 18.29it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:07, 17.06it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 17.57it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:07, 17.70it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:07, 17.84it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:06, 17.89it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:06, 17.97it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:02<00:06, 17.93it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:06, 18.15it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:06, 18.30it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:06, 18.31it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:06, 18.07it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:06, 18.15it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:06, 18.05it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:02<00:05, 18.19it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:02<00:05, 18.23it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:02<00:05, 18.11it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:05, 17.98it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 17.94it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 17.96it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 17.97it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 17.93it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:05, 18.10it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:03<00:04, 17.97it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:03<00:04, 18.08it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:03<00:04, 18.15it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:04, 18.16it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:05, 13.85it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:05, 14.78it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 15.69it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 16.28it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:04<00:04, 16.89it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:04<00:04, 17.16it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:04<00:03, 17.50it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:03, 17.65it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 17.75it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 17.87it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 18.01it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 17.81it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 17.77it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:05<00:03, 17.56it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:05<00:03, 17.55it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:02, 17.54it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 17.31it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 17.29it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 17.22it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 17.14it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 17.12it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:06<00:02, 17.11it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:06<00:02, 17.28it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:06<00:02, 17.22it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 17.22it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 17.31it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 17.33it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 17.25it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 17.34it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 17.17it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:07<00:01, 17.10it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:07<00:01, 17.05it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:07<00:00, 17.28it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 17.17it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 17.28it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 17.35it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 17.36it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 17.27it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:08<00:00, 17.26it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:08<00:00, 17.43it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:08<00:00, 17.37it/s][A100%|#####################################################################################################################################################| 157/157 [00:08<00:00, 17.55it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:09, 16.79it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 17.66it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 17.89it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 17.93it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:08, 18.31it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:07, 18.38it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:07, 18.25it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:07, 18.17it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:00<00:07, 18.49it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 18.23it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 18.21it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:07, 18.30it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 18.16it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:07, 18.41it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:06, 18.44it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:06, 18.56it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:06, 18.60it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:02<00:08, 14.20it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:10, 11.09it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:09, 12.54it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:08, 13.91it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:07, 14.86it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:07, 15.57it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:06, 16.07it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:03<00:06, 16.28it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:03<00:06, 16.60it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:06, 16.82it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:05, 16.98it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 16.80it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 17.05it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 17.11it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 17.23it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:05, 17.32it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:04<00:05, 17.34it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:04<00:04, 17.44it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:04, 17.37it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:04, 17.42it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 17.36it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 17.46it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 17.48it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 17.63it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:04<00:04, 17.55it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:05<00:04, 17.50it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:03, 17.42it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:03, 17.50it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 17.41it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 17.31it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 17.33it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 17.34it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 17.44it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:06<00:03, 17.38it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:06<00:03, 17.42it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:02, 17.50it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 17.51it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 17.29it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 17.27it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 17.21it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 17.22it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:06<00:02, 17.17it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:07<00:02, 17.32it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:07<00:02, 17.25it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 17.24it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 17.24it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 17.32it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 17.43it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 17.37it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 17.37it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:07<00:01, 17.60it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:08<00:01, 17.53it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:08<00:00, 17.53it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 17.35it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 17.49it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 17.50it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 17.51it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 17.15it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:08<00:00, 17.13it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:09<00:00, 17.25it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:09<00:00, 17.33it/s][A100%|#####################################################################################################################################################| 157/157 [00:09<00:00, 17.14it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:09, 16.93it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 17.37it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 17.79it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 17.94it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:08, 18.02it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:08, 18.12it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:07, 18.19it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:07, 18.29it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:00<00:07, 18.30it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 18.36it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:08, 16.84it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:07, 17.40it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 17.72it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:07, 17.81it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:06, 18.16it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:06, 18.41it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:06, 18.24it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:02<00:06, 18.22it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:06, 18.45it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:06, 18.42it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:06, 18.44it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:06, 18.51it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:05, 18.51it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:05, 18.40it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:02<00:05, 18.38it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:02<00:05, 18.27it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:02<00:05, 18.19it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:05, 18.23it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 18.16it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 18.26it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 18.49it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 18.44it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:04, 18.51it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:03<00:04, 18.56it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:03<00:04, 18.65it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:03<00:04, 18.60it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:04, 18.73it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 18.50it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:05, 13.91it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:05, 15.03it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 15.92it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:04<00:04, 16.62it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:04<00:04, 17.10it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:04<00:03, 17.50it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:03, 17.79it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 18.09it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 18.21it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 18.35it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 18.19it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 18.04it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:05<00:03, 17.79it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:05<00:02, 17.85it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:05<00:02, 17.75it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 17.59it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 17.62it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 17.50it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 17.46it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 17.57it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:06<00:02, 17.42it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:06<00:02, 17.55it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:06<00:01, 17.54it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:06<00:01, 17.49it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 17.55it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 17.68it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 17.68it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 17.73it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 17.62it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:07<00:01, 17.69it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:07<00:01, 17.69it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:07<00:00, 17.68it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:07<00:00, 17.54it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 17.49it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 17.46it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 17.52it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 17.48it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:08<00:00, 17.45it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:08<00:00, 17.38it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:08<00:00, 17.42it/s][A100%|#####################################################################################################################################################| 157/157 [00:08<00:00, 17.80it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:08, 17.53it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 18.28it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 18.38it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 18.16it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:08, 18.35it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:07, 18.40it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:07, 18.38it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:07, 18.42it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:00<00:07, 18.44it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 18.57it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 18.71it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:07, 18.64it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 18.71it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:06, 18.64it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:06, 18.60it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:06, 18.52it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:06, 18.57it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:02<00:08, 14.31it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:10, 10.94it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:09, 12.45it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:08, 13.75it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:07, 14.60it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:07, 15.23it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:06, 15.89it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:03<00:06, 16.27it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:03<00:06, 16.63it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:06, 16.76it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:05, 16.98it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 17.06it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 17.11it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 17.28it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 17.58it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:05, 17.80it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:04<00:04, 17.86it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:04<00:04, 17.66it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:04, 17.72it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:04, 17.61it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 17.63it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 17.89it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 17.78it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 17.75it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:04<00:04, 17.78it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:05<00:04, 17.70it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:03, 17.60it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:03, 17.49it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 17.41it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 17.54it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 17.58it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 17.66it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 17.71it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:05<00:03, 17.56it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:06<00:03, 17.55it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:02, 17.73it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 17.76it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 17.74it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 17.63it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 17.60it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 17.58it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:06<00:02, 17.61it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:06<00:02, 17.63it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:07<00:01, 17.51it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 17.56it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 17.64it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 17.47it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 17.44it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 17.51it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 17.43it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:07<00:01, 17.41it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:08<00:01, 17.45it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:08<00:00, 17.42it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 17.55it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 17.50it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 17.55it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 17.54it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 17.63it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:08<00:00, 17.74it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:08<00:00, 17.91it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:09<00:00, 17.84it/s][A100%|#####################################################################################################################################################| 157/157 [00:09<00:00, 17.32it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:08, 17.84it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 18.32it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 18.48it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 18.56it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:07, 18.73it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:07, 18.77it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:07, 18.85it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:07, 18.91it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:00<00:07, 18.83it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 19.01it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 18.74it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:07, 17.16it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:07, 17.68it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:07, 18.02it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:06, 18.16it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:06, 18.26it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:06, 18.39it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:01<00:06, 18.47it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:06, 18.58it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:06, 18.66it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:06, 18.51it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:06, 18.61it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:05, 18.63it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:05, 18.64it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:02<00:05, 18.71it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:02<00:05, 18.80it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:02<00:05, 18.82it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:05, 18.77it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 18.69it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 18.74it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 18.77it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:04, 18.85it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:04, 18.85it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:03<00:04, 18.96it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:03<00:04, 19.09it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:03<00:04, 19.02it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:03<00:04, 19.07it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 18.90it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 18.83it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:05, 14.06it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 15.12it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:04<00:04, 16.04it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:04<00:04, 16.66it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:04<00:03, 17.26it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:04<00:03, 17.66it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 18.20it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 18.49it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 18.60it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 18.47it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 18.13it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:05<00:03, 17.94it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:05<00:02, 17.96it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:05<00:02, 17.83it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:05<00:02, 17.93it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 17.71it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 17.56it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 17.65it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 17.66it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:06<00:02, 17.76it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:06<00:02, 17.83it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:06<00:01, 17.79it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:06<00:01, 17.76it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:06<00:01, 17.73it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 17.81it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 17.77it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 17.89it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 17.87it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:07<00:01, 17.77it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:07<00:01, 17.60it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:07<00:00, 17.53it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:07<00:00, 17.53it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:07<00:00, 17.53it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 17.58it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 17.65it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 17.66it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:08<00:00, 17.67it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:08<00:00, 17.63it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:08<00:00, 17.64it/s][A100%|#####################################################################################################################################################| 157/157 [00:08<00:00, 18.07it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:08, 17.53it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 18.18it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 18.18it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:08, 18.50it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:07, 18.69it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:07, 18.80it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:07, 18.88it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:07, 18.70it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:00<00:07, 18.64it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 18.81it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 18.77it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:07, 18.79it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:06, 18.81it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:06, 18.82it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:06, 18.78it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:06, 18.80it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:06, 19.03it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:01<00:07, 16.48it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:10, 11.44it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:09, 12.95it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:08, 14.32it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:07, 15.22it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:06, 15.89it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:06, 16.39it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:02<00:06, 16.71it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:03<00:06, 16.91it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:05, 17.18it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:05, 17.37it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 17.37it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 17.46it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 17.58it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 17.51it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:05, 17.75it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:03<00:04, 17.87it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:04<00:04, 17.82it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:04, 17.78it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:04, 17.84it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 17.84it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 17.70it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 17.74it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 17.77it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:04<00:04, 17.79it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:04<00:03, 17.85it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:03, 17.90it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:03, 17.88it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 17.87it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 17.96it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 17.87it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 17.86it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 17.95it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:05<00:03, 18.02it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:05<00:02, 18.01it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:02, 18.06it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 18.19it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 18.23it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 18.16it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 18.06it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 18.09it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:06<00:02, 17.97it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:06<00:02, 17.98it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:06<00:01, 17.89it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 17.87it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 17.96it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 17.97it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 17.93it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 17.91it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 17.79it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:07<00:01, 17.95it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:07<00:01, 17.87it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:07<00:00, 17.86it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 17.85it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 17.80it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 17.81it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 17.82it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 17.69it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:08<00:00, 17.78it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:08<00:00, 17.75it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:08<00:00, 17.64it/s][A100%|#####################################################################################################################################################| 157/157 [00:08<00:00, 17.63it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:08, 18.17it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 18.56it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:08, 18.61it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:07, 18.71it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:07, 18.63it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:07, 18.95it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:07, 18.97it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:07, 18.93it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:00<00:07, 18.91it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 19.06it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:14,  9.49it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:11, 11.24it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:10, 12.88it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:09, 14.24it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:08, 15.45it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:02<00:07, 16.26it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:02<00:07, 17.04it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:02<00:06, 17.50it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:06, 17.94it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:06, 18.20it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:06, 18.39it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:06, 18.58it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:05, 18.87it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:05, 19.19it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:02<00:05, 19.09it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:03<00:05, 19.18it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:05, 19.03it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:05, 19.03it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 19.25it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 19.07it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:04, 19.01it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:04, 19.12it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:04, 19.20it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:03<00:04, 19.10it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:04<00:04, 18.91it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:04, 19.06it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:05, 14.71it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:05, 15.71it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 16.46it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 17.07it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 17.61it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:04<00:04, 17.97it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:04<00:03, 18.32it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:05<00:03, 18.63it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:03, 18.80it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 18.98it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 19.05it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 18.99it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 18.84it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 18.68it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:05<00:02, 18.53it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:05<00:02, 18.42it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:06<00:02, 18.29it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 18.35it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 18.40it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 18.23it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 18.21it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 18.05it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:06<00:02, 17.94it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:06<00:02, 18.10it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:06<00:01, 18.12it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:07<00:01, 18.09it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 18.16it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 18.21it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 18.15it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 18.05it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 18.09it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:07<00:01, 17.92it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:07<00:01, 18.04it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:07<00:00, 18.13it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:08<00:00, 18.04it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 18.23it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 18.16it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 18.06it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 18.09it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:08<00:00, 18.21it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:08<00:00, 18.05it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:08<00:00, 18.04it/s][A100%|#####################################################################################################################################################| 157/157 [00:08<00:00, 17.76it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}

  0%|                                                                                                                                                               | 0/157 [00:00<?, ?it/s][A
  1%|#9                                                                                                                                                     | 2/157 [00:00<00:08, 18.00it/s][A
  3%|###8                                                                                                                                                   | 4/157 [00:00<00:08, 18.59it/s][A
  4%|#####7                                                                                                                                                 | 6/157 [00:00<00:07, 18.95it/s][A
  5%|#######6                                                                                                                                               | 8/157 [00:00<00:07, 19.20it/s][A
  6%|#########5                                                                                                                                            | 10/157 [00:00<00:07, 19.14it/s][A
  8%|###########4                                                                                                                                          | 12/157 [00:00<00:07, 19.10it/s][A
  9%|#############3                                                                                                                                        | 14/157 [00:00<00:07, 19.14it/s][A
 10%|###############2                                                                                                                                      | 16/157 [00:00<00:07, 19.05it/s][A
 11%|#################1                                                                                                                                    | 18/157 [00:00<00:07, 19.04it/s][A
 13%|###################1                                                                                                                                  | 20/157 [00:01<00:07, 19.04it/s][A
 14%|#####################                                                                                                                                 | 22/157 [00:01<00:07, 19.04it/s][A
 15%|######################9                                                                                                                               | 24/157 [00:01<00:06, 19.20it/s][A
 17%|########################8                                                                                                                             | 26/157 [00:01<00:06, 19.37it/s][A
 18%|##########################7                                                                                                                           | 28/157 [00:01<00:06, 19.33it/s][A
 19%|############################6                                                                                                                         | 30/157 [00:01<00:06, 19.46it/s][A
 20%|##############################5                                                                                                                       | 32/157 [00:01<00:06, 19.39it/s][A
 22%|################################4                                                                                                                     | 34/157 [00:01<00:06, 19.33it/s][A
 23%|##################################3                                                                                                                   | 36/157 [00:01<00:07, 16.81it/s][A
 24%|####################################3                                                                                                                 | 38/157 [00:02<00:07, 15.19it/s][A
 25%|######################################2                                                                                                               | 40/157 [00:02<00:09, 11.98it/s][A
 27%|########################################1                                                                                                             | 42/157 [00:02<00:08, 13.59it/s][A
 28%|##########################################                                                                                                            | 44/157 [00:02<00:07, 14.67it/s][A
 29%|###########################################9                                                                                                          | 46/157 [00:02<00:07, 15.53it/s][A
 31%|#############################################8                                                                                                        | 48/157 [00:02<00:06, 16.24it/s][A
 32%|###############################################7                                                                                                      | 50/157 [00:02<00:06, 16.73it/s][A
 33%|#################################################6                                                                                                    | 52/157 [00:02<00:06, 17.14it/s][A
 34%|###################################################5                                                                                                  | 54/157 [00:03<00:05, 17.30it/s][A
 36%|#####################################################5                                                                                                | 56/157 [00:03<00:05, 17.59it/s][A
 37%|#######################################################4                                                                                              | 58/157 [00:03<00:05, 17.71it/s][A
 38%|#########################################################3                                                                                            | 60/157 [00:03<00:05, 17.90it/s][A
 39%|###########################################################2                                                                                          | 62/157 [00:03<00:05, 17.78it/s][A
 41%|#############################################################1                                                                                        | 64/157 [00:03<00:05, 17.85it/s][A
 42%|###############################################################                                                                                       | 66/157 [00:03<00:05, 17.85it/s][A
 43%|################################################################9                                                                                     | 68/157 [00:03<00:04, 17.99it/s][A
 45%|##################################################################8                                                                                   | 70/157 [00:03<00:04, 17.99it/s][A
 46%|####################################################################7                                                                                 | 72/157 [00:04<00:04, 18.04it/s][A
 47%|######################################################################7                                                                               | 74/157 [00:04<00:04, 17.98it/s][A
 48%|########################################################################6                                                                             | 76/157 [00:04<00:04, 18.04it/s][A
 50%|##########################################################################5                                                                           | 78/157 [00:04<00:04, 17.98it/s][A
 51%|############################################################################4                                                                         | 80/157 [00:04<00:04, 17.98it/s][A
 52%|##############################################################################3                                                                       | 82/157 [00:04<00:04, 17.99it/s][A
 54%|################################################################################2                                                                     | 84/157 [00:04<00:04, 18.09it/s][A
 55%|##################################################################################1                                                                   | 86/157 [00:04<00:03, 18.11it/s][A
 56%|####################################################################################                                                                  | 88/157 [00:04<00:03, 18.13it/s][A
 57%|#####################################################################################9                                                                | 90/157 [00:05<00:03, 18.09it/s][A
 59%|#######################################################################################8                                                              | 92/157 [00:05<00:03, 18.06it/s][A
 60%|#########################################################################################8                                                            | 94/157 [00:05<00:03, 18.29it/s][A
 61%|###########################################################################################7                                                          | 96/157 [00:05<00:03, 18.11it/s][A
 62%|#############################################################################################6                                                        | 98/157 [00:05<00:03, 18.07it/s][A
 64%|##############################################################################################9                                                      | 100/157 [00:05<00:03, 18.00it/s][A
 65%|################################################################################################8                                                    | 102/157 [00:05<00:03, 18.00it/s][A
 66%|##################################################################################################7                                                  | 104/157 [00:05<00:02, 18.15it/s][A
 68%|####################################################################################################5                                                | 106/157 [00:05<00:02, 18.11it/s][A
 69%|######################################################################################################4                                              | 108/157 [00:06<00:02, 18.07it/s][A
 70%|########################################################################################################3                                            | 110/157 [00:06<00:02, 17.95it/s][A
 71%|##########################################################################################################2                                          | 112/157 [00:06<00:02, 18.07it/s][A
 73%|############################################################################################################1                                        | 114/157 [00:06<00:02, 18.10it/s][A
 74%|##############################################################################################################                                       | 116/157 [00:06<00:02, 18.02it/s][A
 75%|###############################################################################################################9                                     | 118/157 [00:06<00:02, 17.96it/s][A
 76%|#################################################################################################################8                                   | 120/157 [00:06<00:02, 17.98it/s][A
 78%|###################################################################################################################7                                 | 122/157 [00:06<00:01, 18.03it/s][A
 79%|#####################################################################################################################6                               | 124/157 [00:06<00:01, 17.88it/s][A
 80%|#######################################################################################################################5                             | 126/157 [00:07<00:01, 17.91it/s][A
 82%|#########################################################################################################################4                           | 128/157 [00:07<00:01, 18.14it/s][A
 83%|###########################################################################################################################3                         | 130/157 [00:07<00:01, 18.14it/s][A
 84%|#############################################################################################################################2                       | 132/157 [00:07<00:01, 18.25it/s][A
 85%|###############################################################################################################################1                     | 134/157 [00:07<00:01, 18.33it/s][A
 87%|#################################################################################################################################                    | 136/157 [00:07<00:01, 18.18it/s][A
 88%|##################################################################################################################################9                  | 138/157 [00:07<00:01, 18.22it/s][A
 89%|####################################################################################################################################8                | 140/157 [00:07<00:00, 18.26it/s][A
 90%|######################################################################################################################################7              | 142/157 [00:07<00:00, 18.23it/s][A
 92%|########################################################################################################################################6            | 144/157 [00:08<00:00, 18.11it/s][A
 93%|##########################################################################################################################################5          | 146/157 [00:08<00:00, 18.08it/s][A
 94%|############################################################################################################################################4        | 148/157 [00:08<00:00, 18.05it/s][A
 96%|##############################################################################################################################################3      | 150/157 [00:08<00:00, 18.19it/s][A
 97%|################################################################################################################################################2    | 152/157 [00:08<00:00, 18.03it/s][A
 98%|##################################################################################################################################################1  | 154/157 [00:08<00:00, 18.12it/s][A
 99%|#################################################################################################################################################### | 156/157 [00:08<00:00, 18.13it/s][A100%|#####################################################################################################################################################| 157/157 [00:08<00:00, 17.88it/s]

  0%|                                                                                                                                                               | 0/313 [00:00<?, ?it/s][A
  0%|4                                                                                                                                                      | 1/313 [00:00<01:00,  5.12it/s][A
  1%|9                                                                                                                                                      | 2/313 [00:00<01:00,  5.14it/s][A
  1%|#4                                                                                                                                                     | 3/313 [00:00<01:00,  5.14it/s][A
  1%|#9                                                                                                                                                     | 4/313 [00:00<01:00,  5.12it/s][A
  2%|##4                                                                                                                                                    | 5/313 [00:00<01:00,  5.07it/s][A
  2%|##8                                                                                                                                                    | 6/313 [00:01<00:59,  5.16it/s][A
  2%|###3                                                                                                                                                   | 7/313 [00:01<01:37,  3.15it/s][A
  3%|###8                                                                                                                                                   | 8/313 [00:01<01:25,  3.57it/s][A
  3%|####3                                                                                                                                                  | 9/313 [00:02<01:17,  3.93it/s][A
  3%|####7                                                                                                                                                 | 10/313 [00:02<01:11,  4.24it/s][A
  4%|#####2                                                                                                                                                | 11/313 [00:02<01:07,  4.46it/s][A
  4%|#####7                                                                                                                                                | 12/313 [00:02<01:04,  4.63it/s][A
  4%|######2                                                                                                                                               | 13/313 [00:02<01:03,  4.73it/s][A
  4%|######7                                                                                                                                               | 14/313 [00:03<01:01,  4.87it/s][A
  5%|#######1                                                                                                                                              | 15/313 [00:03<01:00,  4.94it/s][A
  5%|#######6                                                                                                                                              | 16/313 [00:03<00:59,  5.02it/s][A
  5%|########1                                                                                                                                             | 17/313 [00:03<00:58,  5.06it/s][A
  6%|########6                                                                                                                                             | 18/313 [00:03<00:58,  5.06it/s][A
  6%|#########1                                                                                                                                            | 19/313 [00:04<00:57,  5.09it/s][A
  6%|#########5                                                                                                                                            | 20/313 [00:04<00:57,  5.12it/s][A
  7%|##########                                                                                                                                            | 21/313 [00:04<00:56,  5.13it/s][A
  7%|##########5                                                                                                                                           | 22/313 [00:04<00:56,  5.15it/s][A
  7%|###########                                                                                                                                           | 23/313 [00:04<00:56,  5.16it/s][A
  8%|###########5                                                                                                                                          | 24/313 [00:05<00:55,  5.16it/s][A
  8%|###########9                                                                                                                                          | 25/313 [00:05<00:56,  5.14it/s][A
  8%|############4                                                                                                                                         | 26/313 [00:05<00:55,  5.16it/s][A
  9%|############9                                                                                                                                         | 27/313 [00:05<00:55,  5.16it/s][A
  9%|#############4                                                                                                                                        | 28/313 [00:05<00:54,  5.20it/s][A
  9%|#############8                                                                                                                                        | 29/313 [00:06<00:54,  5.22it/s][A
 10%|##############3                                                                                                                                       | 30/313 [00:06<00:54,  5.21it/s][A
 10%|##############8                                                                                                                                       | 31/313 [00:06<00:53,  5.24it/s][A
 10%|###############3                                                                                                                                      | 32/313 [00:06<00:53,  5.23it/s][A 10%|###############3                                                                                                                                      | 32/313 [00:06<00:57,  4.85it/s]
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D38F70>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D38F70>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D395A0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D395A0>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D39E10>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D39E10>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D38B80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D38B80>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3A7A0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3A7A0>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3B9A0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3B9A0>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3A320>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3A320>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D389D0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D389D0>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D39BD0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D39BD0>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D39900>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D39900>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3B760>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3B760>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3B010>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D38B80>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D39E10>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3AB00>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3A170>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D388B0>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D384C0>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3ADD0>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3B1C0>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D385E0>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D392D0>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[HOOK] Performing Dynamic PTQ hook operations.
[HOOK] Dynamic PTQ setup completed.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1B028CE50>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1B028CE50>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1B028FAC0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1B028FAC0>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1B028EA70>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1B028EA70>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1B028EF80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1B028EF80>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19018ED40>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19018ED40>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19018DAB0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19018DAB0>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19018DF30>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19018DF30>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19018F5B0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19018F5B0>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19018F640>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19018F640>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDBAC0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDBAC0>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDA320>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDA320>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDB5B0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDB5B0>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDB910>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDB910>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDAF80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDAF80>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDB010>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDB010>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDBF40>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDBF40>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDB6D0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDB6D0>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDBB50>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDBB50>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDBAC0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDBAC0>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDAC20>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDAC20>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDBE20>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDBE20>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BD9480>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BD9480>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[HOOK] Performing QAT training hook.
[HOOK] QAT epoch 1/5 started.
[HOOK][Epoch: 1] Batch 1 Loss: 0.6882
[HOOK][Epoch: 1] Batch 51 Loss: 0.3535
[HOOK][Epoch: 1] Batch 101 Loss: 0.1380
[HOOK][Epoch: 1] Batch 151 Loss: 0.0818
[HOOK][Epoch: 1] Batch 201 Loss: 0.3577
[HOOK][Epoch: 1] Batch 251 Loss: 0.0965
[HOOK][Epoch: 1] Batch 301 Loss: 0.2892
[HOOK][Epoch: 1] Batch 351 Loss: 0.1086
[HOOK][Epoch: 1] Batch 401 Loss: 0.2051
[HOOK][Epoch: 1] Batch 451 Loss: 0.0808
[HOOK][Epoch: 1] Batch 501 Loss: 0.2726
[HOOK][Epoch: 1] Batch 551 Loss: 0.0636
[HOOK][Epoch: 1] Batch 601 Loss: 0.1428
[HOOK] QAT epoch 2/5 started.
[HOOK][Epoch: 2] Batch 1 Loss: 0.1833
[HOOK][Epoch: 2] Batch 51 Loss: 0.1991
[HOOK][Epoch: 2] Batch 101 Loss: 0.1560
[HOOK][Epoch: 2] Batch 151 Loss: 0.2171
[HOOK][Epoch: 2] Batch 201 Loss: 0.1515
[HOOK][Epoch: 2] Batch 251 Loss: 0.1088
[HOOK][Epoch: 2] Batch 301 Loss: 0.1246
[HOOK][Epoch: 2] Batch 351 Loss: 0.0224
[HOOK][Epoch: 2] Batch 401 Loss: 0.0277
[HOOK][Epoch: 2] Batch 451 Loss: 0.1259
[HOOK][Epoch: 2] Batch 501 Loss: 0.1127
[HOOK][Epoch: 2] Batch 551 Loss: 0.0401
[HOOK][Epoch: 2] Batch 601 Loss: 0.0506
[HOOK] QAT epoch 3/5 started.
[HOOK][Epoch: 3] Batch 1 Loss: 0.0066
[HOOK][Epoch: 3] Batch 51 Loss: 0.0635
[HOOK][Epoch: 3] Batch 101 Loss: 0.0193
[HOOK][Epoch: 3] Batch 151 Loss: 0.0174
[HOOK][Epoch: 3] Batch 201 Loss: 0.0551
[HOOK][Epoch: 3] Batch 251 Loss: 0.0251
[HOOK][Epoch: 3] Batch 301 Loss: 0.0161
[HOOK][Epoch: 3] Batch 351 Loss: 0.0125
[HOOK][Epoch: 3] Batch 401 Loss: 0.0142
[HOOK][Epoch: 3] Batch 451 Loss: 0.0227
[HOOK][Epoch: 3] Batch 501 Loss: 0.0091
[HOOK][Epoch: 3] Batch 551 Loss: 0.0007
[HOOK][Epoch: 3] Batch 601 Loss: 0.0218
[HOOK] QAT epoch 4/5 started.
[HOOK][Epoch: 4] Batch 1 Loss: 0.0272
[HOOK][Epoch: 4] Batch 51 Loss: 0.0792
[HOOK][Epoch: 4] Batch 101 Loss: 0.0007
[HOOK][Epoch: 4] Batch 151 Loss: 0.0007
[HOOK][Epoch: 4] Batch 201 Loss: 0.0447
[HOOK][Epoch: 4] Batch 251 Loss: 0.0047
[HOOK][Epoch: 4] Batch 301 Loss: 0.0127
[HOOK][Epoch: 4] Batch 351 Loss: 0.0165
[HOOK][Epoch: 4] Batch 401 Loss: 0.0029
[HOOK][Epoch: 4] Batch 451 Loss: 0.0148
[HOOK][Epoch: 4] Batch 501 Loss: 0.0156
[HOOK][Epoch: 4] Batch 551 Loss: 0.0004
[HOOK][Epoch: 4] Batch 601 Loss: 0.0017
[HOOK] QAT epoch 5/5 started.
[HOOK][Epoch: 5] Batch 1 Loss: 0.0770
[HOOK][Epoch: 5] Batch 51 Loss: 0.0004
[HOOK][Epoch: 5] Batch 101 Loss: 0.0005
[HOOK][Epoch: 5] Batch 151 Loss: 0.0010
[HOOK][Epoch: 5] Batch 201 Loss: 0.0138
[HOOK][Epoch: 5] Batch 251 Loss: 0.0408
[HOOK][Epoch: 5] Batch 301 Loss: 0.0019
[HOOK][Epoch: 5] Batch 351 Loss: 0.0030
[HOOK][Epoch: 5] Batch 401 Loss: 0.0016
[HOOK][Epoch: 5] Batch 451 Loss: 0.0110
[HOOK][Epoch: 5] Batch 501 Loss: 0.0671
[HOOK][Epoch: 5] Batch 551 Loss: 0.0034
[HOOK][Epoch: 5] Batch 601 Loss: 0.0068
[HOOK] QAT training completed.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDB910>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198BDB910>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D38B80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D38B80>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D39E10>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D39E10>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3B5B0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198D3B5B0>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19440D120>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19440D120>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19440D000>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19440D000>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19440CC10>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19440CC10>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19440EA70>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19440EA70>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19440D900>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19440D900>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19440CE50>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19440CE50>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19440F370>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19440F370>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19440D120>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19440F010>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19440D240>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A19440E4D0>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1942A43A0>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1942A4E50>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1942A4B80>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1942A45E0>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1942A4A60>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1942A4940>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1942A44C0>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[HOOK] Performing Dynamic PTQ hook operations.
[HOOK] Dynamic PTQ setup completed.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1942A4B80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1942A4B80>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1942A43A0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1942A43A0>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1942A4E50>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1942A4E50>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1942A7370>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1942A7370>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1942A44C0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A1942A44C0>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE2A70>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE2A70>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE0B80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE0B80>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE0CA0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE0CA0>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE1F30>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE1F30>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE28C0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE28C0>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE3370>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE3370>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE0B80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE0B80>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE11B0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE11B0>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE1750>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE1750>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE3D00>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE3D00>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE0AF0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE0AF0>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE05E0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE05E0>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE1090>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE1090>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE0700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE0700>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE3BE0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE3BE0>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE12D0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE12D0>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE25F0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE25F0>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[HOOK] Performing QAT training hook.
[HOOK] QAT epoch 1/5 started.
[HOOK][Epoch: 1] Batch 1 Loss: 0.4437
[HOOK][Epoch: 1] Batch 51 Loss: 0.3449
[HOOK][Epoch: 1] Batch 101 Loss: 0.3492
[HOOK][Epoch: 1] Batch 151 Loss: 0.1756
[HOOK][Epoch: 1] Batch 201 Loss: 0.2940
[HOOK][Epoch: 1] Batch 251 Loss: 0.2533
[HOOK][Epoch: 1] Batch 301 Loss: 0.2728
[HOOK][Epoch: 1] Batch 351 Loss: 0.0560
[HOOK][Epoch: 1] Batch 401 Loss: 0.4612
[HOOK][Epoch: 1] Batch 451 Loss: 0.0628
[HOOK][Epoch: 1] Batch 501 Loss: 0.0597
[HOOK][Epoch: 1] Batch 551 Loss: 0.1990
[HOOK][Epoch: 1] Batch 601 Loss: 0.1618
[HOOK] QAT epoch 2/5 started.
[HOOK][Epoch: 2] Batch 1 Loss: 0.1442
[HOOK][Epoch: 2] Batch 51 Loss: 0.0889
[HOOK][Epoch: 2] Batch 101 Loss: 0.0949
[HOOK][Epoch: 2] Batch 151 Loss: 0.0290
[HOOK][Epoch: 2] Batch 201 Loss: 0.0593
[HOOK][Epoch: 2] Batch 251 Loss: 0.3024
[HOOK][Epoch: 2] Batch 301 Loss: 0.1826
[HOOK][Epoch: 2] Batch 351 Loss: 0.0676
[HOOK][Epoch: 2] Batch 401 Loss: 0.1008
[HOOK][Epoch: 2] Batch 451 Loss: 0.0259
[HOOK][Epoch: 2] Batch 501 Loss: 0.0775
[HOOK][Epoch: 2] Batch 551 Loss: 0.0861
[HOOK][Epoch: 2] Batch 601 Loss: 0.1057
[HOOK] QAT epoch 3/5 started.
[HOOK][Epoch: 3] Batch 1 Loss: 0.0344
[HOOK][Epoch: 3] Batch 51 Loss: 0.1288
[HOOK][Epoch: 3] Batch 101 Loss: 0.0097
[HOOK][Epoch: 3] Batch 151 Loss: 0.0551
[HOOK][Epoch: 3] Batch 201 Loss: 0.1108
[HOOK][Epoch: 3] Batch 251 Loss: 0.0079
[HOOK][Epoch: 3] Batch 301 Loss: 0.0126
[HOOK][Epoch: 3] Batch 351 Loss: 0.0926
[HOOK][Epoch: 3] Batch 401 Loss: 0.0010
[HOOK][Epoch: 3] Batch 451 Loss: 0.0021
[HOOK][Epoch: 3] Batch 501 Loss: 0.0074
[HOOK][Epoch: 3] Batch 551 Loss: 0.0118
[HOOK][Epoch: 3] Batch 601 Loss: 0.0064
[HOOK] QAT epoch 4/5 started.
[HOOK][Epoch: 4] Batch 1 Loss: 0.0161
[HOOK][Epoch: 4] Batch 51 Loss: 0.0184
[HOOK][Epoch: 4] Batch 101 Loss: 0.0230
[HOOK][Epoch: 4] Batch 151 Loss: 0.0186
[HOOK][Epoch: 4] Batch 201 Loss: 0.0746
[HOOK][Epoch: 4] Batch 251 Loss: 0.0041
[HOOK][Epoch: 4] Batch 301 Loss: 0.0113
[HOOK][Epoch: 4] Batch 351 Loss: 0.0040
[HOOK][Epoch: 4] Batch 401 Loss: 0.0438
[HOOK][Epoch: 4] Batch 451 Loss: 0.0150
[HOOK][Epoch: 4] Batch 501 Loss: 0.0008
[HOOK][Epoch: 4] Batch 551 Loss: 0.0141
[HOOK][Epoch: 4] Batch 601 Loss: 0.0409
[HOOK] QAT epoch 5/5 started.
[HOOK][Epoch: 5] Batch 1 Loss: 0.0040
[HOOK][Epoch: 5] Batch 51 Loss: 0.0045
[HOOK][Epoch: 5] Batch 101 Loss: 0.0047
[HOOK][Epoch: 5] Batch 151 Loss: 0.0042
[HOOK][Epoch: 5] Batch 201 Loss: 0.0028
[HOOK][Epoch: 5] Batch 251 Loss: 0.0034
[HOOK][Epoch: 5] Batch 301 Loss: 0.0776
[HOOK][Epoch: 5] Batch 351 Loss: 0.0004
[HOOK][Epoch: 5] Batch 401 Loss: 0.0040
[HOOK][Epoch: 5] Batch 451 Loss: 0.0138
[HOOK][Epoch: 5] Batch 501 Loss: 0.0031
[HOOK][Epoch: 5] Batch 551 Loss: 0.0665
[HOOK][Epoch: 5] Batch 601 Loss: 0.0029
[HOOK] QAT training completed.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE39A0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE39A0>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE1750>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE1750>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE11B0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE11B0>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE25F0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE25F0>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE3E20>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE3E20>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE2200>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE2200>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE2710>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE2710>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198C38310>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198C38310>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198C39240>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198C39240>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198C3A170>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198C3A170>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198C3BEB0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198C3BEB0>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[HOOK] Performing QAT training hook.
[HOOK] QAT epoch 1/5 started.
[HOOK][Epoch: 1] Batch 1 Loss: 0.1467
[HOOK][Epoch: 1] Batch 51 Loss: 0.2120
[HOOK][Epoch: 1] Batch 101 Loss: 0.3118
[HOOK][Epoch: 1] Batch 151 Loss: 0.3419
[HOOK][Epoch: 1] Batch 201 Loss: 0.2187
[HOOK][Epoch: 1] Batch 251 Loss: 0.0688
[HOOK][Epoch: 1] Batch 301 Loss: 0.0752
[HOOK][Epoch: 1] Batch 351 Loss: 0.2919
[HOOK][Epoch: 1] Batch 401 Loss: 0.1788
[HOOK][Epoch: 1] Batch 451 Loss: 0.2488
[HOOK][Epoch: 1] Batch 501 Loss: 0.1560
[HOOK][Epoch: 1] Batch 551 Loss: 0.2731
[HOOK][Epoch: 1] Batch 601 Loss: 0.0860
[HOOK] QAT epoch 2/5 started.
[HOOK][Epoch: 2] Batch 1 Loss: 0.1623
[HOOK][Epoch: 2] Batch 51 Loss: 0.0553
[HOOK][Epoch: 2] Batch 101 Loss: 0.0755
[HOOK][Epoch: 2] Batch 151 Loss: 0.0782
[HOOK][Epoch: 2] Batch 201 Loss: 0.0703
[HOOK][Epoch: 2] Batch 251 Loss: 0.1023
[HOOK][Epoch: 2] Batch 301 Loss: 0.0246
[HOOK][Epoch: 2] Batch 351 Loss: 0.2178
[HOOK][Epoch: 2] Batch 401 Loss: 0.0870
[HOOK][Epoch: 2] Batch 451 Loss: 0.0874
[HOOK][Epoch: 2] Batch 501 Loss: 0.0732
[HOOK][Epoch: 2] Batch 551 Loss: 0.1565
[HOOK][Epoch: 2] Batch 601 Loss: 0.0578
[HOOK] QAT epoch 3/5 started.
[HOOK][Epoch: 3] Batch 1 Loss: 0.0678
[HOOK][Epoch: 3] Batch 51 Loss: 0.0280
[HOOK][Epoch: 3] Batch 101 Loss: 0.0028
[HOOK][Epoch: 3] Batch 151 Loss: 0.0439
[HOOK][Epoch: 3] Batch 201 Loss: 0.0018
[HOOK][Epoch: 3] Batch 251 Loss: 0.0118
[HOOK][Epoch: 3] Batch 301 Loss: 0.0026
[HOOK][Epoch: 3] Batch 351 Loss: 0.0423
[HOOK][Epoch: 3] Batch 401 Loss: 0.0046
[HOOK][Epoch: 3] Batch 451 Loss: 0.0024
[HOOK][Epoch: 3] Batch 501 Loss: 0.0209
[HOOK][Epoch: 3] Batch 551 Loss: 0.0775
[HOOK][Epoch: 3] Batch 601 Loss: 0.0088
[HOOK] QAT epoch 4/5 started.
[HOOK][Epoch: 4] Batch 1 Loss: 0.0030
[HOOK][Epoch: 4] Batch 51 Loss: 0.0155
[HOOK][Epoch: 4] Batch 101 Loss: 0.0012
[HOOK][Epoch: 4] Batch 151 Loss: 0.0115
[HOOK][Epoch: 4] Batch 201 Loss: 0.0054
[HOOK][Epoch: 4] Batch 251 Loss: 0.0123
[HOOK][Epoch: 4] Batch 301 Loss: 0.0171
[HOOK][Epoch: 4] Batch 351 Loss: 0.0028
[HOOK][Epoch: 4] Batch 401 Loss: 0.0144
[HOOK][Epoch: 4] Batch 451 Loss: 0.0007
[HOOK][Epoch: 4] Batch 501 Loss: 0.0155
[HOOK][Epoch: 4] Batch 551 Loss: 0.0260
[HOOK][Epoch: 4] Batch 601 Loss: 0.0046
[HOOK] QAT epoch 5/5 started.
[HOOK][Epoch: 5] Batch 1 Loss: 0.0116
[HOOK][Epoch: 5] Batch 51 Loss: 0.0302
[HOOK][Epoch: 5] Batch 101 Loss: 0.0018
[HOOK][Epoch: 5] Batch 151 Loss: 0.1315
[HOOK][Epoch: 5] Batch 201 Loss: 0.0255
[HOOK][Epoch: 5] Batch 251 Loss: 0.0016
[HOOK][Epoch: 5] Batch 301 Loss: 0.0021
[HOOK][Epoch: 5] Batch 351 Loss: 0.0020
[HOOK][Epoch: 5] Batch 401 Loss: 0.0030
[HOOK][Epoch: 5] Batch 451 Loss: 0.0266
[HOOK][Epoch: 5] Batch 501 Loss: 0.0022
[HOOK][Epoch: 5] Batch 551 Loss: 0.0671
[HOOK][Epoch: 5] Batch 601 Loss: 0.0020
[HOOK] QAT training completed.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E48700>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4BF40>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4A0E0>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4A4D0>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49630>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49750>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4B880>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E48820>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E493F0>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49C60>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4B2E0>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[HOOK] Performing Dynamic PTQ hook operations.
[HOOK] Dynamic PTQ setup completed.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4A5F0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4A5F0>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49750>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49750>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4BA30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4BA30>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4A4D0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4A4D0>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4A0E0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4A0E0>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4BF40>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4BF40>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49240>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49240>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49120>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49120>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E48CA0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E48CA0>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E48700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E48700>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4B2E0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E4B2E0>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[HOOK] Performing QAT training hook.
[HOOK] QAT epoch 1/5 started.
[HOOK][Epoch: 1] Batch 1 Loss: 1.5944
[HOOK][Epoch: 1] Batch 51 Loss: 0.1411
[HOOK][Epoch: 1] Batch 101 Loss: 0.7953
[HOOK][Epoch: 1] Batch 151 Loss: 0.0723
[HOOK][Epoch: 1] Batch 201 Loss: 0.9694
[HOOK][Epoch: 1] Batch 251 Loss: 0.8940
[HOOK][Epoch: 1] Batch 301 Loss: 0.3550
[HOOK][Epoch: 1] Batch 351 Loss: 0.0944
[HOOK][Epoch: 1] Batch 401 Loss: 0.1891
[HOOK][Epoch: 1] Batch 451 Loss: 0.2250
[HOOK][Epoch: 1] Batch 501 Loss: 0.1257
[HOOK][Epoch: 1] Batch 551 Loss: 0.0569
[HOOK][Epoch: 1] Batch 601 Loss: 0.1697
[HOOK] QAT epoch 2/5 started.
[HOOK][Epoch: 2] Batch 1 Loss: 0.0212
[HOOK][Epoch: 2] Batch 51 Loss: 0.2302
[HOOK][Epoch: 2] Batch 101 Loss: 0.0799
[HOOK][Epoch: 2] Batch 151 Loss: 0.1806
[HOOK][Epoch: 2] Batch 201 Loss: 0.0604
[HOOK][Epoch: 2] Batch 251 Loss: 0.0376
[HOOK][Epoch: 2] Batch 301 Loss: 0.0263
[HOOK][Epoch: 2] Batch 351 Loss: 0.2054
[HOOK][Epoch: 2] Batch 401 Loss: 0.0777
[HOOK][Epoch: 2] Batch 451 Loss: 0.0604
[HOOK][Epoch: 2] Batch 501 Loss: 0.0652
[HOOK][Epoch: 2] Batch 551 Loss: 0.1599
[HOOK][Epoch: 2] Batch 601 Loss: 0.0176
[HOOK] QAT epoch 3/5 started.
[HOOK][Epoch: 3] Batch 1 Loss: 0.1009
[HOOK][Epoch: 3] Batch 51 Loss: 0.0323
[HOOK][Epoch: 3] Batch 101 Loss: 0.0790
[HOOK][Epoch: 3] Batch 151 Loss: 0.0090
[HOOK][Epoch: 3] Batch 201 Loss: 0.0200
[HOOK][Epoch: 3] Batch 251 Loss: 0.0153
[HOOK][Epoch: 3] Batch 301 Loss: 0.0263
[HOOK][Epoch: 3] Batch 351 Loss: 0.0140
[HOOK][Epoch: 3] Batch 401 Loss: 0.0416
[HOOK][Epoch: 3] Batch 451 Loss: 0.2382
[HOOK][Epoch: 3] Batch 501 Loss: 0.0113
[HOOK][Epoch: 3] Batch 551 Loss: 0.0070
[HOOK][Epoch: 3] Batch 601 Loss: 0.0277
[HOOK] QAT epoch 4/5 started.
[HOOK][Epoch: 4] Batch 1 Loss: 0.0167
[HOOK][Epoch: 4] Batch 51 Loss: 0.0043
[HOOK][Epoch: 4] Batch 101 Loss: 0.0167
[HOOK][Epoch: 4] Batch 151 Loss: 0.0142
[HOOK][Epoch: 4] Batch 201 Loss: 0.0019
[HOOK][Epoch: 4] Batch 251 Loss: 0.0269
[HOOK][Epoch: 4] Batch 301 Loss: 0.0236
[HOOK][Epoch: 4] Batch 351 Loss: 0.0023
[HOOK][Epoch: 4] Batch 401 Loss: 0.2294
[HOOK][Epoch: 4] Batch 451 Loss: 0.0021
[HOOK][Epoch: 4] Batch 501 Loss: 0.0081
[HOOK][Epoch: 4] Batch 551 Loss: 0.0134
[HOOK][Epoch: 4] Batch 601 Loss: 0.0252
[HOOK] QAT epoch 5/5 started.
[HOOK][Epoch: 5] Batch 1 Loss: 0.0004
[HOOK][Epoch: 5] Batch 51 Loss: 0.0019
[HOOK][Epoch: 5] Batch 101 Loss: 0.0001
[HOOK][Epoch: 5] Batch 151 Loss: 0.0148
[HOOK][Epoch: 5] Batch 201 Loss: 0.1598
[HOOK][Epoch: 5] Batch 251 Loss: 0.0398
[HOOK][Epoch: 5] Batch 301 Loss: 0.1132
[HOOK][Epoch: 5] Batch 351 Loss: 0.1144
[HOOK][Epoch: 5] Batch 401 Loss: 0.0126
[HOOK][Epoch: 5] Batch 451 Loss: 0.0131
[HOOK][Epoch: 5] Batch 501 Loss: 0.0019
[HOOK][Epoch: 5] Batch 551 Loss: 0.0019
[HOOK][Epoch: 5] Batch 601 Loss: 0.0128
[HOOK] QAT training completed.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49750>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E49750>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DCA5F0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DCA5F0>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DCAA70>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DCAA70>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DCA560>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DCA560>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DCB7F0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198DCB7F0>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE01F0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198FE01F0>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1D2D0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1D2D0>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1F880>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1F880>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1CD30>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1CD30>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1C820>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1C820>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1F7F0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1F7F0>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[FIT] Quantization performed successfully.
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: fbgemm, device: cpu
[INIT] dtype: torch.qint8, allow_embedding: False, allow_convolution: True
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[MODEL] Model initialized and copied for quantization.
[ParentalReassembler] Residual block 'layer1.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer1.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer2.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer3.1' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.0' wrapped with ResidualAddWrapper.
[ParentalReassembler] Residual block 'layer4.1' wrapped with ResidualAddWrapper.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1C040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1C040>})
Module: conv1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1EB90>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1EB90>})
Module: bn1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1CA60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1CA60>})
Module: relu, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1C820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1C820>})
Module: maxpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1CD30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1CD30>})
Module: layer1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1F2E0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1F2E0>})
Module: layer1.0, qconfig: None
Module: layer1.0.module, qconfig: None
Module: layer1.0.module.conv1, qconfig: None
Module: layer1.0.module.bn1, qconfig: None
Module: layer1.0.module.relu, qconfig: None
Module: layer1.0.module.conv2, qconfig: None
Module: layer1.0.module.bn2, qconfig: None
Module: layer1.0.skip_add, qconfig: None
Module: layer1.0.skip_add.activation_post_process, qconfig: None
Module: layer1.1, qconfig: None
Module: layer1.1.module, qconfig: None
Module: layer1.1.module.conv1, qconfig: None
Module: layer1.1.module.bn1, qconfig: None
Module: layer1.1.module.relu, qconfig: None
Module: layer1.1.module.conv2, qconfig: None
Module: layer1.1.module.bn2, qconfig: None
Module: layer1.1.skip_add, qconfig: None
Module: layer1.1.skip_add.activation_post_process, qconfig: None
Module: layer2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1F880>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1F880>})
Module: layer2.0, qconfig: None
Module: layer2.0.module, qconfig: None
Module: layer2.0.module.conv1, qconfig: None
Module: layer2.0.module.bn1, qconfig: None
Module: layer2.0.module.relu, qconfig: None
Module: layer2.0.module.conv2, qconfig: None
Module: layer2.0.module.bn2, qconfig: None
Module: layer2.0.module.downsample, qconfig: None
Module: layer2.0.module.downsample.0, qconfig: None
Module: layer2.0.module.downsample.1, qconfig: None
Module: layer2.0.skip_add, qconfig: None
Module: layer2.0.skip_add.activation_post_process, qconfig: None
Module: layer2.1, qconfig: None
Module: layer2.1.module, qconfig: None
Module: layer2.1.module.conv1, qconfig: None
Module: layer2.1.module.bn1, qconfig: None
Module: layer2.1.module.relu, qconfig: None
Module: layer2.1.module.conv2, qconfig: None
Module: layer2.1.module.bn2, qconfig: None
Module: layer2.1.skip_add, qconfig: None
Module: layer2.1.skip_add.activation_post_process, qconfig: None
Module: layer3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1D2D0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1D2D0>})
Module: layer3.0, qconfig: None
Module: layer3.0.module, qconfig: None
Module: layer3.0.module.conv1, qconfig: None
Module: layer3.0.module.bn1, qconfig: None
Module: layer3.0.module.relu, qconfig: None
Module: layer3.0.module.conv2, qconfig: None
Module: layer3.0.module.bn2, qconfig: None
Module: layer3.0.module.downsample, qconfig: None
Module: layer3.0.module.downsample.0, qconfig: None
Module: layer3.0.module.downsample.1, qconfig: None
Module: layer3.0.skip_add, qconfig: None
Module: layer3.0.skip_add.activation_post_process, qconfig: None
Module: layer3.1, qconfig: None
Module: layer3.1.module, qconfig: None
Module: layer3.1.module.conv1, qconfig: None
Module: layer3.1.module.bn1, qconfig: None
Module: layer3.1.module.relu, qconfig: None
Module: layer3.1.module.conv2, qconfig: None
Module: layer3.1.module.bn2, qconfig: None
Module: layer3.1.skip_add, qconfig: None
Module: layer3.1.skip_add.activation_post_process, qconfig: None
Module: layer4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1DBD0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1DBD0>})
Module: layer4.0, qconfig: None
Module: layer4.0.module, qconfig: None
Module: layer4.0.module.conv1, qconfig: None
Module: layer4.0.module.bn1, qconfig: None
Module: layer4.0.module.relu, qconfig: None
Module: layer4.0.module.conv2, qconfig: None
Module: layer4.0.module.bn2, qconfig: None
Module: layer4.0.module.downsample, qconfig: None
Module: layer4.0.module.downsample.0, qconfig: None
Module: layer4.0.module.downsample.1, qconfig: None
Module: layer4.0.skip_add, qconfig: None
Module: layer4.0.skip_add.activation_post_process, qconfig: None
Module: layer4.1, qconfig: None
Module: layer4.1.module, qconfig: None
Module: layer4.1.module.conv1, qconfig: None
Module: layer4.1.module.bn1, qconfig: None
Module: layer4.1.module.relu, qconfig: None
Module: layer4.1.module.conv2, qconfig: None
Module: layer4.1.module.bn2, qconfig: None
Module: layer4.1.skip_add, qconfig: None
Module: layer4.1.skip_add.activation_post_process, qconfig: None
Module: avgpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1F0A0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1F0A0>})
Module: fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1F370>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001A198E1F370>})
[DATA] Example input shape: torch.Size([64, 3, 32, 32])
[PREPARE] Model prepared successfully.
[HOOK] Performing QAT training hook.
[HOOK] QAT epoch 1/5 started.
[HOOK][Epoch: 1] Batch 1 Loss: 1.2503
[HOOK][Epoch: 1] Batch 51 Loss: 0.2764
[HOOK][Epoch: 1] Batch 101 Loss: 0.0787
[HOOK][Epoch: 1] Batch 151 Loss: 0.1441
[HOOK][Epoch: 1] Batch 201 Loss: 0.2975
[HOOK][Epoch: 1] Batch 251 Loss: 0.9271
[HOOK][Epoch: 1] Batch 301 Loss: 0.1061
[HOOK][Epoch: 1] Batch 351 Loss: 0.1140
[HOOK][Epoch: 1] Batch 401 Loss: 0.3190
[HOOK][Epoch: 1] Batch 451 Loss: 0.3884
[HOOK][Epoch: 1] Batch 501 Loss: 0.1685
[HOOK][Epoch: 1] Batch 551 Loss: 0.2318
[HOOK][Epoch: 1] Batch 601 Loss: 0.1733
[HOOK] QAT epoch 2/5 started.
[HOOK][Epoch: 2] Batch 1 Loss: 0.0290
[HOOK][Epoch: 2] Batch 51 Loss: 0.0483
[HOOK][Epoch: 2] Batch 101 Loss: 0.1049
[HOOK][Epoch: 2] Batch 151 Loss: 0.0373
[HOOK][Epoch: 2] Batch 201 Loss: 0.0179
[HOOK][Epoch: 2] Batch 251 Loss: 0.0819
[HOOK][Epoch: 2] Batch 301 Loss: 0.1671
[HOOK][Epoch: 2] Batch 351 Loss: 0.1362
[HOOK][Epoch: 2] Batch 401 Loss: 0.0424
[HOOK][Epoch: 2] Batch 451 Loss: 0.2234
Generations:   0%|                                                                                                                                             | 0/10000 [1:49:58<?, ?gen/s]
