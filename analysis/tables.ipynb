{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b5a40f",
   "metadata": {},
   "source": [
    "## CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cc9f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Pipelines:\n",
      "CPU - low-rank_quant-dynamic_pruning_quant-qat: f1 = 0.758 (-0.1%)\n",
      "CPU - low-rank_quant-qat_pruning_quant-static: f1 = 0.747 (-1.6%)\n",
      "CPU - low-rank_quant-static_pruning_quant-qat: f1 = 0.746 (-1.7%)\n",
      "CPU - pruning_quant-dynamic_low-rank_quant-qat: f1 = 0.736 (-3.0%)\n",
      "CPU - quant-dynamic_low-rank_quant-static_pruning: f1 = 0.732 (-3.6%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "import numpy as np\n",
    "\n",
    "def extract_quality(filepath, quality_metric='f1'):\n",
    "    \"\"\"\n",
    "    Extract quality metrics from an Excel file.\n",
    "    Returns init and step metrics for the specified quality metric.\n",
    "    \"\"\"\n",
    "    xls = pd.ExcelFile(filepath)\n",
    "    quality = pd.read_excel(xls, 'quality_comparison')\n",
    "    quality.columns = quality.iloc[0]\n",
    "    quality = quality.drop(quality.index[0])\n",
    "    init_val = quality[quality['mode'] == quality_metric]['original'].values[0]\n",
    "    step_val = quality[quality['mode'] == quality_metric]['fedcore'].values[0]\n",
    "    return float(init_val), float(step_val)\n",
    "\n",
    "def extract_computational(filepath):\n",
    "    \"\"\"\n",
    "    Extract computational metrics from an Excel file.\n",
    "    Returns latency, size, and throughput for init and step.\n",
    "    \"\"\"\n",
    "    xls = pd.ExcelFile(filepath)\n",
    "    computational = pd.read_excel(xls, 'computational_comparison')\n",
    "    latency_init, size_init, thr_init = computational.iloc[2, 1], computational.iloc[3, 1], computational.iloc[4, 1]\n",
    "    latency_step, size_step, thr_step = computational.iloc[2, 2], computational.iloc[3, 2], computational.iloc[4, 2]\n",
    "    return (float(latency_init), float(size_init), float(thr_init)), (float(latency_step), float(size_step), float(thr_step))\n",
    "\n",
    "def analyze_results(gpu_path, cpu_path, tab_name, quality_metric='f1'):\n",
    "    \"\"\"\n",
    "    Analyze PEFT pipeline results and generate plots and tables for top 5 pipelines.\n",
    "    \"\"\"\n",
    "    # Create output directories\n",
    "    os.makedirs('imgs', exist_ok=True)\n",
    "    os.makedirs('tables', exist_ok=True)\n",
    "\n",
    "    # Initialize results storage\n",
    "    results = []\n",
    "\n",
    "    # Process both GPU and CPU folders\n",
    "    for device_path, device in [(gpu_path, 'GPU'), (cpu_path, 'CPU')]:\n",
    "        for pipeline in os.listdir(device_path):\n",
    "            # Check if pipeline has exactly 4 steps\n",
    "            if pipeline == '.DS_Store':\n",
    "                continue\n",
    "            try:\n",
    "                xlsx_files = [f for f in os.listdir(os.path.join(device_path, pipeline)) if f.endswith('.xlsx')]\n",
    "            except:\n",
    "                _ = 1\n",
    "            count = len(xlsx_files)\n",
    "            if count < 3:\n",
    "                continue\n",
    "\n",
    "            pipeline_path = os.path.join(device_path, pipeline)\n",
    "            if not os.path.isdir(pipeline_path):\n",
    "                continue\n",
    "\n",
    "            # Extract metrics for each step\n",
    "            quality_metrics = []\n",
    "            comp_metrics = []\n",
    "            for step_file in sorted(os.listdir(pipeline_path)):\n",
    "                if not step_file.endswith('.xlsx'):\n",
    "                    continue\n",
    "                step_path = os.path.join(pipeline_path, step_file)\n",
    "                quality_metrics.append(extract_quality(step_path, quality_metric))\n",
    "                comp_metrics.append(extract_computational(step_path))\n",
    "\n",
    "            # Use final step metrics for comparison\n",
    "            # try:\n",
    "            init_quality, final_quality = quality_metrics[0][0], quality_metrics[-1][1]\n",
    "            (init_latency, init_size, init_thr), (final_latency, final_size, final_thr) = comp_metrics[0][0], comp_metrics[-1][1]\n",
    "            # except:\n",
    "            #     _ = 1\n",
    "\n",
    "            # Calculate percentage changes\n",
    "            quality_change = ((final_quality - init_quality) / init_quality * 100) if init_quality != 0 else 0\n",
    "            latency_change = ((final_latency - init_latency) / init_latency * 100) if init_latency != 0 else 0\n",
    "            size_change = ((final_size - init_size) / init_size * 100) if init_size != 0 else 0\n",
    "            thr_change = ((final_thr - init_thr) / init_thr * 100) if init_thr != 0 else 0\n",
    "\n",
    "            results.append({\n",
    "                'pipeline': pipeline,\n",
    "                'device': device,\n",
    "                'quality_init': init_quality,\n",
    "                'quality_final': final_quality,\n",
    "                'quality_change': quality_change,\n",
    "                'latency': final_latency,\n",
    "                'latency_change': latency_change,\n",
    "                'throughput': final_thr,\n",
    "                'throughput_change': thr_change,\n",
    "                'size': final_size,\n",
    "                'size_change': size_change\n",
    "            })\n",
    "\n",
    "    # Create DataFrame and sort by quality metric\n",
    "    df = pd.DataFrame(results)\n",
    "    if quality_metric.lower() == 'rmse':\n",
    "        top_5_cpu = df[df['device'] == 'CPU'].sort_values('quality_final').head(5)\n",
    "        top_5_gpu = df[df['device'] == 'GPU'].sort_values('quality_final').head(5)\n",
    "    else:\n",
    "        # top_5 = df.sort_values('quality_final', ascending=False).head(5)\n",
    "        top_5_cpu = df[df['device'] == 'CPU'].sort_values('quality_final', ascending=False).head(5)\n",
    "        top_5_gpu = df[df['device'] == 'GPU'].sort_values('quality_final', ascending=False).head(5)\n",
    "\n",
    "    top_5 = pd.concat([top_5_gpu, top_5_cpu], axis=0).reset_index(drop=True)\n",
    "    if quality_metric.lower() == 'rmse':\n",
    "        best_top = top_5.sort_values('quality_final').head(5)\n",
    "    else:\n",
    "        best_top = top_5.sort_values('quality_final', ascending=False).head(5)\n",
    "    # Print top 5 pipelines\n",
    "    print(\"Top 5 Pipelines:\")\n",
    "    for _, row in best_top.iterrows():\n",
    "        print(f\"{row['device']} - {row['pipeline']}: {quality_metric} = {row['quality_final']:.3f} ({row['quality_change']:+.1f}%)\")\n",
    "\n",
    "    # Plot quality metrics before and after\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(top_5))\n",
    "    plt.bar(index, top_5['quality_init'], bar_width, label='Before')\n",
    "    plt.bar(index + bar_width, top_5['quality_final'], bar_width, label='After')\n",
    "    plt.xlabel('Pipeline')\n",
    "    plt.ylabel(quality_metric)\n",
    "    plt.title(f'{quality_metric} Before and After Pipeline')\n",
    "    plt.xticks(index + bar_width/2, [f\"{row['device']}: {row['pipeline']}\" for _, row in top_5.iterrows()], rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('imgs/quality_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot percentage changes\n",
    "    metrics = ['quality_change', 'latency_change', 'throughput_change', 'size_change']\n",
    "    metric_labels = [quality_metric, 'Latency', 'Throughput', 'Model Size']\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, (metric, label) in enumerate(zip(metrics, metric_labels)):\n",
    "        plt.bar(index + i*bar_width, top_5[metric], bar_width, label=label)\n",
    "    plt.xlabel('Pipeline')\n",
    "    plt.ylabel('Percentage Change (%)')\n",
    "    plt.title('Percentage Change in Metrics by Pipeline')\n",
    "    plt.xticks(index + 1.5*bar_width, [f\"{row['device']}: {row['pipeline']}\" for _, row in top_5.iterrows()], rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('imgs/percent_change.png')\n",
    "    plt.close()\n",
    "\n",
    "    #  table data\n",
    "    table_data = []\n",
    "    # original row\n",
    "    original_row = {\n",
    "        'Pipeline': 'Original',\n",
    "        quality_metric: f\"{top_5['quality_init'].iloc[0]:.3f}\",\n",
    "        'CPU Latency (ms)': f\"{df[df['device'] == 'CPU']['latency'].iloc[0]:.3f}\",\n",
    "        'GPU Latency (ms)': f\"{df[df['device'] == 'GPU']['latency'].iloc[0]:.3f}\",\n",
    "        'CPU Throughput (IPS)': f\"{df[df['device'] == 'CPU']['throughput'].iloc[0]:.0f}\",\n",
    "        'GPU Throughput (IPS)': f\"{df[df['device'] == 'GPU']['throughput'].iloc[0]:.0f}\",\n",
    "        'Model Size (MB)': f\"{top_5['size'].iloc[0]:.3f}\"\n",
    "    }\n",
    "    # table_data.append(original_row)\n",
    "\n",
    "\n",
    "    for _, row in top_5.iterrows():\n",
    "        table_row = {\n",
    "            # 'Pipeline': f\"{row['device']}: {row['pipeline']}\",\n",
    "            'Pipeline': f\"{row['pipeline']}\",\n",
    "            'Device': row['device'],\n",
    "            quality_metric: f\"{row['quality_final']:.3f} / {row['quality_change']:+.1f}%\",\n",
    "            'CPU Latency (ms)': f\"{row['latency']:.3f} / {row['latency_change']:+.1f}%\" if row['device'] == 'CPU' else '∞',\n",
    "            'GPU Latency (ms)': f\"{row['latency']:.3f} / {row['latency_change']:+.1f}%\" if row['device'] == 'GPU' else '∞',\n",
    "            'CPU Throughput (IPS)': f\"{row['throughput']:.0f} / {row['throughput_change']:+.1f}%\" if row['device'] == 'CPU' else '∞',\n",
    "            'GPU Throughput (IPS)': f\"{row['throughput']:.0f} / {row['throughput_change']:+.1f}%\" if row['device'] == 'GPU' else '∞',\n",
    "            'Model Size (MB)': f\"{row['size']:.3f} / {row['size_change']:+.1f}%\"\n",
    "        }\n",
    "        table_data.append(table_row)\n",
    "\n",
    "    table_df = pd.DataFrame(table_data)\n",
    "    table_df = table_df.groupby('Pipeline')[[\n",
    "        quality_metric, 'CPU Latency (ms)', 'GPU Latency (ms)',\n",
    "        'CPU Throughput (IPS)', 'GPU Throughput (IPS)', 'Model Size (MB)'\n",
    "        ]].min().reset_index(drop=False)\n",
    "    \n",
    "    original_df = pd.DataFrame(original_row, index=[0])\n",
    "    table_df = pd.concat([original_df, table_df], axis=0).reset_index(drop=True)\n",
    "    table_df.to_csv(f'tables/{tab_name}.csv', index=True)\n",
    "\n",
    "    # latex table\n",
    "    latex_content = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "\\\\centering\n",
    "\\\\caption{Top 5 PEFT Pipelines}\n",
    "\\\\label{tab:peft_pipelines}\n",
    "\\\\resizebox{\\\\textwidth}{!}{%\n",
    "\\\\begin{tabular}{lcccccc}\n",
    "\\\\toprule\n",
    "\\\\textbf{Pipeline} & \\\\textbf{\"\"\" + quality_metric + \"\"\"} & \\\\textbf{CPU Latency (ms)} & \\\\textbf{GPU Latency (ms)} & \\\\textbf{CPU Throughput (IPS)} & \\\\textbf{GPU Throughput (IPS)} & \\\\textbf{Model Size (MB)} \\\\\n",
    "\\\\midrule\n",
    "\"\"\"\n",
    "    for i, row in enumerate(table_data):\n",
    "        escaped_row = {k: str(v).replace('%', '\\%').replace('∞', '$\\infty$') for k, v in row.items()}\n",
    "        # latex_content += \" & \".join(str(val) for val in row.values()) + \" \\\\\\\\\\n\"\n",
    "        latex_content += \" & \".join(escaped_row.values()) + \" \\\\\\\\\\n\"\n",
    "\n",
    "        if i == 0:\n",
    "            latex_content += \"\\\\cmidrule{1-7}\\n\"\n",
    "\n",
    "    latex_content += \"\"\"\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "}\n",
    "\\\\footnotesize\n",
    "\\\\vspace{0.2cm}\n",
    "\\\\emph{Note}: Values show final metric / percentage change from original. Best values are bold for non-quantized models and underlined for quantized models. Abbreviations: LR - Low-Rank Decomposition, Pr - Pruning, QAT - Quant-Aware Training, PDQ - Post-training Dynamic Quantization.\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "    # Save LaTeX table\n",
    "    with open(f'tables/{tab_name}_latex.txt', 'w') as f:\n",
    "        f.write(latex_content)\n",
    "\n",
    "    return table_df\n",
    "\n",
    "gpu_path = \"../results/ResNet18/CIFAR10\"\n",
    "cpu_path = \"../results_cpu/ResNet18/CIFAR10\"\n",
    "\n",
    "tab_name = 'cifar'\n",
    "tab = analyze_results(gpu_path, cpu_path, tab_name, quality_metric='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "992cf107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>f1</th>\n",
       "      <th>CPU Latency (ms)</th>\n",
       "      <th>GPU Latency (ms)</th>\n",
       "      <th>CPU Throughput (IPS)</th>\n",
       "      <th>GPU Throughput (IPS)</th>\n",
       "      <th>Model Size (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Original</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1.901</td>\n",
       "      <td>1890</td>\n",
       "      <td>17</td>\n",
       "      <td>43.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low-rank_quant-dynamic_pruning_quant-qat</td>\n",
       "      <td>0.702 / -7.5%</td>\n",
       "      <td>0.005 / +9.6%</td>\n",
       "      <td>2.271 / +79.9%</td>\n",
       "      <td>1436 / -22.8%</td>\n",
       "      <td>15 / -42.0%</td>\n",
       "      <td>43.349 / +1.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>low-rank_quant-qat_pruning_quant-static</td>\n",
       "      <td>0.747 / -1.6%</td>\n",
       "      <td>0.005 / +9.8%</td>\n",
       "      <td>∞</td>\n",
       "      <td>1792 / -9.4%</td>\n",
       "      <td>∞</td>\n",
       "      <td>44.137 / +3.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>low-rank_quant-static_pruning_quant-dynamic</td>\n",
       "      <td>0.656 / -13.6%</td>\n",
       "      <td>∞</td>\n",
       "      <td>1.873 / +34.9%</td>\n",
       "      <td>∞</td>\n",
       "      <td>17 / -25.0%</td>\n",
       "      <td>10.861 / -74.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low-rank_quant-static_pruning_quant-qat</td>\n",
       "      <td>0.660 / -13.0%</td>\n",
       "      <td>0.004 / -4.9%</td>\n",
       "      <td>1.901 / +34.5%</td>\n",
       "      <td>1890 / -6.7%</td>\n",
       "      <td>17 / -24.4%</td>\n",
       "      <td>10.854 / -74.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pruning_quant-dynamic_low-rank_quant-qat</td>\n",
       "      <td>0.642 / -15.5%</td>\n",
       "      <td>0.005 / +2.4%</td>\n",
       "      <td>1.983 / +54.0%</td>\n",
       "      <td>1912 / -3.2%</td>\n",
       "      <td>15 / -43.6%</td>\n",
       "      <td>10.607 / -75.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pruning_quant-qat_low-rank_quant-dynamic</td>\n",
       "      <td>0.639 / -15.9%</td>\n",
       "      <td>∞</td>\n",
       "      <td>2.080 / +83.5%</td>\n",
       "      <td>∞</td>\n",
       "      <td>24 / -18.2%</td>\n",
       "      <td>10.607 / -75.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>quant-dynamic_low-rank_quant-static_pruning</td>\n",
       "      <td>0.732 / -3.6%</td>\n",
       "      <td>0.004 / -8.0%</td>\n",
       "      <td>∞</td>\n",
       "      <td>2139 / +16.1%</td>\n",
       "      <td>∞</td>\n",
       "      <td>43.466 / +1.9%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Pipeline              f1  \\\n",
       "0                                     Original           0.759   \n",
       "1     low-rank_quant-dynamic_pruning_quant-qat   0.702 / -7.5%   \n",
       "2      low-rank_quant-qat_pruning_quant-static   0.747 / -1.6%   \n",
       "3  low-rank_quant-static_pruning_quant-dynamic  0.656 / -13.6%   \n",
       "4      low-rank_quant-static_pruning_quant-qat  0.660 / -13.0%   \n",
       "5     pruning_quant-dynamic_low-rank_quant-qat  0.642 / -15.5%   \n",
       "6     pruning_quant-qat_low-rank_quant-dynamic  0.639 / -15.9%   \n",
       "7  quant-dynamic_low-rank_quant-static_pruning   0.732 / -3.6%   \n",
       "\n",
       "  CPU Latency (ms) GPU Latency (ms) CPU Throughput (IPS) GPU Throughput (IPS)  \\\n",
       "0            0.004            1.901                 1890                   17   \n",
       "1    0.005 / +9.6%   2.271 / +79.9%        1436 / -22.8%          15 / -42.0%   \n",
       "2    0.005 / +9.8%                ∞         1792 / -9.4%                    ∞   \n",
       "3                ∞   1.873 / +34.9%                    ∞          17 / -25.0%   \n",
       "4    0.004 / -4.9%   1.901 / +34.5%         1890 / -6.7%          17 / -24.4%   \n",
       "5    0.005 / +2.4%   1.983 / +54.0%         1912 / -3.2%          15 / -43.6%   \n",
       "6                ∞   2.080 / +83.5%                    ∞          24 / -18.2%   \n",
       "7    0.004 / -8.0%                ∞        2139 / +16.1%                    ∞   \n",
       "\n",
       "   Model Size (MB)  \n",
       "0           43.349  \n",
       "1   43.349 / +1.6%  \n",
       "2   44.137 / +3.5%  \n",
       "3  10.861 / -74.5%  \n",
       "4  10.854 / -74.6%  \n",
       "5  10.607 / -75.1%  \n",
       "6  10.607 / -75.1%  \n",
       "7   43.466 / +1.9%  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe7215a",
   "metadata": {},
   "source": [
    "## imagenette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdda92d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Pipelines:\n",
      "GPU - pruning_quant-static_low-rank_quant-qat: f1 = 0.477 (+2068.2%)\n",
      "GPU - pruning_quant-dynamic_low-rank_quant-qat: f1 = 0.472 (+2045.5%)\n",
      "GPU - pruning_quant-static_low-rank_quant-dynamic: f1 = 0.467 (+2022.7%)\n",
      "GPU - pruning_quant-dynamic_low-rank_quant-static: f1 = 0.462 (+2000.0%)\n",
      "GPU - pruning_quant-qat_low-rank_quant-dynamic: f1 = 0.461 (+1995.5%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "import numpy as np\n",
    "\n",
    "def extract_quality(filepath, quality_metric='f1'):\n",
    "    \"\"\"\n",
    "    Extract quality metrics from an Excel file.\n",
    "    Returns init and step metrics for the specified quality metric.\n",
    "    \"\"\"\n",
    "    xls = pd.ExcelFile(filepath)\n",
    "    quality = pd.read_excel(xls, 'quality_comparison')\n",
    "    quality.columns = quality.iloc[0]\n",
    "    quality = quality.drop(quality.index[0])\n",
    "    init_val = quality[quality['mode'] == quality_metric]['original'].values[0]\n",
    "    step_val = quality[quality['mode'] == quality_metric]['fedcore'].values[0]\n",
    "    return float(init_val), float(step_val)\n",
    "\n",
    "def extract_computational(filepath):\n",
    "    \"\"\"\n",
    "    Extract computational metrics from an Excel file.\n",
    "    Returns latency, size, and throughput for init and step.\n",
    "    \"\"\"\n",
    "    xls = pd.ExcelFile(filepath)\n",
    "    computational = pd.read_excel(xls, 'computational_comparison')\n",
    "    latency_init, size_init, thr_init = computational.iloc[2, 1], computational.iloc[3, 1], computational.iloc[4, 1]\n",
    "    latency_step, size_step, thr_step = computational.iloc[2, 2], computational.iloc[3, 2], computational.iloc[4, 2]\n",
    "    return (float(latency_init), float(size_init), float(thr_init)), (float(latency_step), float(size_step), float(thr_step))\n",
    "\n",
    "def analyze_results(gpu_path, cpu_path, tab_name, quality_metric='f1'):\n",
    "    \"\"\"\n",
    "    Analyze PEFT pipeline results and generate plots and tables for top 5 pipelines.\n",
    "    \"\"\"\n",
    "    # Create output directories\n",
    "    os.makedirs('imgs', exist_ok=True)\n",
    "    os.makedirs('tables', exist_ok=True)\n",
    "\n",
    "    # Initialize results storage\n",
    "    results = []\n",
    "\n",
    "    # Process both GPU and CPU folders\n",
    "    for device_path, device in [(gpu_path, 'GPU'), (cpu_path, 'CPU')]:\n",
    "        if device_path is None:\n",
    "            continue\n",
    "        for pipeline in os.listdir(device_path):\n",
    "            # Check if pipeline has exactly 4 steps\n",
    "            if pipeline == '.DS_Store':\n",
    "                continue\n",
    "            try:\n",
    "                xlsx_files = [f for f in os.listdir(os.path.join(device_path, pipeline)) if f.endswith('.xlsx')]\n",
    "            except:\n",
    "                _ = 1\n",
    "            count = len(xlsx_files)\n",
    "            if count < 3:\n",
    "                continue\n",
    "\n",
    "            pipeline_path = os.path.join(device_path, pipeline)\n",
    "            if not os.path.isdir(pipeline_path):\n",
    "                continue\n",
    "\n",
    "            # Extract metrics for each step\n",
    "            quality_metrics = []\n",
    "            comp_metrics = []\n",
    "            for step_file in sorted(os.listdir(pipeline_path)):\n",
    "                if not step_file.endswith('.xlsx'):\n",
    "                    continue\n",
    "                step_path = os.path.join(pipeline_path, step_file)\n",
    "                quality_metrics.append(extract_quality(step_path, quality_metric))\n",
    "                comp_metrics.append(extract_computational(step_path))\n",
    "\n",
    "            # Use final step metrics for comparison\n",
    "            # try:\n",
    "            init_quality, final_quality = quality_metrics[0][0], quality_metrics[-1][1]\n",
    "            (init_latency, init_size, init_thr), (final_latency, final_size, final_thr) = comp_metrics[0][0], comp_metrics[-1][1]\n",
    "            # except:\n",
    "            #     _ = 1\n",
    "\n",
    "            # Calculate percentage changes\n",
    "            quality_change = ((final_quality - init_quality) / init_quality * 100) if init_quality != 0 else 0\n",
    "            latency_change = ((final_latency - init_latency) / init_latency * 100) if init_latency != 0 else 0\n",
    "            size_change = ((final_size - init_size) / init_size * 100) if init_size != 0 else 0\n",
    "            thr_change = ((final_thr - init_thr) / init_thr * 100) if init_thr != 0 else 0\n",
    "\n",
    "            results.append({\n",
    "                'pipeline': pipeline,\n",
    "                'device': device,\n",
    "                'quality_init': init_quality,\n",
    "                'quality_final': final_quality,\n",
    "                'quality_change': quality_change,\n",
    "                'latency': final_latency,\n",
    "                'latency_change': latency_change,\n",
    "                'throughput': final_thr,\n",
    "                'throughput_change': thr_change,\n",
    "                'size': final_size,\n",
    "                'size_change': size_change\n",
    "            })\n",
    "\n",
    "    # Create DataFrame and sort by quality metric\n",
    "    df = pd.DataFrame(results)\n",
    "    if quality_metric.lower() == 'rmse':\n",
    "        top_5_cpu = df[df['device'] == 'CPU'].sort_values('quality_final').head(5)\n",
    "        top_5_gpu = df[df['device'] == 'GPU'].sort_values('quality_final').head(5)\n",
    "    else:\n",
    "        # top_5 = df.sort_values('quality_final', ascending=False).head(5)\n",
    "        top_5_cpu = df[df['device'] == 'CPU'].sort_values('quality_final', ascending=False).head(5)\n",
    "        top_5_gpu = df[df['device'] == 'GPU'].sort_values('quality_final', ascending=False).head(5)\n",
    "\n",
    "    top_5 = pd.concat([top_5_gpu, top_5_cpu], axis=0).reset_index(drop=True)\n",
    "    if quality_metric.lower() == 'rmse':\n",
    "        best_top = top_5.sort_values('quality_final').head(5)\n",
    "    else:\n",
    "        best_top = top_5.sort_values('quality_final', ascending=False).head(5)\n",
    "    # Print top 5 pipelines\n",
    "    print(\"Top 5 Pipelines:\")\n",
    "    for _, row in best_top.iterrows():\n",
    "        print(f\"{row['device']} - {row['pipeline']}: {quality_metric} = {row['quality_final']:.3f} ({row['quality_change']:+.1f}%)\")\n",
    "\n",
    "    # Plot quality metrics before and after\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(top_5))\n",
    "    plt.bar(index, top_5['quality_init'], bar_width, label='Before')\n",
    "    plt.bar(index + bar_width, top_5['quality_final'], bar_width, label='After')\n",
    "    plt.xlabel('Pipeline')\n",
    "    plt.ylabel(quality_metric)\n",
    "    plt.title(f'{quality_metric} Before and After Pipeline')\n",
    "    plt.xticks(index + bar_width/2, [f\"{row['device']}: {row['pipeline']}\" for _, row in top_5.iterrows()], rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('imgs/quality_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot percentage changes\n",
    "    metrics = ['quality_change', 'latency_change', 'throughput_change', 'size_change']\n",
    "    metric_labels = [quality_metric, 'Latency', 'Throughput', 'Model Size']\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, (metric, label) in enumerate(zip(metrics, metric_labels)):\n",
    "        plt.bar(index + i*bar_width, top_5[metric], bar_width, label=label)\n",
    "    plt.xlabel('Pipeline')\n",
    "    plt.ylabel('Percentage Change (%)')\n",
    "    plt.title('Percentage Change in Metrics by Pipeline')\n",
    "    plt.xticks(index + 1.5*bar_width, [f\"{row['device']}: {row['pipeline']}\" for _, row in top_5.iterrows()], rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('imgs/percent_change.png')\n",
    "    plt.close()\n",
    "\n",
    "    #  table data\n",
    "    table_data = []\n",
    "    # original row\n",
    "    original_row = {\n",
    "        'Pipeline': 'Original',\n",
    "        quality_metric: f\"{top_5['quality_init'].iloc[0]:.3f}\",\n",
    "        'CPU Latency (ms)': f\"{df[df['device'] == 'CPU']['latency'].iloc[0]:.3f}\" if len(df[df['device'] == 'CPU']['latency']) > 0 else np.NaN,\n",
    "        'GPU Latency (ms)': f\"{df[df['device'] == 'GPU']['latency'].iloc[0]:.3f}\" if len(df[df['device'] == 'GPU']['latency']) > 0 else np.NaN,\n",
    "        'CPU Throughput (IPS)': f\"{df[df['device'] == 'CPU']['throughput'].iloc[0]:.0f}\" if len(df[df['device'] == 'CPU']['throughput']) > 0 else np.NaN,\n",
    "        'GPU Throughput (IPS)': f\"{df[df['device'] == 'GPU']['throughput'].iloc[0]:.0f}\"if len(df[df['device'] == 'GPU']['throughput']) > 0 else np.NaN,\n",
    "        'Model Size (MB)': f\"{top_5['size'].iloc[0]:.3f}\"\n",
    "    }\n",
    "    # table_data.append(original_row)\n",
    "\n",
    "\n",
    "    for _, row in top_5.iterrows():\n",
    "        table_row = {\n",
    "            # 'Pipeline': f\"{row['device']}: {row['pipeline']}\",\n",
    "            'Pipeline': f\"{row['pipeline']}\",\n",
    "            'Device': row['device'],\n",
    "            quality_metric: f\"{row['quality_final']:.3f} / {row['quality_change']:+.1f}%\",\n",
    "            'CPU Latency (ms)': f\"{row['latency']:.3f} / {row['latency_change']:+.1f}%\" if row['device'] == 'CPU' else '∞',\n",
    "            'GPU Latency (ms)': f\"{row['latency']:.3f} / {row['latency_change']:+.1f}%\" if row['device'] == 'GPU' else '∞',\n",
    "            'CPU Throughput (IPS)': f\"{row['throughput']:.0f} / {row['throughput_change']:+.1f}%\" if row['device'] == 'CPU' else '∞',\n",
    "            'GPU Throughput (IPS)': f\"{row['throughput']:.0f} / {row['throughput_change']:+.1f}%\" if row['device'] == 'GPU' else '∞',\n",
    "            'Model Size (MB)': f\"{row['size']:.3f} / {row['size_change']:+.1f}%\"\n",
    "        }\n",
    "        table_data.append(table_row)\n",
    "\n",
    "    table_df = pd.DataFrame(table_data)\n",
    "    table_df = table_df.groupby('Pipeline')[[\n",
    "        quality_metric, 'CPU Latency (ms)', 'GPU Latency (ms)',\n",
    "        'CPU Throughput (IPS)', 'GPU Throughput (IPS)', 'Model Size (MB)'\n",
    "        ]].min().reset_index(drop=False)\n",
    "    \n",
    "    original_df = pd.DataFrame(original_row, index=[0])\n",
    "    table_df = pd.concat([original_df, table_df], axis=0).reset_index(drop=True)\n",
    "    table_df.to_csv(f'tables/{tab_name}.csv', index=True)\n",
    "\n",
    "    # latex table\n",
    "    latex_content = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "\\\\centering\n",
    "\\\\caption{Top 5 PEFT Pipelines}\n",
    "\\\\label{tab:peft_pipelines}\n",
    "\\\\resizebox{\\\\textwidth}{!}{%\n",
    "\\\\begin{tabular}{lcccccc}\n",
    "\\\\toprule\n",
    "\\\\textbf{Pipeline} & \\\\textbf{\"\"\" + quality_metric + \"\"\"} & \\\\textbf{CPU Latency (ms)} & \\\\textbf{GPU Latency (ms)} & \\\\textbf{CPU Throughput (IPS)} & \\\\textbf{GPU Throughput (IPS)} & \\\\textbf{Model Size (MB)} \\\\\n",
    "\\\\midrule\n",
    "\"\"\"\n",
    "    for i, row in enumerate(table_data):\n",
    "        escaped_row = {k: str(v).replace('%', '\\%').replace('∞', '$\\infty$') for k, v in row.items()}\n",
    "        # latex_content += \" & \".join(str(val) for val in row.values()) + \" \\\\\\\\\\n\"\n",
    "        latex_content += \" & \".join(escaped_row.values()) + \" \\\\\\\\\\n\"\n",
    "\n",
    "        if i == 0:\n",
    "            latex_content += \"\\\\cmidrule{1-7}\\n\"\n",
    "\n",
    "    latex_content += \"\"\"\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "}\n",
    "\\\\footnotesize\n",
    "\\\\vspace{0.2cm}\n",
    "\\\\emph{Note}: Values show final metric / percentage change from original. Best values are bold for non-quantized models and underlined for quantized models. Abbreviations: LR - Low-Rank Decomposition, Pr - Pruning, QAT - Quant-Aware Training, PDQ - Post-training Dynamic Quantization.\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "    # Save LaTeX table\n",
    "    with open(f'tables/{tab_name}_latex.txt', 'w') as f:\n",
    "        f.write(latex_content)\n",
    "\n",
    "    return table_df\n",
    "\n",
    "gpu_path = \"../results/ResNet18/Imagenette\"\n",
    "# cpu_path = \"../results_cpu/ResNet18/Imagenette\"\n",
    "\n",
    "# tab_name = 'imagenette'\n",
    "tab = analyze_results(gpu_path=gpu_path, cpu_path=None, tab_name='imagenette', quality_metric='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "732f92ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>f1</th>\n",
       "      <th>CPU Latency (ms)</th>\n",
       "      <th>GPU Latency (ms)</th>\n",
       "      <th>CPU Throughput (IPS)</th>\n",
       "      <th>GPU Throughput (IPS)</th>\n",
       "      <th>Model Size (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Original</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>10.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pruning_quant-dynamic_low-rank_quant-qat</td>\n",
       "      <td>0.472 / +2045.5%</td>\n",
       "      <td>∞</td>\n",
       "      <td>1.991 / +11.5%</td>\n",
       "      <td>∞</td>\n",
       "      <td>18 / +93.9%</td>\n",
       "      <td>10.453 / -75.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pruning_quant-dynamic_low-rank_quant-static</td>\n",
       "      <td>0.462 / +2000.0%</td>\n",
       "      <td>∞</td>\n",
       "      <td>2.016 / +39.0%</td>\n",
       "      <td>∞</td>\n",
       "      <td>17 / +68.2%</td>\n",
       "      <td>10.453 / -75.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pruning_quant-qat_low-rank_quant-dynamic</td>\n",
       "      <td>0.461 / +1995.5%</td>\n",
       "      <td>∞</td>\n",
       "      <td>2.007 / +43.9%</td>\n",
       "      <td>∞</td>\n",
       "      <td>17 / +60.6%</td>\n",
       "      <td>10.453 / -75.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pruning_quant-static_low-rank_quant-dynamic</td>\n",
       "      <td>0.467 / +2022.7%</td>\n",
       "      <td>∞</td>\n",
       "      <td>2.004 / +38.3%</td>\n",
       "      <td>∞</td>\n",
       "      <td>17 / +57.6%</td>\n",
       "      <td>10.453 / -75.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pruning_quant-static_low-rank_quant-qat</td>\n",
       "      <td>0.477 / +2068.2%</td>\n",
       "      <td>∞</td>\n",
       "      <td>2.057 / +49.9%</td>\n",
       "      <td>∞</td>\n",
       "      <td>17 / +68.3%</td>\n",
       "      <td>10.453 / -75.5%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Pipeline                f1  \\\n",
       "0                                     Original             0.022   \n",
       "1     pruning_quant-dynamic_low-rank_quant-qat  0.472 / +2045.5%   \n",
       "2  pruning_quant-dynamic_low-rank_quant-static  0.462 / +2000.0%   \n",
       "3     pruning_quant-qat_low-rank_quant-dynamic  0.461 / +1995.5%   \n",
       "4  pruning_quant-static_low-rank_quant-dynamic  0.467 / +2022.7%   \n",
       "5      pruning_quant-static_low-rank_quant-qat  0.477 / +2068.2%   \n",
       "\n",
       "  CPU Latency (ms) GPU Latency (ms) CPU Throughput (IPS) GPU Throughput (IPS)  \\\n",
       "0              NaN            1.796                  NaN                   20   \n",
       "1                ∞   1.991 / +11.5%                    ∞          18 / +93.9%   \n",
       "2                ∞   2.016 / +39.0%                    ∞          17 / +68.2%   \n",
       "3                ∞   2.007 / +43.9%                    ∞          17 / +60.6%   \n",
       "4                ∞   2.004 / +38.3%                    ∞          17 / +57.6%   \n",
       "5                ∞   2.057 / +49.9%                    ∞          17 / +68.3%   \n",
       "\n",
       "   Model Size (MB)  \n",
       "0           10.453  \n",
       "1  10.453 / -75.5%  \n",
       "2  10.453 / -75.5%  \n",
       "3  10.453 / -75.5%  \n",
       "4  10.453 / -75.5%  \n",
       "5  10.453 / -75.5%  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b76950",
   "metadata": {},
   "source": [
    "## ApplienceEnergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e93f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Pipelines:\n",
      "GPU - pruning_quant-static_low-rank_quant-dynamic: rmse = 3.811 (+10.8%)\n",
      "GPU - pruning_quant-static_low-rank_quant-qat: rmse = 3.817 (+10.9%)\n",
      "GPU - pruning_quant-qat_low-rank_quant-dynamic: rmse = 3.841 (+11.6%)\n",
      "GPU - pruning_quant-qat_low-rank_quant-static: rmse = 3.845 (+11.7%)\n",
      "GPU - low-rank_quant-qat_pruning_quant-dynamic: rmse = 4.577 (+33.0%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "import numpy as np\n",
    "\n",
    "def extract_quality(filepath, quality_metric='f1'):\n",
    "    \"\"\"\n",
    "    Extract quality metrics from an Excel file.\n",
    "    Returns init and step metrics for the specified quality metric.\n",
    "    \"\"\"\n",
    "    xls = pd.ExcelFile(filepath)\n",
    "    quality = pd.read_excel(xls, 'quality_comparison')\n",
    "    quality.columns = quality.iloc[0]\n",
    "    quality = quality.drop(quality.index[0])\n",
    "    init_val = quality[quality['mode'] == quality_metric]['original'].values[0]\n",
    "    step_val = quality[quality['mode'] == quality_metric]['fedcore'].values[0]\n",
    "    return float(init_val), float(step_val)\n",
    "\n",
    "def extract_computational(filepath):\n",
    "    \"\"\"\n",
    "    Extract computational metrics from an Excel file.\n",
    "    Returns latency, size, and throughput for init and step.\n",
    "    \"\"\"\n",
    "    xls = pd.ExcelFile(filepath)\n",
    "    computational = pd.read_excel(xls, 'computational_comparison')\n",
    "    latency_init, size_init, thr_init = computational.iloc[2, 1], computational.iloc[3, 1], computational.iloc[4, 1]\n",
    "    latency_step, size_step, thr_step = computational.iloc[2, 2], computational.iloc[3, 2], computational.iloc[4, 2]\n",
    "    return (float(latency_init), float(size_init), float(thr_init)), (float(latency_step), float(size_step), float(thr_step))\n",
    "\n",
    "def analyze_results(gpu_path, cpu_path, tab_name, quality_metric='f1'):\n",
    "    \"\"\"\n",
    "    Analyze PEFT pipeline results and generate plots and tables for top 5 pipelines.\n",
    "    \"\"\"\n",
    "    # Create output directories\n",
    "    os.makedirs('imgs', exist_ok=True)\n",
    "    os.makedirs('tables', exist_ok=True)\n",
    "\n",
    "    # Initialize results storage\n",
    "    results = []\n",
    "\n",
    "    # Process both GPU and CPU folders\n",
    "    for device_path, device in [(gpu_path, 'GPU'), (cpu_path, 'CPU')]:\n",
    "        if device_path is None:\n",
    "            continue\n",
    "        for pipeline in os.listdir(device_path):\n",
    "            # Check if pipeline has exactly 4 steps\n",
    "            if pipeline == '.DS_Store':\n",
    "                continue\n",
    "\n",
    "            xlsx_files = [f for f in os.listdir(os.path.join(device_path, pipeline)) if f.endswith('.xlsx')]\n",
    "\n",
    "            count = len(xlsx_files)\n",
    "            if count < 2:\n",
    "                continue\n",
    "\n",
    "            pipeline_path = os.path.join(device_path, pipeline)\n",
    "            if not os.path.isdir(pipeline_path):\n",
    "                continue\n",
    "\n",
    "            # Extract metrics for each step\n",
    "            quality_metrics = []\n",
    "            comp_metrics = []\n",
    "            for step_file in sorted(os.listdir(pipeline_path)):\n",
    "                if not step_file.endswith('.xlsx'):\n",
    "                    continue\n",
    "                step_path = os.path.join(pipeline_path, step_file)\n",
    "                quality_metrics.append(extract_quality(step_path, quality_metric))\n",
    "                comp_metrics.append(extract_computational(step_path))\n",
    "\n",
    "            # Use final step metrics for comparison\n",
    "            # try:\n",
    "            init_quality, final_quality = quality_metrics[0][0], quality_metrics[-1][1]\n",
    "            (init_latency, init_size, init_thr), (final_latency, final_size, final_thr) = comp_metrics[0][0], comp_metrics[-1][1]\n",
    "            # except:\n",
    "            #     _ = 1\n",
    "\n",
    "            # Calculate percentage changes\n",
    "            quality_change = ((final_quality - init_quality) / init_quality * 100) if init_quality != 0 else 0\n",
    "            latency_change = ((final_latency - init_latency) / init_latency * 100) if init_latency != 0 else 0\n",
    "            size_change = ((final_size - init_size) / init_size * 100) if init_size != 0 else 0\n",
    "            thr_change = ((final_thr - init_thr) / init_thr * 100) if init_thr != 0 else 0\n",
    "\n",
    "            results.append({\n",
    "                'pipeline': pipeline,\n",
    "                'device': device,\n",
    "                'quality_init': init_quality,\n",
    "                'quality_final': final_quality,\n",
    "                'quality_change': quality_change,\n",
    "                'latency': final_latency,\n",
    "                'latency_change': latency_change,\n",
    "                'throughput': final_thr,\n",
    "                'throughput_change': thr_change,\n",
    "                'size': final_size,\n",
    "                'size_change': size_change\n",
    "            })\n",
    "\n",
    "    # Create DataFrame and sort by quality metric\n",
    "    df = pd.DataFrame(results)\n",
    "    if quality_metric.lower() == 'rmse':\n",
    "        top_5_cpu = df[df['device'] == 'CPU'].sort_values('quality_final').head(5)\n",
    "        top_5_gpu = df[df['device'] == 'GPU'].sort_values('quality_final').head(5)\n",
    "    else:\n",
    "        # top_5 = df.sort_values('quality_final', ascending=False).head(5)\n",
    "        top_5_cpu = df[df['device'] == 'CPU'].sort_values('quality_final', ascending=False).head(5)\n",
    "        top_5_gpu = df[df['device'] == 'GPU'].sort_values('quality_final', ascending=False).head(5)\n",
    "\n",
    "    top_5 = pd.concat([top_5_gpu, top_5_cpu], axis=0).reset_index(drop=True)\n",
    "    if quality_metric.lower() == 'rmse':\n",
    "        best_top = top_5.sort_values('quality_final').head(5)\n",
    "    else:\n",
    "        best_top = top_5.sort_values('quality_final', ascending=False).head(5)\n",
    "    # Print top 5 pipelines\n",
    "    print(\"Top 5 Pipelines:\")\n",
    "    for _, row in best_top.iterrows():\n",
    "        print(f\"{row['device']} - {row['pipeline']}: {quality_metric} = {row['quality_final']:.3f} ({row['quality_change']:+.1f}%)\")\n",
    "\n",
    "    # Plot quality metrics before and after\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(top_5))\n",
    "    plt.bar(index, top_5['quality_init'], bar_width, label='Before')\n",
    "    plt.bar(index + bar_width, top_5['quality_final'], bar_width, label='After')\n",
    "    plt.xlabel('Pipeline')\n",
    "    plt.ylabel(quality_metric)\n",
    "    plt.title(f'{quality_metric} Before and After Pipeline')\n",
    "    plt.xticks(index + bar_width/2, [f\"{row['device']}: {row['pipeline']}\" for _, row in top_5.iterrows()], rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('imgs/quality_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot percentage changes\n",
    "    metrics = ['quality_change', 'latency_change', 'throughput_change', 'size_change']\n",
    "    metric_labels = [quality_metric, 'Latency', 'Throughput', 'Model Size']\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, (metric, label) in enumerate(zip(metrics, metric_labels)):\n",
    "        plt.bar(index + i*bar_width, top_5[metric], bar_width, label=label)\n",
    "    plt.xlabel('Pipeline')\n",
    "    plt.ylabel('Percentage Change (%)')\n",
    "    plt.title('Percentage Change in Metrics by Pipeline')\n",
    "    plt.xticks(index + 1.5*bar_width, [f\"{row['device']}: {row['pipeline']}\" for _, row in top_5.iterrows()], rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('imgs/percent_change.png')\n",
    "    plt.close()\n",
    "\n",
    "    #  table data\n",
    "    table_data = []\n",
    "    # original row\n",
    "    original_row = {\n",
    "        'Pipeline': 'Original',\n",
    "        quality_metric: f\"{top_5['quality_init'].iloc[0]:.3f}\",\n",
    "        'CPU Latency (ms)': f\"{df[df['device'] == 'CPU']['latency'].iloc[0]:.3f}\" if len(df[df['device'] == 'CPU']['latency']) > 0 else np.NaN,\n",
    "        'GPU Latency (ms)': f\"{df[df['device'] == 'GPU']['latency'].iloc[0]:.3f}\" if len(df[df['device'] == 'GPU']['latency']) > 0 else np.NaN,\n",
    "        'CPU Throughput (IPS)': f\"{df[df['device'] == 'CPU']['throughput'].iloc[0]:.0f}\" if len(df[df['device'] == 'CPU']['throughput']) > 0 else np.NaN,\n",
    "        'GPU Throughput (IPS)': f\"{df[df['device'] == 'GPU']['throughput'].iloc[0]:.0f}\"if len(df[df['device'] == 'GPU']['throughput']) > 0 else np.NaN,\n",
    "        'Model Size (MB)': f\"{top_5['size'].iloc[0]:.3f}\"\n",
    "    }\n",
    "    # table_data.append(original_row)\n",
    "\n",
    "\n",
    "    for _, row in top_5.iterrows():\n",
    "        table_row = {\n",
    "            # 'Pipeline': f\"{row['device']}: {row['pipeline']}\",\n",
    "            'Pipeline': f\"{row['pipeline']}\",\n",
    "            'Device': row['device'],\n",
    "            quality_metric: f\"{row['quality_final']:.3f} / {row['quality_change']:+.1f}%\",\n",
    "            'CPU Latency (ms)': f\"{row['latency']:.3f} / {row['latency_change']:+.1f}%\" if row['device'] == 'CPU' else '∞',\n",
    "            'GPU Latency (ms)': f\"{row['latency']:.3f} / {row['latency_change']:+.1f}%\" if row['device'] == 'GPU' else '∞',\n",
    "            'CPU Throughput (IPS)': f\"{row['throughput']:.0f} / {row['throughput_change']:+.1f}%\" if row['device'] == 'CPU' else '∞',\n",
    "            'GPU Throughput (IPS)': f\"{row['throughput']:.0f} / {row['throughput_change']:+.1f}%\" if row['device'] == 'GPU' else '∞',\n",
    "            'Model Size (MB)': f\"{row['size']:.3f} / {row['size_change']:+.1f}%\"\n",
    "        }\n",
    "        table_data.append(table_row)\n",
    "\n",
    "    table_df = pd.DataFrame(table_data)\n",
    "    table_df = table_df.groupby('Pipeline')[[\n",
    "        quality_metric, 'CPU Latency (ms)', 'GPU Latency (ms)',\n",
    "        'CPU Throughput (IPS)', 'GPU Throughput (IPS)', 'Model Size (MB)'\n",
    "        ]].min().reset_index(drop=False)\n",
    "    \n",
    "    original_df = pd.DataFrame(original_row, index=[0])\n",
    "    table_df = pd.concat([original_df, table_df], axis=0).reset_index(drop=True)\n",
    "    table_df.replace('∞', '$\\infty$')\n",
    "    table_df.to_csv(f'tables/{tab_name}.csv', index=True)\n",
    "\n",
    "    # latex table\n",
    "    latex_content = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "\\\\centering\n",
    "\\\\caption{Top 5 PEFT Pipelines}\n",
    "\\\\label{tab:peft_pipelines}\n",
    "\\\\resizebox{\\\\textwidth}{!}{%\n",
    "\\\\begin{tabular}{lcccccc}\n",
    "\\\\toprule\n",
    "\\\\textbf{Pipeline} & \\\\textbf{\"\"\" + quality_metric + \"\"\"} & \\\\textbf{CPU Latency (ms)} & \\\\textbf{GPU Latency (ms)} & \\\\textbf{CPU Throughput (IPS)} & \\\\textbf{GPU Throughput (IPS)} & \\\\textbf{Model Size (MB)} \\\\\n",
    "\\\\midrule\n",
    "\"\"\"\n",
    "    for i, row in enumerate(table_data):\n",
    "        escaped_row = {k: str(v).replace('%', '\\%').replace('∞', '$\\infty$') for k, v in row.items()}\n",
    "        # latex_content += \" & \".join(str(val) for val in row.values()) + \" \\\\\\\\\\n\"\n",
    "        latex_content += \" & \".join(escaped_row.values()) + \" \\\\\\\\\\n\"\n",
    "\n",
    "        if i == 0:\n",
    "            latex_content += \"\\\\cmidrule{1-7}\\n\"\n",
    "\n",
    "    latex_content += \"\"\"\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "}\n",
    "\\\\footnotesize\n",
    "\\\\vspace{0.2cm}\n",
    "\\\\emph{Note}: Values show final metric / percentage change from original. Best values are bold for non-quantized models and underlined for quantized models. Abbreviations: LR - Low-Rank Decomposition, Pr - Pruning, QAT - Quant-Aware Training, PDQ - Post-training Dynamic Quantization.\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "    # Save LaTeX table\n",
    "    with open(f'tables/{tab_name}_latex.txt', 'w') as f:\n",
    "        f.write(latex_content)\n",
    "\n",
    "    return table_df\n",
    "\n",
    "gpu_path = \"../results/InceptionNet/AppliancesEnergy\"\n",
    "# cpu_path = \"../results_cpu/InceptionNet/AppliancesEnergy\"\n",
    "\n",
    "# tab_name = 'imagenette'\n",
    "tab = analyze_results(gpu_path=gpu_path, cpu_path=None, tab_name='timseseries', quality_metric='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e02d2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>rmse</th>\n",
       "      <th>CPU Latency (ms)</th>\n",
       "      <th>GPU Latency (ms)</th>\n",
       "      <th>CPU Throughput (IPS)</th>\n",
       "      <th>GPU Throughput (IPS)</th>\n",
       "      <th>Model Size (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Original</td>\n",
       "      <td>3.441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low-rank_quant-qat_pruning_quant-dynamic</td>\n",
       "      <td>4.577 / +33.0%</td>\n",
       "      <td>∞</td>\n",
       "      <td>4.427 / +44.2%</td>\n",
       "      <td>∞</td>\n",
       "      <td>2 / -32.1%</td>\n",
       "      <td>0.591 / -80.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pruning_quant-qat_low-rank_quant-dynamic</td>\n",
       "      <td>3.841 / +11.6%</td>\n",
       "      <td>∞</td>\n",
       "      <td>3.664 / +22.8%</td>\n",
       "      <td>∞</td>\n",
       "      <td>3 / -16.1%</td>\n",
       "      <td>0.923 / -68.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pruning_quant-qat_low-rank_quant-static</td>\n",
       "      <td>3.845 / +11.7%</td>\n",
       "      <td>∞</td>\n",
       "      <td>3.409 / +3.0%</td>\n",
       "      <td>∞</td>\n",
       "      <td>3 / -11.2%</td>\n",
       "      <td>0.923 / -68.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pruning_quant-static_low-rank_quant-dynamic</td>\n",
       "      <td>3.811 / +10.8%</td>\n",
       "      <td>∞</td>\n",
       "      <td>3.852 / +30.4%</td>\n",
       "      <td>∞</td>\n",
       "      <td>3 / -11.3%</td>\n",
       "      <td>0.923 / -68.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pruning_quant-static_low-rank_quant-qat</td>\n",
       "      <td>3.817 / +10.9%</td>\n",
       "      <td>∞</td>\n",
       "      <td>3.538 / +15.8%</td>\n",
       "      <td>∞</td>\n",
       "      <td>3 / -16.1%</td>\n",
       "      <td>0.923 / -68.8%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Pipeline            rmse  \\\n",
       "0                                     Original           3.441   \n",
       "1     low-rank_quant-qat_pruning_quant-dynamic  4.577 / +33.0%   \n",
       "2     pruning_quant-qat_low-rank_quant-dynamic  3.841 / +11.6%   \n",
       "3      pruning_quant-qat_low-rank_quant-static  3.845 / +11.7%   \n",
       "4  pruning_quant-static_low-rank_quant-dynamic  3.811 / +10.8%   \n",
       "5      pruning_quant-static_low-rank_quant-qat  3.817 / +10.9%   \n",
       "\n",
       "  CPU Latency (ms) GPU Latency (ms) CPU Throughput (IPS) GPU Throughput (IPS)  \\\n",
       "0              NaN            4.345                  NaN                    2   \n",
       "1                ∞   4.427 / +44.2%                    ∞           2 / -32.1%   \n",
       "2                ∞   3.664 / +22.8%                    ∞           3 / -16.1%   \n",
       "3                ∞    3.409 / +3.0%                    ∞           3 / -11.2%   \n",
       "4                ∞   3.852 / +30.4%                    ∞           3 / -11.3%   \n",
       "5                ∞   3.538 / +15.8%                    ∞           3 / -16.1%   \n",
       "\n",
       "  Model Size (MB)  \n",
       "0           0.923  \n",
       "1  0.591 / -80.0%  \n",
       "2  0.923 / -68.8%  \n",
       "3  0.923 / -68.8%  \n",
       "4  0.923 / -68.8%  \n",
       "5  0.923 / -68.8%  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb7207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
