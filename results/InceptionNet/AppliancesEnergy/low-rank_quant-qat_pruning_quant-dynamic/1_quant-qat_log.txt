
>>> PEFT step 2: quant-qat
Creating Dask Server
Generations:   0%|          | 0/10000 [00:00<?, ?gen/s][QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: onednn, device: cuda:0
[INIT] dtype: torch.float16, allow_embedding: False, allow_convolution: False
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})}
[MODEL] Model initialized and copied for quantization.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: criterion, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.add, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.gap, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.gap.gap, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.gap.flatten, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.fc.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.fc.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
[DATA] Example input shape: torch.Size([8, 24, 144])
[PREPARE] Model prepared successfully.
[HOOK] Performing Dynamic PTQ hook operations.
[HOOK] Dynamic PTQ setup completed.
[FIT ERROR] Exception during quantization:
Traceback (most recent call last):
  File "/ptls-experiments/FedCore/fedcore/algorithm/quantization/quantizers.py", line 205, in fit
    self.quant_model = quantize_dynamic(
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 476, in quantize_dynamic
    convert(model, mapping, inplace=True)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 563, in convert
    _convert(
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 604, in _convert
    _convert(mod, mapping, True,  # inplace
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 604, in _convert
    _convert(mod, mapping, True,  # inplace
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 604, in _convert
    _convert(mod, mapping, True,  # inplace
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 607, in _convert
    reassign[name] = swap_module(mod, mapping, custom_module_class_mapping, use_precomputed_fake_quant)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 642, in swap_module
    new_mod = qmod.from_float(mod, use_precomputed_fake_quant=use_precomputed_fake_quant)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py", line 115, in from_float
    qlinear = cls(mod.in_features, mod.out_features, dtype=dtype)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py", line 41, in __init__
    super().__init__(in_features, out_features, bias_, dtype=dtype)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/linear.py", line 152, in __init__
    self._packed_params = LinearPackedParams(dtype)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/linear.py", line 28, in __init__
    self.set_weight_bias(wq, None)  # type: ignore[possibly-undefined]
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/linear.py", line 35, in set_weight_bias
    self._packed_params = torch.ops.quantized.linear_prepack_fp16(weight, bias)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/_ops.py", line 1061, in __call__
    return self_._op(*args, **(kwargs or {}))
RuntimeError: quantized::linear_prepack_fp16 is currently not supported by ONEDNN
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: onednn, device: cuda:0
[INIT] dtype: torch.float16, allow_embedding: False, allow_convolution: False
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: onednn, device: cuda:0
[INIT] dtype: torch.float16, allow_embedding: False, allow_convolution: False
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})}
[MODEL] Model initialized and copied for quantization.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: criterion, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.add, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.gap, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.gap.gap, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.gap.flatten, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.fc.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.fc.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
[DATA] Example input shape: torch.Size([8, 24, 144])
[PREPARE] Model prepared successfully.
[FIT ERROR] Exception during quantization:
Traceback (most recent call last):
  File "/ptls-experiments/FedCore/fedcore/algorithm/quantization/quantizers.py", line 211, in fit
    convert(self.quant_model, inplace=True)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 563, in convert
    _convert(
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 604, in _convert
    _convert(mod, mapping, True,  # inplace
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 604, in _convert
    _convert(mod, mapping, True,  # inplace
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 604, in _convert
    _convert(mod, mapping, True,  # inplace
  [Previous line repeated 2 more times]
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 607, in _convert
    reassign[name] = swap_module(mod, mapping, custom_module_class_mapping, use_precomputed_fake_quant)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 642, in swap_module
    new_mod = qmod.from_float(mod, use_precomputed_fake_quant=use_precomputed_fake_quant)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/conv.py", line 379, in from_float
    return _ConvNd.from_float(cls, mod, use_precomputed_fake_quant=use_precomputed_fake_quant)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/conv.py", line 242, in from_float
    return cls.get_qconv(mod, activation_post_process, weight_post_process)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/conv.py", line 202, in get_qconv
    assert weight_post_process.dtype == torch.qint8, \
AssertionError: Weight observer must have a dtype of qint8
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: onednn, device: cuda:0
[INIT] dtype: torch.float16, allow_embedding: False, allow_convolution: False
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: onednn, device: cuda:0
[INIT] dtype: torch.float16, allow_embedding: False, allow_convolution: False
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})}
[MODEL] Model initialized and copied for quantization.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: criterion, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.add, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.gap, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.gap.gap, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.gap.flatten, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.fc.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.fc.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
[DATA] Example input shape: torch.Size([8, 24, 144])
[PREPARE] Model prepared successfully.
[HOOK] Performing Dynamic PTQ hook operations.
[HOOK] Dynamic PTQ setup completed.
[FIT ERROR] Exception during quantization:
Traceback (most recent call last):
  File "/ptls-experiments/FedCore/fedcore/algorithm/quantization/quantizers.py", line 205, in fit
    self.quant_model = quantize_dynamic(
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 476, in quantize_dynamic
    convert(model, mapping, inplace=True)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 563, in convert
    _convert(
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 604, in _convert
    _convert(mod, mapping, True,  # inplace
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 604, in _convert
    _convert(mod, mapping, True,  # inplace
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 604, in _convert
    _convert(mod, mapping, True,  # inplace
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 607, in _convert
    reassign[name] = swap_module(mod, mapping, custom_module_class_mapping, use_precomputed_fake_quant)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 642, in swap_module
    new_mod = qmod.from_float(mod, use_precomputed_fake_quant=use_precomputed_fake_quant)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py", line 115, in from_float
    qlinear = cls(mod.in_features, mod.out_features, dtype=dtype)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py", line 41, in __init__
    super().__init__(in_features, out_features, bias_, dtype=dtype)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/linear.py", line 152, in __init__
    self._packed_params = LinearPackedParams(dtype)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/linear.py", line 28, in __init__
    self.set_weight_bias(wq, None)  # type: ignore[possibly-undefined]
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/linear.py", line 35, in set_weight_bias
    self._packed_params = torch.ops.quantized.linear_prepack_fp16(weight, bias)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/_ops.py", line 1061, in __call__
    return self_._op(*args, **(kwargs or {}))
RuntimeError: quantized::linear_prepack_fp16 is currently not supported by ONEDNN
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: onednn, device: cuda:0
[INIT] dtype: torch.float16, allow_embedding: False, allow_convolution: False
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: onednn, device: cuda:0
[INIT] dtype: torch.float16, allow_embedding: False, allow_convolution: False
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[MODEL] Model initialized and copied for quantization.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad262f70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad262f70>})
Module: criterion, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b418e9d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b418e9d0>})
Module: model, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad262ee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad262ee0>})
Module: model.inception_block, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad262e50>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad262e50>})
Module: model.inception_block.inception, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f31b0042b80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f31b0042b80>})
Module: model.inception_block.inception.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f31b0042d30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f31b0042d30>})
Module: model.inception_block.inception.0.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f31b0042a60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f31b0042a60>})
Module: model.inception_block.inception.0.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f31b0042700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f31b0042700>})
Module: model.inception_block.inception.0.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f31b0042940>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f31b0042940>})
Module: model.inception_block.inception.0.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f31b0042dc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f31b0042dc0>})
Module: model.inception_block.inception.0.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f31b00428b0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f31b00428b0>})
Module: model.inception_block.inception.0.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f31b00424c0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f31b00424c0>})
Module: model.inception_block.inception.0.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f314a4083a0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f314a4083a0>})
Module: model.inception_block.inception.0.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f314a4088b0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f314a4088b0>})
Module: model.inception_block.inception.0.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f314a408940>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f314a408940>})
Module: model.inception_block.inception.0.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4f280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4f280>})
Module: model.inception_block.inception.0.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4fee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4fee0>})
Module: model.inception_block.inception.0.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4f700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4f700>})
Module: model.inception_block.inception.0.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4fa60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4fa60>})
Module: model.inception_block.inception.0.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4f550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4f550>})
Module: model.inception_block.inception.0.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4f940>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4f940>})
Module: model.inception_block.inception.0.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4fb80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4fb80>})
Module: model.inception_block.inception.0.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4f8b0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4f8b0>})
Module: model.inception_block.inception.0.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4fe50>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4fe50>})
Module: model.inception_block.inception.0.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4fca0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4fca0>})
Module: model.inception_block.inception.0.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4fdc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4fdc0>})
Module: model.inception_block.inception.0.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4f310>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4f310>})
Module: model.inception_block.inception.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4f5e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4f5e0>})
Module: model.inception_block.inception.1.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4f0d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4f0d0>})
Module: model.inception_block.inception.1.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4ff70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b4ff70>})
Module: model.inception_block.inception.1.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b414e670>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b414e670>})
Module: model.inception_block.inception.1.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b414eca0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b414eca0>})
Module: model.inception_block.inception.1.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b414e5e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b414e5e0>})
Module: model.inception_block.inception.1.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b414ea60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b414ea60>})
Module: model.inception_block.inception.1.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b414e3a0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b414e3a0>})
Module: model.inception_block.inception.1.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b414e430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b414e430>})
Module: model.inception_block.inception.1.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b414e820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b414e820>})
Module: model.inception_block.inception.1.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b3e64820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b3e64820>})
Module: model.inception_block.inception.1.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b3e641f0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b3e641f0>})
Module: model.inception_block.inception.1.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b3e64700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b3e64700>})
Module: model.inception_block.inception.1.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b3e64790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b3e64790>})
Module: model.inception_block.inception.1.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b3e64af0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b3e64af0>})
Module: model.inception_block.inception.1.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3148b8c310>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3148b8c310>})
Module: model.inception_block.inception.1.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3148b8c550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3148b8c550>})
Module: model.inception_block.inception.1.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3148b8c700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3148b8c700>})
Module: model.inception_block.inception.1.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3148b8cd30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3148b8cd30>})
Module: model.inception_block.inception.1.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3148b8c430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3148b8c430>})
Module: model.inception_block.inception.1.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3148b8c670>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3148b8c670>})
Module: model.inception_block.inception.1.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3148b8caf0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3148b8caf0>})
Module: model.inception_block.inception.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3148b8c0d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3148b8c0d0>})
Module: model.inception_block.inception.2.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3149d52550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3149d52550>})
Module: model.inception_block.inception.2.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3149d523a0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3149d523a0>})
Module: model.inception_block.inception.2.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f2f5a618dc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f2f5a618dc0>})
Module: model.inception_block.inception.2.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3149d52a60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3149d52a60>})
Module: model.inception_block.inception.2.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3149d52b80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3149d52b80>})
Module: model.inception_block.inception.2.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3149d52430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3149d52430>})
Module: model.inception_block.inception.2.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3149d52dc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f3149d52dc0>})
Module: model.inception_block.inception.2.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b87550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b87550>})
Module: model.inception_block.inception.2.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b875e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b875e0>})
Module: model.inception_block.inception.2.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b870d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1b870d0>})
Module: model.inception_block.inception.2.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1c00310>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1c00310>})
Module: model.inception_block.inception.2.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1c009d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1c009d0>})
Module: model.inception_block.inception.2.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1c00040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1c00040>})
Module: model.inception_block.inception.2.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1c00790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1c00790>})
Module: model.inception_block.inception.2.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1c00550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1c00550>})
Module: model.inception_block.inception.2.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1c00dc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1c00dc0>})
Module: model.inception_block.inception.2.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1c005e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1c005e0>})
Module: model.inception_block.inception.2.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1c003a0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1c003a0>})
Module: model.inception_block.inception.2.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1c00430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1c00430>})
Module: model.inception_block.inception.2.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa25e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa25e0>})
Module: model.inception_block.inception.2.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa24c0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa24c0>})
Module: model.inception_block.inception.3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2af0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2af0>})
Module: model.inception_block.inception.3.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2550>})
Module: model.inception_block.inception.3.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa21f0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa21f0>})
Module: model.inception_block.inception.3.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2670>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2670>})
Module: model.inception_block.inception.3.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2dc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2dc0>})
Module: model.inception_block.inception.3.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2040>})
Module: model.inception_block.inception.3.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2ee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2ee0>})
Module: model.inception_block.inception.3.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2820>})
Module: model.inception_block.inception.3.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2940>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2940>})
Module: model.inception_block.inception.3.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa20d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa20d0>})
Module: model.inception_block.inception.3.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2160>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2160>})
Module: model.inception_block.inception.3.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2b80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2b80>})
Module: model.inception_block.inception.3.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2ca0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2ca0>})
Module: model.inception_block.inception.3.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2f70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2f70>})
Module: model.inception_block.inception.3.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2d30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2d30>})
Module: model.inception_block.inception.3.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa29d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa29d0>})
Module: model.inception_block.inception.3.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2790>})
Module: model.inception_block.inception.3.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2310>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2310>})
Module: model.inception_block.inception.3.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2e50>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2e50>})
Module: model.inception_block.inception.3.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2700>})
Module: model.inception_block.inception.3.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1bb7280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1bb7280>})
Module: model.inception_block.inception.3.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2430>})
Module: model.inception_block.inception.4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa23a0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa23a0>})
Module: model.inception_block.inception.4.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2a60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2a60>})
Module: model.inception_block.inception.4.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2c10>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2c10>})
Module: model.inception_block.inception.4.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1aa2280>})
Module: model.inception_block.inception.4.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1bb7550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1bb7550>})
Module: model.inception_block.inception.4.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1bb7940>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1bb7940>})
Module: model.inception_block.inception.4.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1bb7430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1bb7430>})
Module: model.inception_block.inception.4.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b4033550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b4033550>})
Module: model.inception_block.inception.4.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b4033790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b4033790>})
Module: model.inception_block.inception.4.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b40334c0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b40334c0>})
Module: model.inception_block.inception.4.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b4033280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b4033280>})
Module: model.inception_block.inception.4.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b4033a60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b4033a60>})
Module: model.inception_block.inception.4.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b4033af0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b4033af0>})
Module: model.inception_block.inception.4.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b18431f0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b18431f0>})
Module: model.inception_block.inception.4.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1843af0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1843af0>})
Module: model.inception_block.inception.4.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1843c10>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1843c10>})
Module: model.inception_block.inception.4.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1843b80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1843b80>})
Module: model.inception_block.inception.4.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1843280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1843280>})
Module: model.inception_block.inception.4.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1843ca0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b1843ca0>})
Module: model.inception_block.inception.4.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17de430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17de430>})
Module: model.inception_block.inception.4.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17de4c0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17de4c0>})
Module: model.inception_block.inception.4.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17de550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17de550>})
Module: model.inception_block.inception.5, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17de5e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17de5e0>})
Module: model.inception_block.inception.5.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17de670>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17de670>})
Module: model.inception_block.inception.5.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17de8b0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17de8b0>})
Module: model.inception_block.inception.5.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17dea60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17dea60>})
Module: model.inception_block.inception.5.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17de700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17de700>})
Module: model.inception_block.inception.5.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17de790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17de790>})
Module: model.inception_block.inception.5.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17de820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17de820>})
Module: model.inception_block.inception.5.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17deaf0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17deaf0>})
Module: model.inception_block.inception.5.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17deb80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17deb80>})
Module: model.inception_block.inception.5.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad50e310>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad50e310>})
Module: model.inception_block.inception.5.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17def70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17def70>})
Module: model.inception_block.inception.5.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad50e0d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad50e0d0>})
Module: model.inception_block.inception.5.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad50e040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad50e040>})
Module: model.inception_block.inception.5.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad50e160>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad50e160>})
Module: model.inception_block.inception.5.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad50e280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad50e280>})
Module: model.inception_block.inception.5.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525430>})
Module: model.inception_block.inception.5.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad5258b0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad5258b0>})
Module: model.inception_block.inception.5.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525820>})
Module: model.inception_block.inception.5.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525790>})
Module: model.inception_block.inception.5.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525a60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525a60>})
Module: model.inception_block.inception.5.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525550>})
Module: model.inception_block.inception.5.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad5259d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad5259d0>})
Module: model.inception_block.inception.6, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525310>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525310>})
Module: model.inception_block.inception.6.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525280>})
Module: model.inception_block.inception.6.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525c10>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525c10>})
Module: model.inception_block.inception.6.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525ca0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525ca0>})
Module: model.inception_block.inception.6.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525d30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525d30>})
Module: model.inception_block.inception.6.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525dc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525dc0>})
Module: model.inception_block.inception.6.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525e50>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525e50>})
Module: model.inception_block.inception.6.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525ee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525ee0>})
Module: model.inception_block.inception.6.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525f70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525f70>})
Module: model.inception_block.inception.6.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e430>})
Module: model.inception_block.inception.6.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e5e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e5e0>})
Module: model.inception_block.inception.6.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad5254c0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad5254c0>})
Module: model.inception_block.inception.6.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad5253a0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad5253a0>})
Module: model.inception_block.inception.6.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525700>})
Module: model.inception_block.inception.6.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525670>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525670>})
Module: model.inception_block.inception.6.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad5255e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad5255e0>})
Module: model.inception_block.inception.6.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525940>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad525940>})
Module: model.inception_block.inception.6.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e9d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e9d0>})
Module: model.inception_block.inception.6.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e8b0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e8b0>})
Module: model.inception_block.inception.6.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e820>})
Module: model.inception_block.inception.6.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e790>})
Module: model.inception_block.inception.6.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e670>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e670>})
Module: model.inception_block.inception.7, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25edc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25edc0>})
Module: model.inception_block.inception.7.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25eee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25eee0>})
Module: model.inception_block.inception.7.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25ee50>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25ee50>})
Module: model.inception_block.inception.7.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e4c0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e4c0>})
Module: model.inception_block.inception.7.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26a820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26a820>})
Module: model.inception_block.inception.7.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26a670>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26a670>})
Module: model.inception_block.inception.7.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26a9d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26a9d0>})
Module: model.inception_block.inception.7.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26aa60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26aa60>})
Module: model.inception_block.inception.7.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26ad30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26ad30>})
Module: model.inception_block.inception.7.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26adc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26adc0>})
Module: model.inception_block.inception.7.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26ae50>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26ae50>})
Module: model.inception_block.inception.7.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26aee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26aee0>})
Module: model.inception_block.inception.7.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26af70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26af70>})
Module: model.inception_block.inception.7.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad274670>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad274670>})
Module: model.inception_block.inception.7.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad274160>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad274160>})
Module: model.inception_block.inception.7.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad2740d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad2740d0>})
Module: model.inception_block.inception.7.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad2741f0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad2741f0>})
Module: model.inception_block.inception.7.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad274280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad274280>})
Module: model.inception_block.inception.7.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad274310>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad274310>})
Module: model.inception_block.inception.7.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad274dc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad274dc0>})
Module: model.inception_block.inception.7.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad274430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad274430>})
Module: model.inception_block.inception.7.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad274700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad274700>})
Module: model.inception_block.inception.8, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad2743a0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad2743a0>})
Module: model.inception_block.inception.8.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217af0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217af0>})
Module: model.inception_block.inception.8.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217a60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217a60>})
Module: model.inception_block.inception.8.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad2174c0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad2174c0>})
Module: model.inception_block.inception.8.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217550>})
Module: model.inception_block.inception.8.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad2175e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad2175e0>})
Module: model.inception_block.inception.8.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26a940>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26a940>})
Module: model.inception_block.inception.8.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26a700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26a700>})
Module: model.inception_block.inception.8.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26aca0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26aca0>})
Module: model.inception_block.inception.8.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217820>})
Module: model.inception_block.inception.8.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217790>})
Module: model.inception_block.inception.8.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217c10>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217c10>})
Module: model.inception_block.inception.8.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad2178b0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad2178b0>})
Module: model.inception_block.inception.8.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217ee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217ee0>})
Module: model.inception_block.inception.8.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217f70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217f70>})
Module: model.inception_block.inception.8.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51040>})
Module: model.inception_block.inception.8.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25ed30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25ed30>})
Module: model.inception_block.inception.8.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25eca0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25eca0>})
Module: model.inception_block.inception.8.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25eaf0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25eaf0>})
Module: model.inception_block.inception.8.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25ea60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25ea60>})
Module: model.inception_block.inception.8.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25ef70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25ef70>})
Module: model.inception_block.inception.8.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e700>})
Module: model.inception_block.inception.9, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26a4c0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26a4c0>})
Module: model.inception_block.inception.9.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25ec10>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25ec10>})
Module: model.inception_block.inception.9.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25eb80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25eb80>})
Module: model.inception_block.inception.9.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26a550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26a550>})
Module: model.inception_block.inception.9.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26a5e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad26a5e0>})
Module: model.inception_block.inception.9.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17deca0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17deca0>})
Module: model.inception_block.inception.9.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217b80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217b80>})
Module: model.inception_block.inception.9.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217700>})
Module: model.inception_block.inception.9.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217ca0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217ca0>})
Module: model.inception_block.inception.9.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217d30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217d30>})
Module: model.inception_block.inception.9.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217dc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217dc0>})
Module: model.inception_block.inception.9.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217e50>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217e50>})
Module: model.inception_block.inception.9.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17dedc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33b17dedc0>})
Module: model.inception_block.inception.9.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51790>})
Module: model.inception_block.inception.9.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51700>})
Module: model.inception_block.inception.9.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf519d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf519d0>})
Module: model.inception_block.inception.9.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf514c0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf514c0>})
Module: model.inception_block.inception.9.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51820>})
Module: model.inception_block.inception.9.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51af0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51af0>})
Module: model.inception_block.inception.9.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51a60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51a60>})
Module: model.inception_block.inception.9.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51dc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51dc0>})
Module: model.inception_block.inception.9.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51e50>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51e50>})
Module: model.inception_block.shortcut, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51ee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51ee0>})
Module: model.inception_block.shortcut.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51f70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51f70>})
Module: model.inception_block.shortcut.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf54040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf54040>})
Module: model.inception_block.shortcut.0.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e940>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad25e940>})
Module: model.inception_block.shortcut.0.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf54280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf54280>})
Module: model.inception_block.shortcut.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf54310>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf54310>})
Module: model.inception_block.shortcut.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf543a0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf543a0>})
Module: model.inception_block.shortcut.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf541f0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf541f0>})
Module: model.inception_block.shortcut.1.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf540d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf540d0>})
Module: model.inception_block.shortcut.1.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf54160>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf54160>})
Module: model.inception_block.shortcut.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf54430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf54430>})
Module: model.inception_block.shortcut.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf544c0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf544c0>})
Module: model.inception_block.shortcut.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf54940>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf54940>})
Module: model.inception_block.shortcut.2.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf548b0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf548b0>})
Module: model.inception_block.shortcut.2.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf54820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf54820>})
Module: model.inception_block.shortcut.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf54790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf54790>})
Module: model.inception_block.add, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf54670>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf54670>})
Module: model.inception_block.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51940>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51940>})
Module: model.gap, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf518b0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf518b0>})
Module: model.gap.gap, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51b80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51b80>})
Module: model.gap.flatten, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51c10>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51c10>})
Module: model.fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51ca0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51ca0>})
Module: model.fc.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51d30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33acf51d30>})
Module: model.fc.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f33ad217430>})
[DATA] Example input shape: torch.Size([8, 24, 144])
[PREPARE] Model prepared successfully.
[HOOK] Performing QAT training hook.
[HOOK] QAT epoch 1/1 started.
Generations:   0%|          | 0/10000 [00:12<?, ?gen/s]
