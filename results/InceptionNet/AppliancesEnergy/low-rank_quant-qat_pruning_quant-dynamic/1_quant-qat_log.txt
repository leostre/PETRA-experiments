
>>> PEFT step 2: quant-qat
Creating Dask Server
Generations:   0%|          | 0/10000 [00:00<?, ?gen/s][QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: onednn, device: cuda:0
[INIT] dtype: torch.float16, allow_embedding: False, allow_convolution: False
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})}
[MODEL] Model initialized and copied for quantization.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: criterion, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.add, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.gap, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.gap.gap, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.gap.flatten, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.fc.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.fc.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
[DATA] Example input shape: torch.Size([8, 24, 144])
[PREPARE] Model prepared successfully.
[HOOK] Performing Dynamic PTQ hook operations.
[HOOK] Dynamic PTQ setup completed.
[FIT ERROR] Exception during quantization:
Traceback (most recent call last):
  File "/ptls-experiments/FedCore/fedcore/algorithm/quantization/quantizers.py", line 205, in fit
    self.quant_model = quantize_dynamic(
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 476, in quantize_dynamic
    convert(model, mapping, inplace=True)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 563, in convert
    _convert(
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 604, in _convert
    _convert(mod, mapping, True,  # inplace
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 604, in _convert
    _convert(mod, mapping, True,  # inplace
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 604, in _convert
    _convert(mod, mapping, True,  # inplace
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 607, in _convert
    reassign[name] = swap_module(mod, mapping, custom_module_class_mapping, use_precomputed_fake_quant)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 642, in swap_module
    new_mod = qmod.from_float(mod, use_precomputed_fake_quant=use_precomputed_fake_quant)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py", line 115, in from_float
    qlinear = cls(mod.in_features, mod.out_features, dtype=dtype)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py", line 41, in __init__
    super().__init__(in_features, out_features, bias_, dtype=dtype)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/linear.py", line 152, in __init__
    self._packed_params = LinearPackedParams(dtype)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/linear.py", line 28, in __init__
    self.set_weight_bias(wq, None)  # type: ignore[possibly-undefined]
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/linear.py", line 35, in set_weight_bias
    self._packed_params = torch.ops.quantized.linear_prepack_fp16(weight, bias)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/_ops.py", line 1061, in __call__
    return self_._op(*args, **(kwargs or {}))
RuntimeError: quantized::linear_prepack_fp16 is currently not supported by ONEDNN
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: onednn, device: cuda:0
[INIT] dtype: torch.float16, allow_embedding: False, allow_convolution: False
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: onednn, device: cuda:0
[INIT] dtype: torch.float16, allow_embedding: False, allow_convolution: False
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})}
[MODEL] Model initialized and copied for quantization.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: criterion, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.add, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.gap, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.gap.gap, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.gap.flatten, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.fc.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.fc.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
[DATA] Example input shape: torch.Size([8, 24, 144])
[PREPARE] Model prepared successfully.
[FIT ERROR] Exception during quantization:
Traceback (most recent call last):
  File "/ptls-experiments/FedCore/fedcore/algorithm/quantization/quantizers.py", line 211, in fit
    convert(self.quant_model, inplace=True)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 563, in convert
    _convert(
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 604, in _convert
    _convert(mod, mapping, True,  # inplace
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 604, in _convert
    _convert(mod, mapping, True,  # inplace
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 604, in _convert
    _convert(mod, mapping, True,  # inplace
  [Previous line repeated 2 more times]
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 607, in _convert
    reassign[name] = swap_module(mod, mapping, custom_module_class_mapping, use_precomputed_fake_quant)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 642, in swap_module
    new_mod = qmod.from_float(mod, use_precomputed_fake_quant=use_precomputed_fake_quant)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/conv.py", line 379, in from_float
    return _ConvNd.from_float(cls, mod, use_precomputed_fake_quant=use_precomputed_fake_quant)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/conv.py", line 242, in from_float
    return cls.get_qconv(mod, activation_post_process, weight_post_process)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/conv.py", line 202, in get_qconv
    assert weight_post_process.dtype == torch.qint8, \
AssertionError: Weight observer must have a dtype of qint8
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: static, backend: onednn, device: cuda:0
[INIT] dtype: torch.float16, allow_embedding: False, allow_convolution: False
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: onednn, device: cuda:0
[INIT] dtype: torch.float16, allow_embedding: False, allow_convolution: False
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})}
[MODEL] Model initialized and copied for quantization.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: criterion, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.0.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.1.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.2.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.3.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.4.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.5.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.6.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.7.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.8.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.inception.9.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.shortcut.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.add, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.inception_block.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.gap, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.gap.gap, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.gap.flatten, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.fc.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
Module: model.fc.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
[DATA] Example input shape: torch.Size([8, 24, 144])
[PREPARE] Model prepared successfully.
[HOOK] Performing Dynamic PTQ hook operations.
[HOOK] Dynamic PTQ setup completed.
[FIT ERROR] Exception during quantization:
Traceback (most recent call last):
  File "/ptls-experiments/FedCore/fedcore/algorithm/quantization/quantizers.py", line 205, in fit
    self.quant_model = quantize_dynamic(
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 476, in quantize_dynamic
    convert(model, mapping, inplace=True)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 563, in convert
    _convert(
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 604, in _convert
    _convert(mod, mapping, True,  # inplace
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 604, in _convert
    _convert(mod, mapping, True,  # inplace
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 604, in _convert
    _convert(mod, mapping, True,  # inplace
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 607, in _convert
    reassign[name] = swap_module(mod, mapping, custom_module_class_mapping, use_precomputed_fake_quant)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/quantization/quantize.py", line 642, in swap_module
    new_mod = qmod.from_float(mod, use_precomputed_fake_quant=use_precomputed_fake_quant)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py", line 115, in from_float
    qlinear = cls(mod.in_features, mod.out_features, dtype=dtype)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py", line 41, in __init__
    super().__init__(in_features, out_features, bias_, dtype=dtype)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/linear.py", line 152, in __init__
    self._packed_params = LinearPackedParams(dtype)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/linear.py", line 28, in __init__
    self.set_weight_bias(wq, None)  # type: ignore[possibly-undefined]
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/linear.py", line 35, in set_weight_bias
    self._packed_params = torch.ops.quantized.linear_prepack_fp16(weight, bias)
  File "/root/.local/share/virtualenvs/ptls-experiments-H-SwwRmK/lib/python3.8/site-packages/torch/_ops.py", line 1061, in __call__
    return self_._op(*args, **(kwargs or {}))
RuntimeError: quantized::linear_prepack_fp16 is currently not supported by ONEDNN
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: dynamic, backend: onednn, device: cuda:0
[INIT] dtype: torch.float16, allow_embedding: False, allow_convolution: False
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.float16){})}
[QCONFIG] Created qconfig mapping: QConfigMapping (
 global_qconfig
  QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})
 object_type_qconfigs
  OrderedDict()
 module_name_regex_qconfigs
  OrderedDict()
 module_name_qconfigs
  OrderedDict()
 module_name_object_type_order_qconfigs
  OrderedDict()
)
[INIT] quant_type: qat, backend: onednn, device: cuda:0
[INIT] dtype: torch.float16, allow_embedding: False, allow_convolution: False
[INIT] qconfig: {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}
[MODEL] Model initialized and copied for quantization.
Module: , qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28427cf70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28427cf70>})
Module: criterion, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28427c3a0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28427c3a0>})
Module: model, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28421fdc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28421fdc0>})
Module: model.inception_block, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c08b700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c08b700>})
Module: model.inception_block.inception, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c6de550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c6de550>})
Module: model.inception_block.inception.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284283dc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284283dc0>})
Module: model.inception_block.inception.0.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2945eb280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2945eb280>})
Module: model.inception_block.inception.0.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28421caf0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28421caf0>})
Module: model.inception_block.inception.0.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c69fc10>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c69fc10>})
Module: model.inception_block.inception.0.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c744790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c744790>})
Module: model.inception_block.inception.0.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2844745e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2844745e0>})
Module: model.inception_block.inception.0.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c395f70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c395f70>})
Module: model.inception_block.inception.0.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c395e50>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c395e50>})
Module: model.inception_block.inception.0.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c395550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c395550>})
Module: model.inception_block.inception.0.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499700>})
Module: model.inception_block.inception.0.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499040>})
Module: model.inception_block.inception.0.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499ee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499ee0>})
Module: model.inception_block.inception.0.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4994c0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4994c0>})
Module: model.inception_block.inception.0.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c487d30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c487d30>})
Module: model.inception_block.inception.0.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c487670>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c487670>})
Module: model.inception_block.inception.0.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499940>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499940>})
Module: model.inception_block.inception.0.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499b80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499b80>})
Module: model.inception_block.inception.0.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284283f70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284283f70>})
Module: model.inception_block.inception.0.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284283820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284283820>})
Module: model.inception_block.inception.0.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c395160>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c395160>})
Module: model.inception_block.inception.0.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c3955e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c3955e0>})
Module: model.inception_block.inception.0.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c395ee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c395ee0>})
Module: model.inception_block.inception.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28421f430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28421f430>})
Module: model.inception_block.inception.1.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499c10>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499c10>})
Module: model.inception_block.inception.1.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c088040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c088040>})
Module: model.inception_block.inception.1.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2a427aaf0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2a427aaf0>})
Module: model.inception_block.inception.1.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29454ef70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29454ef70>})
Module: model.inception_block.inception.1.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c487790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c487790>})
Module: model.inception_block.inception.1.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499280>})
Module: model.inception_block.inception.1.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4998b0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4998b0>})
Module: model.inception_block.inception.1.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c7393a0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c7393a0>})
Module: model.inception_block.inception.1.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2841a84c0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2841a84c0>})
Module: model.inception_block.inception.1.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c07f160>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c07f160>})
Module: model.inception_block.inception.1.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c614670>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c614670>})
Module: model.inception_block.inception.1.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2841a8280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2841a8280>})
Module: model.inception_block.inception.1.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c131a60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c131a60>})
Module: model.inception_block.inception.1.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c10e820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c10e820>})
Module: model.inception_block.inception.1.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c10eee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c10eee0>})
Module: model.inception_block.inception.1.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28440f820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28440f820>})
Module: model.inception_block.inception.1.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c131f70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c131f70>})
Module: model.inception_block.inception.1.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2943ea700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2943ea700>})
Module: model.inception_block.inception.1.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c367d30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c367d30>})
Module: model.inception_block.inception.1.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284220ca0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284220ca0>})
Module: model.inception_block.inception.1.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c7b9ca0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c7b9ca0>})
Module: model.inception_block.inception.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103ca0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103ca0>})
Module: model.inception_block.inception.2.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284474310>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284474310>})
Module: model.inception_block.inception.2.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28421fe50>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28421fe50>})
Module: model.inception_block.inception.2.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc294229a60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc294229a60>})
Module: model.inception_block.inception.2.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c69f280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c69f280>})
Module: model.inception_block.inception.2.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a65e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a65e0>})
Module: model.inception_block.inception.2.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7c8430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7c8430>})
Module: model.inception_block.inception.2.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2941648b0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2941648b0>})
Module: model.inception_block.inception.2.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a63a0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a63a0>})
Module: model.inception_block.inception.2.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a6d30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a6d30>})
Module: model.inception_block.inception.2.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a6af0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a6af0>})
Module: model.inception_block.inception.2.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bba60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bba60>})
Module: model.inception_block.inception.2.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bbaf0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bbaf0>})
Module: model.inception_block.inception.2.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb940>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb940>})
Module: model.inception_block.inception.2.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb820>})
Module: model.inception_block.inception.2.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb5e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb5e0>})
Module: model.inception_block.inception.2.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb700>})
Module: model.inception_block.inception.2.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb790>})
Module: model.inception_block.inception.2.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a6a60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a6a60>})
Module: model.inception_block.inception.2.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103280>})
Module: model.inception_block.inception.2.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103040>})
Module: model.inception_block.inception.2.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103c10>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103c10>})
Module: model.inception_block.inception.3, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c1033a0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c1033a0>})
Module: model.inception_block.inception.3.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103550>})
Module: model.inception_block.inception.3.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2841a8ee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2841a8ee0>})
Module: model.inception_block.inception.3.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c395430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c395430>})
Module: model.inception_block.inception.3.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c606e50>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c606e50>})
Module: model.inception_block.inception.3.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c606160>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c606160>})
Module: model.inception_block.inception.3.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2841a8790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2841a8790>})
Module: model.inception_block.inception.3.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499160>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499160>})
Module: model.inception_block.inception.3.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499e50>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499e50>})
Module: model.inception_block.inception.3.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2946e1160>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2946e1160>})
Module: model.inception_block.inception.3.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284474dc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284474dc0>})
Module: model.inception_block.inception.3.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a6f70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a6f70>})
Module: model.inception_block.inception.3.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c131d30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c131d30>})
Module: model.inception_block.inception.3.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb160>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb160>})
Module: model.inception_block.inception.3.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c1314c0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c1314c0>})
Module: model.inception_block.inception.3.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1f70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1f70>})
Module: model.inception_block.inception.3.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6d30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6d30>})
Module: model.inception_block.inception.3.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6f70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6f70>})
Module: model.inception_block.inception.3.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28421f550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28421f550>})
Module: model.inception_block.inception.3.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1430>})
Module: model.inception_block.inception.3.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a6dc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a6dc0>})
Module: model.inception_block.inception.3.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354550>})
Module: model.inception_block.inception.4, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284304af0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284304af0>})
Module: model.inception_block.inception.4.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284304280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284304280>})
Module: model.inception_block.inception.4.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c1034c0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c1034c0>})
Module: model.inception_block.inception.4.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7dfb80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7dfb80>})
Module: model.inception_block.inception.4.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7dfd30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7dfd30>})
Module: model.inception_block.inception.4.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7df0d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7df0d0>})
Module: model.inception_block.inception.4.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c36bd30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c36bd30>})
Module: model.inception_block.inception.4.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c36bb80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c36bb80>})
Module: model.inception_block.inception.4.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1d30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1d30>})
Module: model.inception_block.inception.4.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7dfc10>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7dfc10>})
Module: model.inception_block.inception.4.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6af0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6af0>})
Module: model.inception_block.inception.4.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c0b3430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c0b3430>})
Module: model.inception_block.inception.4.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a6b80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a6b80>})
Module: model.inception_block.inception.4.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a6e50>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a6e50>})
Module: model.inception_block.inception.4.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c6065e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c6065e0>})
Module: model.inception_block.inception.4.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4991f0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4991f0>})
Module: model.inception_block.inception.4.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499550>})
Module: model.inception_block.inception.4.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2843040d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2843040d0>})
Module: model.inception_block.inception.4.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7df700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7df700>})
Module: model.inception_block.inception.4.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28421ca60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28421ca60>})
Module: model.inception_block.inception.4.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284474040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284474040>})
Module: model.inception_block.inception.4.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c1035e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c1035e0>})
Module: model.inception_block.inception.5, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499790>})
Module: model.inception_block.inception.5.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c6068b0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c6068b0>})
Module: model.inception_block.inception.5.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c606040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c606040>})
Module: model.inception_block.inception.5.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28450c820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28450c820>})
Module: model.inception_block.inception.5.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c581670>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c581670>})
Module: model.inception_block.inception.5.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c606f70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c606f70>})
Module: model.inception_block.inception.5.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c606550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c606550>})
Module: model.inception_block.inception.5.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2945bb790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2945bb790>})
Module: model.inception_block.inception.5.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2944810d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2944810d0>})
Module: model.inception_block.inception.5.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c0765e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c0765e0>})
Module: model.inception_block.inception.5.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284304430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284304430>})
Module: model.inception_block.inception.5.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c131b80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c131b80>})
Module: model.inception_block.inception.5.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb8b0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb8b0>})
Module: model.inception_block.inception.5.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb9d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb9d0>})
Module: model.inception_block.inception.5.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a6820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a6820>})
Module: model.inception_block.inception.5.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c1039d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c1039d0>})
Module: model.inception_block.inception.5.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284220310>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284220310>})
Module: model.inception_block.inception.5.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1940>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1940>})
Module: model.inception_block.inception.5.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6a60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6a60>})
Module: model.inception_block.inception.5.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1ca0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1ca0>})
Module: model.inception_block.inception.5.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c3544c0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c3544c0>})
Module: model.inception_block.inception.5.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354820>})
Module: model.inception_block.inception.6, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c3548b0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c3548b0>})
Module: model.inception_block.inception.6.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c3540d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c3540d0>})
Module: model.inception_block.inception.6.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354700>})
Module: model.inception_block.inception.6.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c3545e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c3545e0>})
Module: model.inception_block.inception.6.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2841a8ca0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2841a8ca0>})
Module: model.inception_block.inception.6.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1af0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1af0>})
Module: model.inception_block.inception.6.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1820>})
Module: model.inception_block.inception.6.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c14c0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c14c0>})
Module: model.inception_block.inception.6.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1e50>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1e50>})
Module: model.inception_block.inception.6.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1280>})
Module: model.inception_block.inception.6.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c10d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c10d0>})
Module: model.inception_block.inception.6.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c15e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c15e0>})
Module: model.inception_block.inception.6.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354ca0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354ca0>})
Module: model.inception_block.inception.6.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c11f0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c11f0>})
Module: model.inception_block.inception.6.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1310>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1310>})
Module: model.inception_block.inception.6.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354af0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354af0>})
Module: model.inception_block.inception.6.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354790>})
Module: model.inception_block.inception.6.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354160>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354160>})
Module: model.inception_block.inception.6.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354280>})
Module: model.inception_block.inception.6.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354ee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354ee0>})
Module: model.inception_block.inception.6.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35d3a0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35d3a0>})
Module: model.inception_block.inception.6.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2841a81f0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2841a81f0>})
Module: model.inception_block.inception.7, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499670>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499670>})
Module: model.inception_block.inception.7.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4995e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4995e0>})
Module: model.inception_block.inception.7.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1040>})
Module: model.inception_block.inception.7.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb040>})
Module: model.inception_block.inception.7.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2841a8040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2841a8040>})
Module: model.inception_block.inception.7.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284220820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284220820>})
Module: model.inception_block.inception.7.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6820>})
Module: model.inception_block.inception.7.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7b99d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7b99d0>})
Module: model.inception_block.inception.7.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7b9040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7b9040>})
Module: model.inception_block.inception.7.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d60d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d60d0>})
Module: model.inception_block.inception.7.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7b9820>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7b9820>})
Module: model.inception_block.inception.7.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28450c550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28450c550>})
Module: model.inception_block.inception.7.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb310>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb310>})
Module: model.inception_block.inception.7.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284220040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc284220040>})
Module: model.inception_block.inception.7.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6c10>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6c10>})
Module: model.inception_block.inception.7.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6040>})
Module: model.inception_block.inception.7.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb550>})
Module: model.inception_block.inception.7.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29447dee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29447dee0>})
Module: model.inception_block.inception.7.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc3146b0f70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc3146b0f70>})
Module: model.inception_block.inception.7.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6dc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6dc0>})
Module: model.inception_block.inception.7.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7e1310>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7e1310>})
Module: model.inception_block.inception.7.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7e1b80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7e1b80>})
Module: model.inception_block.inception.8, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7e1c10>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7e1c10>})
Module: model.inception_block.inception.8.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35d430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35d430>})
Module: model.inception_block.inception.8.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35dd30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35dd30>})
Module: model.inception_block.inception.8.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35dee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35dee0>})
Module: model.inception_block.inception.8.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35de50>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35de50>})
Module: model.inception_block.inception.8.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c3673a0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c3673a0>})
Module: model.inception_block.inception.8.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35d8b0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35d8b0>})
Module: model.inception_block.inception.8.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c3670d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c3670d0>})
Module: model.inception_block.inception.8.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c367430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c367430>})
Module: model.inception_block.inception.8.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c367790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c367790>})
Module: model.inception_block.inception.8.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c367700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c367700>})
Module: model.inception_block.inception.8.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7e1160>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7e1160>})
Module: model.inception_block.inception.8.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7e1700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7e1700>})
Module: model.inception_block.inception.8.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35d940>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35d940>})
Module: model.inception_block.inception.8.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35d9d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35d9d0>})
Module: model.inception_block.inception.8.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c367dc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c367dc0>})
Module: model.inception_block.inception.8.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c367280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c367280>})
Module: model.inception_block.inception.8.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a64c0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a64c0>})
Module: model.inception_block.inception.8.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c3543a0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c3543a0>})
Module: model.inception_block.inception.8.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354430>})
Module: model.inception_block.inception.8.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1550>})
Module: model.inception_block.inception.8.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1c10>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1c10>})
Module: model.inception_block.inception.9, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c36b1f0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c36b1f0>})
Module: model.inception_block.inception.9.bottleneck, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c447040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c447040>})
Module: model.inception_block.inception.9.bottleneck.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c447160>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c447160>})
Module: model.inception_block.inception.9.bottleneck.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c4471f0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c4471f0>})
Module: model.inception_block.inception.9.convs, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1670>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1670>})
Module: model.inception_block.inception.9.convs.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1700>})
Module: model.inception_block.inception.9.convs.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c367550>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c367550>})
Module: model.inception_block.inception.9.convs.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354940>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c354940>})
Module: model.inception_block.inception.9.convs.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c36b700>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c36b700>})
Module: model.inception_block.inception.9.convs.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c36b9d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c36b9d0>})
Module: model.inception_block.inception.9.convs.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c36bd30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c36bd30>})
Module: model.inception_block.inception.9.convs.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103310>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103310>})
Module: model.inception_block.inception.9.convs.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499dc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c499dc0>})
Module: model.inception_block.inception.9.convs.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2841a8f70>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc2841a8f70>})
Module: model.inception_block.inception.9.maxconvpool, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7e18b0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c7e18b0>})
Module: model.inception_block.inception.9.maxconvpool.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb670>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb670>})
Module: model.inception_block.inception.9.maxconvpool.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c36ba60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c36ba60>})
Module: model.inception_block.inception.9.maxconvpool.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7b9280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7b9280>})
Module: model.inception_block.inception.9.maxconvpool.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c085940>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc29c085940>})
Module: model.inception_block.inception.9.concat, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb1f0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7bb1f0>})
Module: model.inception_block.inception.9.batch_norm, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c69f310>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c69f310>})
Module: model.inception_block.inception.9.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35ddc0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35ddc0>})
Module: model.inception_block.shortcut, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c36b040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c36b040>})
Module: model.inception_block.shortcut.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35d040>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c35d040>})
Module: model.inception_block.shortcut.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a6ee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a6ee0>})
Module: model.inception_block.shortcut.0.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c367160>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c367160>})
Module: model.inception_block.shortcut.0.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6ee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6ee0>})
Module: model.inception_block.shortcut.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c18b0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c18b0>})
Module: model.inception_block.shortcut.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6b80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7d6b80>})
Module: model.inception_block.shortcut.1.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103430>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103430>})
Module: model.inception_block.shortcut.1.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1790>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1790>})
Module: model.inception_block.shortcut.1.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c447940>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c447940>})
Module: model.inception_block.shortcut.1.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c447280>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c447280>})
Module: model.inception_block.shortcut.2, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a69d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc25c4a69d0>})
Module: model.inception_block.shortcut.2.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c36bb80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c36bb80>})
Module: model.inception_block.shortcut.2.0.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103ee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103ee0>})
Module: model.inception_block.shortcut.2.0.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c3675e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c3675e0>})
Module: model.inception_block.shortcut.2.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c36bca0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c36bca0>})
Module: model.inception_block.add, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c36b5e0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c36b5e0>})
Module: model.inception_block.activation, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103d30>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103d30>})
Module: model.gap, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103e50>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc28c103e50>})
Module: model.gap.gap, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1ee0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1ee0>})
Module: model.gap.flatten, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1b80>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c7c1b80>})
Module: model.fc, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c447af0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c447af0>})
Module: model.fc.0, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c447a60>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c447a60>})
Module: model.fc.1, qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c4479d0>}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7fc21c4479d0>})
[DATA] Example input shape: torch.Size([8, 24, 144])
[PREPARE] Model prepared successfully.
[HOOK] Performing QAT training hook.
[HOOK] QAT epoch 1/1 started.
Generations:   0%|          | 0/10000 [00:14<?, ?gen/s]
